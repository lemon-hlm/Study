
<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [0 概述](#0-概述)
  - [0.1 服务名到ClusterIP的解析](#01-服务名到clusterip的解析)
  - [0.2 3个阶段](#02-3个阶段)
    - [0.2.1 SkyDNS: 1.2版本](#021-skydns-12版本)
    - [0.2.2 KubeDNS: 1.4版本](#022-kubedns-14版本)
    - [0.2.3 CoreDNS: 1.11版本](#023-coredns-111版本)
- [1 在创建DNS服务之前修改每个Node上kubelet的启动参数](#1-在创建dns服务之前修改每个node上kubelet的启动参数)
- [2 创建CoreDNS应用](#2-创建coredns应用)
- [3 服务名的DNS解析](#3-服务名的dns解析)
- [4 CoreDNS的配置说明](#4-coredns的配置说明)

<!-- /code_chunk_output -->

# 0 概述

## 0.1 服务名到ClusterIP的解析

作为**服务发现机制的基本功能**，在集群内需要能够**通过服务名对服务进行访问**，这就需要一个**集群范围内**的**DNS服务**来完成从**服务名到ClusterIP！！！** 的解析。

## 0.2 3个阶段

**DNS服务**在Kubernetes的发展过程中经历了**3个阶段**，接下来会进行讲解。

### 0.2.1 SkyDNS: 1.2版本

在Kubernetes **1.2版本**时，DNS服务是由**SkyDNS**提供的，它由**4个容器**组成：**kube2sky**、**skydns**、**etcd**和**healthz**。

- **kube2sky**容器**监控**Kubernetes中**Service资源的变化**，根据**Service的名称**和**IP地址**信息**生成DNS记录**，并将其保存到**etcd**中；
- **skydns容器**从**etcd**中**读取DNS记录**，并为客户端容器应用**提供DNS查询服务**；
- **healthz容器**提供对**skydns服务**的**健康检查功能**。

图4.3展现了SkyDNS的总体架构:

![2019-08-30-14-23-48.png](./images/2019-08-30-14-23-48.png)

### 0.2.2 KubeDNS: 1.4版本

从Kubernetes **1.4版本**开始，SkyDNS组件便被**KubeDNS**替换，主要考虑是**SkyDNS组件之间通信较多**，整体**性能不高**。

KubeDNS由**3个容器**组成：**kubedns**、**dnsmasq**和**sidecar**，去掉了SkyDNS中的**etcd存储**，将**DNS记录**直接**保存在内存**中，以**提高查询性能**。

- **kubedns容器**监控Kubernetes中**Service资源的变化**，根据**Service的名称**和**IP地址**生成**DNS记录**，并将**DNS记录**保存在**内存**中；
- **dnsmasq容器**从kubedns中**获取DNS记录**，提供**DNS缓存**，为**客户端容器应用**提供**DNS查询服务**；
- **sidecar**提供对**kubedns**和**dnsmasq**服务的**健康检查**功能。

图4.4展现了KubeDNS的总体架构。

![2019-08-30-14-25-36.png](./images/2019-08-30-14-25-36.png)

### 0.2.3 CoreDNS: 1.11版本

从Kubernetes **1.11版本**开始，Kubernetes集群的DNS服务由**CoreDNS**提供。CoreDNS是**CNCF基金会**的一个项目，是用**Go语言**实现的**高性能**、**插件式**、**易扩展**的DNS服务端。

CoreDNS解决了KubeDNS的一些问题，例如**dnsmasq的安全漏洞**、**externalName不能使用stubDomains设置**，等等。

CoreDNS支持**自定义DNS记录**及**配置upstream DNS Server**，可以统一管理Kubernetes**基于服务的内部DNS**和**数据中心的物理DNS**。

CoreDNS**没有使用多个容器的架构**，只用**一个容器**便实现了KubeDNS内3个容器的全部功能。

图4.5展现了CoreDNS的总体架构:

![2019-08-30-14-32-07.png](./images/2019-08-30-14-32-07.png)

下面以CoreDNS为例说明Kubernetes集群DNS服务的搭建过程。

# 1 在创建DNS服务之前修改每个Node上kubelet的启动参数

修改每个Node上kubelet的启动参数，加上以下两个参数。

- \-\-cluster\-dns=169.169.0.100：为DNS服务的ClusterIP地址。
- \-\-cluster\-domain=cluster.local：为在DNS服务中设置的域名。

然后重启kubelet服务。

# 2 创建CoreDNS应用

在**部署CoreDNS应用前**，至少需要创建**一个ConfigMap**、**一个Deployment**和**一个Service**共**3个资源对象**。在启用了**RBAC**的集群中，还可以设置**ServiceAccount**、**ClusterRole**、**ClusterRoleBinding**对CoreDNS容器进行**权限设置**。关于RBAC的内容详见6.2.3节的说明。

**ConfigMap** “coredns”主要设置**CoreDNS**的**主配置文件Corefile**的内容，其中可以定义各种**域名的解析方式**和**使用的插件**，示例如下（Corefile的详细配置说明参见4.5.4节）：

```yaml
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: coredns
  namespace: kube-system
  labels:
      addonmanager.kubernetes.io/mode: EnsureExists
data:
  Corefile: |           # 重点
    cluster.local {
        errors
        health
        kubernetes cluster.local in-addr.arpa ip6.arpa {
            pods insecure
            upstream
            fallthrough in-addr.arpa ip6.arpa
        }
        prometheus :9153
        forward . /etc/resolv.conf
        cache 30
        loop
        reload
        loadbalance
    }
    . {
        cache 30
        loadbalance
        forward . /etc/resolv.conf
    }
```

**Deployment** “coredns”主要**设置CoreDNS容器应用的内容**，示例如下。

其中，**replicas**副本的数量通常应该根据**集群的规模**和**服务数量**确定，如果**单个CoreDNS进程**不足以支撑整个集群的DNS查询，则可以通过**水平扩展**提高查询能力。由于DNS服务是Kubernetes集群的**关键核心服务**，所以建议为其Deployment设置**自动扩缩容控制器**，自动管理其副本数量。

另外，对**资源限制部分**（**CPU限制**和**内存限制**）的设置也应根据实际环境进行调整：

```yaml
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: coredns
  namespace: kube-system
  labels:
    k8s-app: kube-dns
    kubernetes.io/cluster-service: "true"
    addonmanager.kubernetes.io/mode: Reconcile
    kubernetes.io/name: "CoreDNS"
spec:
  replicas: 1           # 重点
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
  selector:
    matchLabels:
      k8s-app: kube-dns
  template:
    metadata:
      labels:
        k8s-app: kube-dns
      annotations:
        seccomp.security.alpha.kubernetes.io/pod: 'docker/default'
    spec:
      priorityClassName: system-cluster-critical
      tolerations:
        - key: "CriticalAddonsOnly"
          operator: "Exists"
      nodeSelector:
        beta.kubernetes.io/os: linux
      containers:
      - name: coredns
        image: coredns/coredns:1.3.1
        imagePullPolicy: IfNotPresent
        resources:
          limits:
            memory: 170Mi
          requests:
            cpu: 100m
            memory: 70Mi
        args: [ "-conf", "/etc/coredns/Corefile" ]
        volumeMounts:
        - name: config-volume
          mountPath: /etc/coredns
          readOnly: true
        ports:
        - containerPort: 53
          name: dns
          protocol: UDP
        - containerPort: 53
          name: dns-tcp
          protocol: TCP
        - containerPort: 9153
          name: metrics
          protocol: TCP
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
            scheme: HTTP
          initialDelaySeconds: 60
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 5
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            add:
            - NET_BIND_SERVICE
            drop:
            - all
          readOnlyRootFilesystem: true
      dnsPolicy: Default
      volumes:
        - name: config-volume
          configMap:
            name: coredns
            items:
            - key: Corefile
              path: Corefile
```

**Service** “kube\-dns”是DNS服务的配置，示例如下。

这个服务需要设置固定的ClusterIP，也需要将所有Node上的kubelet启动参数 \-\-cluster\-dns设置为这个ClusterIP：

```yaml
---
apiVersion: v1
kind: Service
metadata:
  name: kube-dns
  namespace: kube-system
  annotations:
    prometheus.io/port: "9153"
    prometheus.io/scrape: "true"
  labels:
    k8s-app: kube-dns
    kubernetes.io/cluster-service: "true"
    addonmanager.kubernetes.io/mode: Reconcile
    kubernetes.io/name: "CoreDNS"
spec:
  selector:
    k8s-app: kube-dns
  clusterIP: 169.169.0.100
  ports:
  - name: dns
    port: 53
    protocol: UDP
  - name: dns-tcp
    port: 53
    protocol: TCP
  - name: metrics
    port: 9153
    protocol: TCP
```

通过kubectl create完成CoreDNS服务的创建：

```
# kubectl create -f coredns.yaml
```

查看RC、Pod和Service，确保容器成功启动：

![2019-08-30-15-30-18.png](./images/2019-08-30-15-30-18.png)

# 3 服务名的DNS解析

使用一个**带有nslookup工具**的**Pod**来验证DNS服务能否正常工作：

```yaml
---
apiVersion: v1
kind: Pod
metadata:
  name: busybox
  namespace: default
spec:
  containers:
  - name: busybox
    image: gcr.io/google_containers/busybox
    command:
      - sleep
      - "3600"
```

运行kubectl create \-f busybox.yaml即可完成创建。

在该容器成功启动后，通过kubectl exec \<container\_id> nslookup进行测试：

```
# kubectl exec busybox -- nslookup redis-master
Server: 169.169.0.100
Address 1: 169.169.0.100

Name: redis-master
Address 1: 169.169.8.10
```

可以看到，通过**DNS服务器169.169.0.100**成功找到了**redis\-master服务**的**IP地址**：169.169.8.10。

如果**某个Service**属于**不同的命名空间**，那么在进行Service查找时，需要**补充Namespace的名称**，组合成完整的域名。

下面以查找kube\-dns服务为例，将其所在的**Namespace** “kube\-system”补充在服务名之后，用“.”连接为“kube\-dns.kube\-system”，即可查询成功：

```
# kubectl exec busybox -- nslookup kube-dns.kube-system
Server: 169.169.0.100
Address 1: 169.169.0.100

Name: kube-dns.kube-system
Address 1: 169.169.0.100
```

如果仅使用“kube\-dns”进行查找，则会失败：

```
# kubectl exec busybox -- nslookup kube-dns
nslookup: can't resolve 'kube-dns'
```

# 4 CoreDNS的配置说明

CoreDNS的**主要功能**是通过插件系统实现的。CoreDNS实现了一种链式插件结构，将DNS的逻辑抽象成了一个个插件，能够灵活组合使用。