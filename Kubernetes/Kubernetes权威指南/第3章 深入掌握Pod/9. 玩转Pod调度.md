
<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->



<!-- /code_chunk_output -->

在Kubernetes平台上，我们**很少会直接创建一个Pod**，在大多数情况下会通过**RC**、**Deployment**、**DaemonSet**、**Job**等**控制器**完成对一组Pod副本的创建、调度及全生命周期的自动控制任务。

在**最早的Kubernetes版本**里是**没有这么多Pod副本控制器**的，**只有一个Pod副本控制器RC**（Replication Controller），这个控制器是这样设计实现的：**RC独立于所控制的Pod**，并通过**Label标签**这个松耦合关联关系**控制目标Pod实例的创建和销毁**，随着Kubernetes的发展，RC也出现了新的继任者——**Deployment**，用于更加自动地完成Pod副本的部署、版本更新、回滚等功能。

严谨地说，**RC的继任者**其实并**不是Deployment**，而是**ReplicaSet**，因为 ReplicaSet进一步**增强了 RC标签选择器的灵活性**。之前**RC的标签选择器只能选择一个标签**，而ReplicaSet拥有**集合式的标签选择器**，可以选择**多个Pod标签**，如下所示：

```yaml
selector:
  matchLabels:
    tier: frontend
  matchExpressions:
    - {key: tier, operator: In, values: [frontend]}
```

**与RC不同**，**ReplicaSet**被设计成能**控制多个不同标签的Pod副本**。一种**常见的应用场景**是，**应用MyApp**目前发布了**v1与v2两个版本**，用户希望MyApp的**Pod副本数保持为3个**，可以**同时包含v1和v2版本的Pod**，就可以用**ReplicaSet来实现这种控制**，写法如下：

```yaml
selector:
  matchLabels:
    version: v2
  matchExpressions:
    - {key: version, operator: In, values: [v1, v2]}
```

其实，Kubernetes的**滚动升级**就是巧妙运用ReplicaSet的这个特性来实现的，同时，**Deployment**也是通过**ReplicaSet**来实现**Pod副本自动控制功能**的。

我们**不应该！！！直接使用底层的ReplicaSet**来控制Pod副本，而应该使用**管理ReplicaSet**的**Deployment对象！！！** 来控制副本，这是来自官方的建议。

在大多数情况下，我们希望Deployment创建的Pod副本被成功调度到集群中的任何一个可用节点，而不关心具体会调度到哪个节点。但是，在真实的生产环境中的确也存在一种需求：希望某种Pod的副本全部在指定的一个或者一些节点上运行，比如希望将MySQL数据库调度到一个具有SSD磁盘的目标节点上，此时Pod模板中的NodeSelector属性就开始发挥作用了，上述MySQL定向调度案例的实现方式可分为以下两步。

（1）把具有SSD磁盘的Node都打上自定义标签“disk=ssd”。

（2）在Pod模板中设定NodeSelector的值为“disk: ssd”。

如此一来，Kubernetes在调度Pod副本的时候，就会先按照Node的标签过滤出合适的目标节点，然后选择一个最佳节点进行调度。

上述逻辑看起来既简单又完美，但在真实的生产环境中可能面临以下令人尴尬的问题。

（1）如果NodeSelector选择的Label不存在或者不符合条件，比如这些目标节点此时宕机或者资源不足，该怎么办？

（2）如果要选择多种合适的目标节点，比如SSD磁盘的节点或者超高速硬盘的节点，该怎么办？Kubernates引入了NodeAffinity（节点亲和性设置）来解决该需求。

在真实的生产环境中还存在如下所述的特殊需求。
