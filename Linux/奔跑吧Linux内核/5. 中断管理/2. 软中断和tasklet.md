[TOC]

- 0 概述
- 1 SoftIRQ软中断
    - 1.1 软中断相关定义
        - 1.1.1 struct softirq\_action
        - 1.1.2 irq\_cpustat\_t
        - 1.1.3 软中断的守护进程ksoftirqd
    - 1.2 注册软中断
    - 1.3 触发软中断
    - 1.4 软中断的执行
        - 1.4.1 中断退出阶段执行软中断
        - 1.4.2 在ksoftirqd进程中执行
- 2 tasklet
    - 2.1 tasklet\_struct结构体
    - 2.2 Per\-CPU的两个tasklet链表
    - 2.3 初始化一个tasklet
    - 2.4 调度tasklet的执行
    - 2.5 tasklet的执行
    - 2.6 tasklet的使用方法
- 3 local\_bh\_disable/local\_bh\_enable
    - 3.1 关闭软中断的BH临界区
    - 3.2 local\_bh\_disable关闭软中断
    - 3.3 local\_bh\_enable打开软中断
- 4 小结

在阅读本节前请思考如下小问题。

- 软中断的回调函数执行过程中是否允许响应本地中断？
- 同一类型的软中断是否允许多个CPU并行执行？
- 软中断上下文包括哪几种情况？
- 软中断上下文和进程上下文哪个优先级高？为什么？
- 是否允许同一个Tasklet在多个CPU上并行执行？

# 0 概述

中断管理中有一个很重要的设计理念 — 上下半部机制（Top half and Bottom half)。第1节中介绍的硬件中断管理基本属于上半部的范畴，**中断线程化属于下半部的范畴(！！！**)。在**中断线程化机制**合并到Linux内核**之前(！！！**)，早己经有一些其他的**下半部机制**，例如**软中断(SoftIRQ**)、**tasklet**和**工作队列（workqueue**) 等。

中断上半部有一个很重要的原则：**硬件中断处理程序**应该执行地**越快越好**。也就是说，希望它**尽快离开**并**从硬件中断返回**，这么做的原因如下。

- **硬件中断处理程序**以**异步方式执行**，它会**打断其他重要的代码**执行，因此为了避免被打断的程序停止时间太长，硬件中断处理程序**必须尽快执行完成**。
- **硬件中断处理程序**通常在**关中断的情况(！！！x86下硬件会自动关！！！**)下执行。所谓的关中断，是指**关闭了本地CPU的所有中断响应(！！！**)。关中断之后，**本地CPU不能再响应中断**，因此硬件中断处理程序必须尽快执行完成。以ARM处理器为例，中断发生时，ARM处理器会自动关闭本地CPU的IRQ/FIQ中断，直到从**中断处理程序退出(硬件中断处理程序, 即整个irq\_handler, 对应到ARM GIC就是gic\_handle\_irq**)时才打开本地中断，这整个过程都处于关中断状态。

**上半部**通常是完成**整个中断处理任务**中的**一小部分**，例如**响应中断**表明中断**己经被软件接收**，简单的数据处理如**DMA操作**，以及硬件中断处理完成时发送**EOI信号**给**中断控制器**等，这些工作**对时间比较敏感**。此外中断处理任务还有一些**计算任务**，例如数据复制、数据包封装和转发、计算时间比较长的数据处理等，这些任务可以放到中断下半部来执行。Linux内核并没有严格的规则约束究竟什么样的任务应该放到下半部来执行，这要驱动开发者来决定。中断任务的划分对系统性能会有比较大的影响。

那**下半部具体在什么时候执行**呢？这个**没有确切的时间点**，一般是从**硬件中断返回**后**某一个时间点内**会被执行。下半部执行的关键点是允许响应所有的中断，是一个**开中断的环境**。

# 1 SoftIRQ软中断

软中断是Linux内核很早引入的机制，最早可以追溯到Linux 2.3开发期间。**软中断**是预留给系统中**对时间要求最为严格和最重要的下半部(！！！**)使用的，而且**目前驱动**中**只有块设备**和**网络子系统**使用了**软中断(！！！**)。

## 1.1 软中断相关定义

系统**静态定义**了**若干种软中断类型**，并且Linux内核开发者**不希望用户再扩充新的软中断类型**，如有需要，建议使用**tasklet机制**。己经定义好的软中断类型如下：

```c
[include/linux/interrupt.h]
enum
{
	HI_SOFTIRQ=0,
	TIMER_SOFTIRQ,
	NET_TX_SOFTIRQ,
	NET_RX_SOFTIRQ,
	BLOCK_SOFTIRQ,
	BLOCK_IOPOLL_SOFTIRQ,
	TASKLET_SOFTIRQ,
	SCHED_SOFTIRQ,
	HRTIMER_SOFTIRQ,
	RCU_SOFTIRQ,    /* Preferable RCU should always be the last softirq */

	NR_SOFTIRQS
};
```

通过**枚举类型来静态声明软中断**，并且每一种软中断都使用**索引**来表示一种相对的**优先级**，索引号越小，软中断优先级高，并**在一轮软中断处理中**得到**优先执行**。其中：

- **HI\_SOFTIRQ**, 优先级为0 , 是**最高优先级**的软中断类型。
- **TIMER\_SOFTIRQ**, 优先级为1，**Timer定时器**的软中断。
- NET\_TX\_SOFTIRQ, 优先级为2 , **发送网络数据包**的软中断。
- NET\_RX\_SOFTIRQ，优先级为3，**接收网络数据包**的软中断。
- BLOCK\_SOFTIRQ 和 BLOCK\_IOPOLL\_SOFTIRQ, 优先级分别是4和5, 用于**块设备的软中断**。
- TASKLET\_SOFTIRQ, 优先级为6，专门为**tasklet机制**准备的软中断。
- SCHED\_SOFTIRQ, 优先级为7 , **进程调度**以及**负载均衡**。
- HRTIMER\_SOFTIRQ，优先级为8 , **高精度定时器**。
- RCU\_SOFTIRQ，优先级为9 , 专门为**RCU服务**的软中断。

### 1.1.1 struct softirq\_action

此外系统还定义了一个用于**描述softirq软中断**的**数据结构**struct **softirq\_action**，并且定义了**软中断描述符数组**softirq\_vec[]，**类似硬件中断描述符**数据结构irq\_desc[]，**每个软中断类型对应一个描述符**，其中**软中断的索引号**就是该数组的**索引**。

```c
[include/linux/interrupt.h]
struct softirq_action
{
	void	(*action)(struct softirq_action *);
};

[kernel/softirq.c]
static struct softirq_action softirq_vec[NR_SOFTIRQS] __cacheline_aligned_in_smp;
```

也就是**每个软中断类型**对应一个**描述符**, **静态定义**的. 可以将**softirq\_vec认为是全局软中断action表(非per CPU**), 而且是**系统初始化会创建好(也就是action会指定！！！**).

NR\_SOFTIRQS是软中断枚举类型中表示系统**最大支持软中断类型的数量**。\_**cacheline\_aligned\_in\_smp**用于将softirq\_vec数据结构和**L1缓存行(cache line) 对齐**，在第1.12节己经详细介绍过。

struct softirq\_action数据结构比较简单，只有一个**action的函数指针**，当**触发了该软中断**，就会**调用action回调函数**来处理这个软中断。

### 1.1.2 irq\_cpustat\_t

此外还有一个**irq\_cpustat\_t**数据结构来**描述软中断状态信息**，可以理解为“**软中断状态寄存器**”，该寄存器其实是一个**unsigned int类型的变量\_\_softirq\_pending**。

同时也定义了一个**irq\_stat[NR\_CPUS]数组**，相当于**每个CPU**有一个**软中断状态信息变量**，可以理解为**每个CPU**有一个“**软中断状态寄存器(！！！**)”。

```c
[include/asm-generic/hardirq.h]
typedef struct {
	unsigned int __softirq_pending;
} ____cacheline_aligned irq_cpustat_t;

[kernel/softirq.c]
#ifndef __ARCH_IRQ_STAT
irq_cpustat_t irq_stat[NR_CPUS] ____cacheline_aligned;
EXPORT_SYMBOL(irq_stat);
#endif
```

### 1.1.3 软中断的守护进程ksoftirqd

在**cpu的热插拔**阶段，内核为**每个cpu**创建了一个用于**执行软件中断**的**守护进程ksoftirqd**，同时定义了一个**per\_cpu变量**用于**保存每个守护进程的task\_struct**结构指针：

```c
DEFINE_PER_CPU(struct task_struct *, ksoftirqd);
```

大多数情况下，软中断都会在irq\_exit阶段被执行，在**irq\_exit阶段**没有处理完的软中断才有可能会在守护进程中执行。

## 1.2 注册软中断

通过调用**open\_softirq**()函数接口可以**注册一个软中断**，其中**参数nr是软中断的序号**。

```c
[kernel/softirq.c]
void open_softirq(int nr, void (*action)(struct softirq_action *))
{
	softirq_vec[nr].action = action;
}
```

注意，**softirq\_vec**[]是一个**多CPU共享的数组(！！！**)，**软中断的初始化**通常是在**系统启动时完成(！！！每个软中断的action也是系统启动时初始化的！！！**)，系统启动时是**串行执行**的，因此它们之间**不会产生冲突**，所以这里没有额外的保护机制。

## 1.3 触发软中断

总结:

(1) **raise\_softirq**()比**raise\_softirq\_irqoff**()唯一区别在于**前者主动关闭本地中断(CPU硬件中断！！！**), 所以后者可以在进程上下文调用

(2) 设置**本地CPU的irq\_stat**的第nr比特位

(3) 通过**in\_interrupt**判断是否在**中断上下文**, **不在的话(即在进程上下文**), 唤醒**软中断守护进程ksoftirqd**, 在**守护进程中执行软中断**回调函数; 在**中断上下文(！！！**)的话, 软中断将在**当前中断退出阶段被执行**

raise\_softirq()函数是**主动触发一个软中断**的API接口函数。

```c
[kernel/softirq.c]
void raise_softirq(unsigned int nr)
{
	unsigned long flags;

	local_irq_save(flags);
	raise_softirq_irqoff(nr);
	local_irq_restore(flags);
}
```

其实**触发软中断**有**两个API接口函数**，分别是**raise\_softirq**()和**raise\_softirq\_irqoff**(),唯一的**区别在于是否主动关闭本地中断(！！！**)，因此**raise\_softirq\_irqoff**()允许在**进程上下文(！！！)中调用**。

```c
[kernel/softirq.c]
inline void raise_softirq_irqoff(unsigned int nr)
{
	__raise_softirq_irqoff(nr);

	if (!in_interrupt())
		wakeup_softirqd();
}
```

\_\_raise\_softirq\_irqoff()函数实现如下:

```c
[include/linux/irq_cpustat.h]
#define __IRQ_STAT(cpu, member)	(irq_stat[cpu].member)
#define local_softirq_pending() \
	__IRQ_STAT(smp_processor_id(), __softirq_pending)

[include/linux/interrupt.h]
#define set_softirq_pending(x) (local_softirq_pending() = (x))
#define or_softirq_pending(x)  (local_softirq_pending() |= (x))

[kernel/softirq.c]
void __raise_softirq_irqoff(unsigned int nr)
{
	or_softirq_pending(1UL << nr);
}
```

\_\_raise\_softirq\_irqoff()函数会设置**本地CPU的irq\_stat**数据结构中\_\_softirq\_pending成员的**第nr个比特位**，nr表示**软中断的序号**。

在**中断返回时(！！！**)，该CPU会检查\_\_**softirq\_pending成员的比特位**，如果\_\_**softirq\_pending不为0**，说明**有pending的软中断需要处理**。

如果**触发点**发生在**中断上下文**，只需要**设置本地CPU \_\_softirq\_pending**中的**软中断对应比特位**即可。**in\_interrupt()为0**, 说明现在运行在**进程上下文**中，那么需要调用**wakeup\_softirqd**()唤醒**ksoftirqd内核线程**来处理。

注意，**raise\_softirq**()函数修改的是**Per\-CPU类型**的\_\_**softirq\_pending变量**，这里**不需要考虑多CPU并发**的情况，因此不需要考虑使用spinlock等机制，**只考虑是否需要关闭本地中断(！！！**)即可。可以根据**触发软中断场景**来考虑是使用raise\_softirq()，还是raise\_softirq\_irqoff()。

## 1.4 软中断的执行

基于上面所说，**软中断的执行**既可以**守护进程**中执行，也可以在**中断的退出阶段**执行。实际上，软中断**更多的是在中断的退出阶段执行**（irq\_exit），以便达到更快的响应. 加入**守护进程机制**，只是担心一旦有大量的软中断等待执行，会使得内核**过长地留在中断上下文**中。

### 1.4.1 中断退出阶段执行软中断

irq\_exit()总结:

(1) 判断条件, **中断退出**时不能处于**中断上下文**(还有种情况, **中断点在软中断处理过程(不可能是硬件中断处理过程<因为硬件中断过程中CPU是关中断的>中**)中, **中断退出**时会返回到**软中断上下文<也是中断上下文**>, 也**不能重新调度软中断**, 因为**软中断在一个CPU总是串行执行！！！**); 本地CPU的irq\_stat上有**pending等待的软中断**. 条件满足才会进行下面步骤.

(2) 调用软中断**invoke\_softirq**()

(3) 获取本地CPU的软中断状态irq\_stat

(4) 增加当前进程struct thread\_info中的preempt\_count成员里的SOFTIRQ域的值, 表明在**软中断上下文**

(5) 清除软中断状态寄存器\_\_softirq\_pending, **清除所有**, 因为这里将**全部处理**

(6) **打开本地中断**, 允许**新的中断**以及**触发软中断**

(7) 循环处理软中断. 遍历**软中断状态irq\_stat(每个CPU一个**), 每一个相当于软中断向量表softirq\_vec\[\]的索引, 得到软中断然后执行

(8) **关闭本地中断**. 

(9) 再次检查\_\_softirq\_pending, 看是否又产生软中断. 当又有软中断并且条件满足则回到步骤(5), 否则唤醒**ksoftirqd内核线程**来处理软中断

(10) 减少当前进程struct thread\_info中的preempt\_count成员里的SOFTIRQ域的值, 表明离开软中断上下文

上节中在介绍**中断退出**时， **irq\_exit**()函数会检查**当前是否有pending 等待的软中断(！！！**)。

```c
[中断发生->irq_handler-> gic_handle_irq() ->handle_domain_irq() ->irq_exit()]

[kernel/softirq.c]
void irq_exit(void)
{
    ...
	if (!in_interrupt() && local_softirq_pending())
	    // 重要
		invoke_softirq();
    ...
}
```

**local\_softirq\_pending**()函数检查**本地CPU**的\_\_**softirq\_pending****是否有**pending等待的软中断**。注意，这里还有一个判断条件**为!in\_terrupt**(), 也就是说，**中断退出**时**不能处于硬件中断上下文**(Hardirq context)和**软中断上下文（Softirq context**)中。**硬件中断处理过程**一般都是**关中断**的，**中断退出时**也就**退出了硬件中断上下文**，因此该条件会满足。还有一个场景，如果**本次中断点**发生在一个**软中断处理过程**中，那么**中断退出**时会**返回到软中断上下文<也是中断上下文**>中，因此这种情况**不允许重新调度软中断**，因为**软中断**在**一个CPU**上总是**串行执行(！！！**)的。

invoke\_softirq()继续查看.

```c
[irq_exit() ->invoke_softirq() -> __do_softirq()]
[kernel/softirq.c]
asmlinkage __visible void __do_softirq(void)
{
	unsigned long end = jiffies + MAX_SOFTIRQ_TIME;
	unsigned long old_flags = current->flags;
	int max_restart = MAX_SOFTIRQ_RESTART;
	struct softirq_action *h;
	bool in_hardirq;
	__u32 pending;
	int softirq_bit;
    // 位置1
	current->flags &= ~PF_MEMALLOC;
    // 位置2
	pending = local_softirq_pending();
	// 位置3
	__local_bh_disable_ip(_RET_IP_, SOFTIRQ_OFFSET);

restart:
	/* Reset the pending bitmask before enabling irqs */
	// 位置4
	set_softirq_pending(0);
    // 位置5
	local_irq_enable();

	h = softirq_vec;
    // 位置6
	while ((softirq_bit = ffs(pending))) {
		unsigned int vec_nr;
		int prev_count;

		h += softirq_bit - 1;

		vec_nr = h - softirq_vec;
		prev_count = preempt_count();

		h->action(h);
		h++;
		pending >>= softirq_bit;
	}
    // 位置7
	local_irq_disable();
    // 位置8
	pending = local_softirq_pending();
	if (pending) {
		if (time_before(jiffies, end) && !need_resched() &&
		    --max_restart)
			goto restart;

		wakeup_softirqd();
	}
    // 位置9
	__local_bh_enable(SOFTIRQ_OFFSET);
	// 位置10
	tsk_restore_flags(current, old_flags, PF_MEMALLOC);
}
```

位置1和位置10是**配对使用**的。**PF\_MEMALLOC**目前主要用在**两个地方**，一是**直接内存压缩(direct compaction)的内核路径**，二是**网络子系统**在**分配skbuff失败**时会设置PF\_MEMALLOC标志位，这是在Linux 3.6内核中，社区专家Mel Gorman为了解决**网络磁盘设备**(network Block Device, NBD)使用**交换分区**时出现**死锁**的问题而引入的，己经超出本章的讨论范围.

位置2, 获取**本地CPU(！！！**)的**软中断寄存器\_\_softirq_pending**的值到局部变量pending.

位置3，增加**preempt\_count**中的**SOFTIRQ域的计数**，表明现在是在**软中断上下文**中, 由此禁止了软中断, 主要为了防止和软中断守护进程发生竞争；

位置4，清除**软中断寄存器\_\_softirq\_pending**, 将所有都清除了。

位置5，**打开本地中断**。这里**先清除\_\_softirq\_pending**位图，然后再**打开本地中断**。需要注意这里和位置4之间的顺序，读者可以思考如果在位置4之前打开本地中断会有什么后果。

位置6，**while循环依次处理软中断**。首先**ffs**()函数会找到**pending中第一个置位的比特位**，然后找到**对应的软中断描述符**和**软中断的序号**，最后**调用action**()函数指针来**执行软中断**处理，依次循环直到**所有软中断都处理完成**。

位置7，**关闭本地中断**。

位置8到位置9，**再次检查\_\_softirq\_pending是否又产生了软中断**。因为**软中断执行过程**是**开中断**的，有可能在这个过程中又发生了中断以及触发了软中断，即有人**调用了raise\_softirq**()。注意，**不是检测到有软中断**就**马上调转到restart标签处**进行软中断处理，这里需要一个**系统平衡的考虑**。需要考虑**3个判断条件**，一是**软中断处理时间没有超过2毫秒**，二是**当前没有进程要求调度**，即!need\_resched(),三是**这种循环不能多于10次**，否则应该**唤醒ksoftirqd内核线程**来处理软中断。

位置9, 代码和位置3代码是配对使用，恢复软中断, 表示现在**离开软中断上下文**了。

### 1.4.2 在ksoftirqd进程中执行

软中断也可能由**ksoftirqd守护进程执行**，这要发生在以下两种情况下：

- 在**irq\_exit中执行软中断**，但是在经过**MAX\_SOFTIRQ\_RESTART次(目前设定为10**)循环后，**软中断还未处理完**，这种情况虽然极少发生，但毕竟有可能；
- 内核的其它代码**主动调用raise\_softirq**，而这时正好**不是在中断上下文中(！！！**)，守护进程将被唤醒；

守护进程最终也会调用\_\_**do\_softirq**执行软中断的回调，具体的代码位于**run\_ksoftirqd**函数中，内核会**关闭抢占**的情况下执行\_\_do\_softirq，具体的过程这里不做讨论。

# 2 tasklet

tasklet是利用**软中断**实现的一种下半部机制，本质上是**软中断的一个变种**，运行在**软中断上下文(！！！**)中。

## 2.1 tasklet\_struct结构体

tasklet由**tasklet\_struct**数据结构来描述：

```c
[include/linux/interrupt.h]
struct tasklet_struct
{
	struct tasklet_struct *next;
	unsigned long state;
	atomic_t count;
	void (*func)(unsigned long);
	unsigned long data;
};


enum
{
	TASKLET_STATE_SCHED,	/* Tasklet is scheduled for execution */
	TASKLET_STATE_RUN	/* Tasklet is running (SMP only) */
};
```

- next: **多个tasklet**串成一个**链表**。
- state: 该**tasklet当前状态**. TASKLET\_STATE\_SCHED表示tasklet**己经被调度，正准备运行**。TASKLET\_STATE\_RUN表示tasklet**正在运行**中。
- count: 为**0**表示tasklet处于**激活状态**；**不为0**表示该**tasklet被禁止**，**不允许执行**。原子变量count用于tasklet对tasklet\_disable和tasklet\_enable的计数，count为0时表示允许tasklet执行，否则不允许执行，每次tasklet\_disable时，该值加1，tasklet\_enable时该值减1
- func: **tasklet处理程序**，类似软中断中的**action函数指针**。
- data: 传递**参数**给tasklet处理函数。

## 2.2 Per\-CPU的两个tasklet链表

**每个CPU(实际上是每个logical processor, 即每个cpu thread)**维护**两个tasklet链表**，一个用于**普通优先级的tasklet\_vec**，另一个用于**高优先级的tasklet\_hi\_vec**，它们都是**Per\-CPU变量(！！！**)。链表中**每个tasklet\_struct**代表一个**tasklet**。

```c
[kernel/softirq.c]
struct tasklet_head {
	struct tasklet_struct *head;
	struct tasklet_struct **tail;
};

static DEFINE_PER_CPU(struct tasklet_head, tasklet_vec);
static DEFINE_PER_CPU(struct tasklet_head, tasklet_hi_vec);
```

其中，**tasklet\_vec**使用**软中断**中的**TASKLET\_SOFTIRQ**类型，它的**优先级是6**; 而**tasklet\_hi\_vec**使用的**软中断**中的**HI\_SOFTIRQ**, **优先级是0**，是**所有软中断**中**优先级最高**的。

在**系统启动(！！！**)时会**初始化这两个链表**，见**softirq\_init**()函数，另外还会**注册TASKLET\_SOFTIRQ**和**HI\_SOFTIRQ**这**两个软中断(！！！**)，它们的**软中断回调函数**分别为**tasklet\_action**和**tasklet\_hi\_action**。高优先级的**tasklet\_hi**在**网络驱动**中用得比较多，它和普通的tasklet实现机制相同，本文以**普通tasklet为例**。

```c
[start_kernel()->softirq_init()]
[kernel/softirq.c]
void __init softirq_init(void)
{
	int cpu;

	for_each_possible_cpu(cpu) {
		per_cpu(tasklet_vec, cpu).tail =
			&per_cpu(tasklet_vec, cpu).head;
		per_cpu(tasklet_hi_vec, cpu).tail =
			&per_cpu(tasklet_hi_vec, cpu).head;
	}

	open_softirq(TASKLET_SOFTIRQ, tasklet_action);
	open_softirq(HI_SOFTIRQ, tasklet_hi_action);
}
```

## 2.3 初始化一个tasklet

要想在**驱动**中使用**tasklet**，首先**定义一个tasklet**, 可以**静态申明**， 也可以**动态初始化**。

```c
[include/linux/interrupt.h]
#define DECLARE_TASKLET(name, func, data) \
struct tasklet_struct name = { NULL, 0, ATOMIC_INIT(0), func, data }

#define DECLARE_TASKLET_DISABLED(name, func, data) \
struct tasklet_struct name = { NULL, 0, ATOMIC_INIT(1), func, data }
```

上述**两个宏**都是**静态**地申明一个**tasklet数据结构**。上述两个宏的**唯一区别**在于**count成员**的初始化值不同，DECLARE\_TASKLET宏把**count初始化为0**, 表示**tasklet处于激活状态**；而DECLARE\_TASKLET\_DISABLED宏把**count成员初始化为1** , 表示**该tasklet处于关闭状态**。

当然也可以在**驱动代码**中调用**tasklet\_init**()函数**动态初始化tasklet**, 该方法**默认tasklet处于enable状态**。

```c
[kernel/softirq.c]
void tasklet_init(struct tasklet_struct *t,
		  void (*func)(unsigned long), unsigned long data)
{
	t->next = NULL;
	t->state = 0;
	atomic_set(&t->count, 0);
	t->func = func;
	t->data = data;
}
EXPORT_SYMBOL(tasklet_init);
```

## 2.4 调度tasklet的执行

总结: 其实就是将**tasklet**挂载到**tasklet\_vec**或者**tasklet\_hi\_vec链表**, 然后**raise\_softirq\_irqoff**(**进程上下文**的话唤醒**ksoftirqd守护进程**, 中断上下文什么都不做, 软中断将在中断退出阶段被执行)

在**驱动程序**中调度tasklet可以使用**tasklet\_schedule**()函数。

```c
[include/linux/interrupt.h]
static inline void tasklet_schedule(struct tasklet_struct *t)
{
	if (!test_and_set_bit(TASKLET_STATE_SCHED, &t->state))
		__tasklet_schedule(t);
}
```

**test\_and\_set\_bit**()函数**原子**地设置**tasklet\_struct\->state**成员为**TASKLET\_STATE\_SCHED**标志位，然后**返回该state旧的值**。返回**true**，说明**该tasklet己经被挂入到tasklet链表**中；返回**false**，则**需要调用\_\_tasklet\_schedule**()把**该tasklet挂入链表**中。

```c
[kernel/softirq.c]
void __tasklet_schedule(struct tasklet_struct *t)
{
	unsigned long flags;

	local_irq_save(flags);
	t->next = NULL;
	*__this_cpu_read(tasklet_vec.tail) = t;
	__this_cpu_write(tasklet_vec.tail, &(t->next));
	raise_softirq_irqoff(TASKLET_SOFTIRQ);
	local_irq_restore(flags);
}
EXPORT_SYMBOL(__tasklet_schedule);
```

\_\_tasklet\_schedule()函数比较简单，在**关闭中断**的情况下，把**tasklet**挂入到**tasklet\_vec链表**中，然后再触发一个**TASKLET\_SOFTIRQ类型的软中断**。

那**什么时候执行tasklet**呢？是在驱动调用了tasklet\_schedule()后马上就执行吗？

其实不是的，**tasklet是基于软中断机制**的，因此tasklet\_schedule()后不会马上执行，要**等到软中断被执行时才有机会运行tasklet(！！！**), tasklet挂入**哪个CPU**的**tasklet\_vec链表**，那么就由**该CPU的软中断来执行**。在分析tasklet\_schedule()时己经看到，一个tasklet挂入到一个CPU的tasklet\_vec链表后会**设置TASKLET\_STATE\_SCHED标志位**，只要该tasklet还没有执行，那么即使驱动程序多次调用tasklet\_schedule()也不起作用。因此一旦**该tasklet挂入到某个CPU的tasklet\_vec链表(！！！**)后，它就**必须在该CPU的软中断上下文中执行(！！！**)，直到执行完毕并清除了TASKLET\_STATE\_SCHED标志位后，才有机会到其他CPU上运行。

## 2.5 tasklet的执行

**软中断执行时**会按照**软中断状态\_\_softirq\_pending**来依次执行**pending状态的软中断**，当轮到执行**TASKLET\_SOFTIRQ类型软中断**时，回调函数**tasklet\_action**()会被调用。

```c
[软中断执行 -> tasklet_action()]
[kernel/softirq.c]
static void tasklet_action(struct softirq_action *a)
{
	struct tasklet_struct *list;
    // 位置1
	local_irq_disable();
	list = __this_cpu_read(tasklet_vec.head);
	__this_cpu_write(tasklet_vec.head, NULL);
	__this_cpu_write(tasklet_vec.tail, this_cpu_ptr(&tasklet_vec.head));
	// 位置2
	local_irq_enable();
    // 位置3
	while (list) {
		struct tasklet_struct *t = list;

		list = list->next;
        // 位置4
		if (tasklet_trylock(t)) {
		    // 位置5
			if (!atomic_read(&t->count)) {
			    // 位置6
				if (!test_and_clear_bit(TASKLET_STATE_SCHED,
							&t->state))
					BUG();
				t->func(t->data);
				// 位置7
				tasklet_unlock(t);
				continue;
			}
			tasklet_unlock(t);
		}
        // 位置8
		local_irq_disable();
		t->next = NULL;
		*__this_cpu_read(tasklet_vec.tail) = t;
		__this_cpu_write(tasklet_vec.tail, &(t->next));
		__raise_softirq_irqoff(TASKLET_SOFTIRQ);
		local_irq_enable();
		// 位置9
	}
}
```

位置1到位置3, 在**关中断的情况下(！！！**)读取**tasklet\_vec链表头**到临时链表list中，并重新初始化tasklet\_vec链表。注意，tasklet\_vec.tail指向链表头tasklet\_vec.head指针本身的地址。

位置3, **while循环**依次执行**tasklet\_vec链表**中**所有的tasklet成员**。注意位置2和位置8，**整个tasklet的执行过程是在开中断的**。

位置4, tasklet\_trylock()函数设计成一个锁。如果tasklet己经处于RUNNING状态，即被设置了TASKLET\_STATE\_RUN标志位，tasklet\_trylock()函数返回false，表示不能成功获取该锁，那么直接跳转到位置8处，这一轮的tasklet将会跳过该tasklet。这样做的目的是为了保证同一个tasklet只能在一个CPU上运行，稍后以scdrv驱动程序为例讲解这种特殊的情况。

```c
[include/linux/interrupt.h]
static inline int tasklet_trylock(struct tasklet_struct *t)
{
	return !test_and_set_bit(TASKLET_STATE_RUN, &(t)->state);
}
```

位置5, 原子地检查count计数是否为0, 为0则表示这个tasklet处于可执行状态。注意，tasklet\_disable()可能随时会原子地增加count计数，count计数大于0, 表示tasklet处于禁止状态。位置5原子地读完count计数后可能马上被另外的内核代码执行路径调用tasklet\_disable()修改了count计数，但这只会影响tasklet的下一次处理。

位置6到位置7之间, 注意顺序是先清TASKLET\_STATE\_SCHED标志位，然后执行t\-func(), 最后才清TASKLET\_STATE\_RUN标志位。为什么不执行完func()再清TASKLET\_STATE\_SCHED标志位呢？这是为了在执行func()期间也可以响应新调度的tasklet, 以免丢失。

位置8到位置9之间, 处理该tasklet己经在其他CPU上执行的情况，tasklet\_trylock()返回false，表示获取锁失败。这种情况下会把该tasklet重新挂入当前CPU的tasklet\_vec链表中，等待下一次触发TASKLET\_SOFTIRQ类型软中断时才会被执行。还有一种情况是在之前调用tasklet\_disable()增加了tasklet\_struct\->count计数，那么本轮的tasklet处理也将会被略过。

为何会出现位置8到位置9情况呢? 即将要执行tasklet时发现该tasklet己经在别的CPU上运行。

总结如下:

- 关闭本地中断的前提下，移出当前cpu的待处理tasklet链表到一个临时链表后，清除当前cpu的tasklet链表，之所以这样处理，是为了处理当前tasklet链表的时候，允许新的tasklet被调度进待处理链表中。
- 遍历临时链表，用tasklet_trylock判断当前tasklet是否已经在其他cpu上运行，而且tasklet没有被禁止：
    - 如果没有运行，也没有禁止，则清除TASKLET\_STATE\_SCHED状态位，执行tasklet的回调函数。
    - 如果已经在运行，或者被禁止，则把该tasklet重新添加会当前cpu的待处理tasklet链表上，然后触发TASKLET_SOFTIRQ软中断，等待下一次软中断时再次执行。


以常见的一个**设备驱动**为例，在硬件中断处理函数中调用tasklet\_schedule()函数去触发tasklet来处理一些数据，例如数据复制、数据转换等。以drivers/char/snsc\_event.c驱动为例，假设该设备为设备A:

```c
[drivers/char/snsc_event.c]
static irqreturn_t
scdrv_event_interrupt(int irq, void *subch_data)
{
	struct subch_data_s *sd = subch_data;
	unsigned long flags;
	int status;

	spin_lock_irqsave(&sd->sd_rlock, flags);
	status = ia64_sn_irtr_intr(sd->sd_nasid, sd->sd_subch);

	if ((status > 0) && (status & SAL_IROUTER_INTR_RECV)) {
		tasklet_schedule(&sn_sysctl_event);
	}
	spin_unlock_irqrestore(&sd->sd_rlock, flags);
	return IRQ_HANDLED;
}
```

硬件中断处理程序scdrv\_event\_interrupt()读取中断状态寄存器确认中断发生，然后调用tasklet\_schedule()函数执行下半部操作，该tasklet回调函数是scdrv\_event()函数。假设CPU0在执行设备A的tasklet下半部操作时，设备B产生了中断，那么CPU0暂停tasklet处理，转去执行设备B的硬件中断处理。这时设备A又产生了中断，中断管理器把该中断派发给CPU1。假设CPU1很快处理完硬件中断并开始处理该tasklet, 在tasklet\_schedule()函数中发现并没有设置TASKLET\_STATE\_SCHED标志位，因为CPUO在执行tasklet回调函数之前已经把该标志位清除了，因此该tasklet被加入到CPU1的tasklet\_vec链表中，当执行到tasklet\_action()函数的tasklet\_trylock(t)时会发现无法获取该锁，因为该tasklet己经被CPU0设置了TASKLET\_STATE\_RUN标志位，因此CPU1便跳过了这次tasklet, 等到CPU0中断返回把TASKLET\_STATE\_RUN标志位清除后，CPU1下一轮软中断执行时才会再继续执行该tasklet。

![config](./images/9.png)

## 2.6 tasklet的使用方法

**使能和禁止tasklet**，使用以下函数：

- tasklet\_disable() 通过给count字段加1来禁止一个tasklet，如果tasklet正在运行中，则等待运行完毕才返回（通过TASKLET\_STATE\_RUN标志）。
- tasklet\_disable\_nosync() tasklet\_disable的异步版本，它不会等待tasklet运行完毕。
- tasklet\_enable() 使能tasklet，只是简单地给count字段减1。

**调度tasklet的执行**，使用以下函数：

- tasklet\_schedule(struct tasklet\_struct *t) 如果TASKLET\_STATE\_SCHED标志为0，则置位TASKLET\_STATE\_SCHED，然后把tasklet挂到该cpu等待执行的tasklet链表上，接着发出TASKLET\_SOFTIRQ软件中断请求。
- tasklet\_hi\_schedule(struct tasklet\_struct *t) 效果同上，区别是它发出的是HI\_SOFTIRQ软件中断请求。

销毁tasklet，使用以下函数：

- tasklet\_kill(struct tasklet\_struct *t) 如果tasklet处于TASKLET\_STATE\_SCHED状态，或者tasklet正在执行，则会等待tasklet执行完毕，然后清除TASKLET\_STATE\_SCHED状态。

# 3 local\_bh\_disable/local\_bh\_enable

## 3.1 关闭软中断的BH临界区

local\_bh\_disable()和local\_bh\_enable()是内核中提供的**关闭软中断**的**锁机制**，它们组成的临界区**禁止本地CPU在中断返回前夕执行软中断**，这个临界区简称**BH临界区(bottom half critical region**).

## 3.2 local\_bh\_disable关闭软中断

总结: 将当前进程的preempt\_count加上SOFTIRQ\_DISABLE\_OFFSET, 表明进入了软中断上下文

```c
[include/linux/bottom_half.h]
static inline void local_bh_disable(void)
{
	__local_bh_disable_ip(_THIS_IP_, SOFTIRQ_DISABLE_OFFSET);
}
static __always_inline void __local_bh_disable_ip(unsigned long ip, unsigned int cnt)
{
	preempt_count_add(cnt);
	barrier();
}

[include/linux/preempt_mask.h]
#define SOFTIRQ_BITS	8
#define PREEMPT_SHIFT	0
#define SOFTIRQ_SHIFT	(PREEMPT_SHIFT + PREEMPT_BITS)
#define SOFTIRQ_OFFSET	(1UL << SOFTIRQ_SHIFT) // 等价于 1UL <<8
#define SOFTIRQ_DISABLE_OFFSET	(2 * SOFTIRQ_OFFSET)
```

local\_bh\_disable()的实现比较简单，就是把**当前进程的preempt\_count**成员**加上SOFTIRQ\_DISABLE\_OFFSET**, 那么现在**内核状态进入了软中断上下文（softirq context**)。这里有barrier()操作以防止编译器做了优化，thread\_info\->preempt\_count相当于Per\-CPU变量，因此不需要使用内存屏障指令。

注意，**preempt\_count成员**的**bit[8:15**]比特位都是用于表示**软中断**的，但是一般情况下使用第8比特位即可，**该域**还用于表示**软中断嵌套的深度**，最多表示255次嵌套，这也是SOFTIRQ\_DISABLE\_OFFSET会定义成(2 \* SOFTIRQ\_OFFSET)的原因。

这样当在**local\_bh\_disable**()和**local\_bh\_enable**()构成的**BH临界区内发生了中断**，**中断返回前irq\_exit**()判断当前处于**软中断上下文**，因而**不能调用和执行pending状态的软中断**, 这样驱动代码构造的BH临界区中就**不会有新的软中断来骚扰(！！！**)。

## 3.3 local\_bh\_enable打开软中断

总结: 执行**软中断**, 然后打开抢占

```c
[include/linux/bottom_half.h]
static inline void local_bh_enable_ip(unsigned long ip)
{
	__local_bh_enable_ip(ip, SOFTIRQ_DISABLE_OFFSET);
}

static inline void local_bh_enable(void)
{
	__local_bh_enable_ip(_THIS_IP_, SOFTIRQ_DISABLE_OFFSET);
}

void __local_bh_enable_ip(unsigned long ip, unsigned int cnt)
{
    // 位置1
	WARN_ON_ONCE(in_irq() || irqs_disabled());
	
	/*
	 * Keep preemption disabled until we are done with
	 * softirq processing:
	 */
	// 位置2
	preempt_count_sub(cnt - 1);
    // 位置3
	if (unlikely(!in_interrupt() && local_softirq_pending())) {
		do_softirq();
	}
    // 位置4
	preempt_count_dec();
	// 位置5
	preempt_check_resched();
}
EXPORT_SYMBOL(__local_bh_enable_ip);
```

位置1有两个警告的条件，WARN\_ON\_ONCE()是一个比较弱的警告语句。**in\_irq**()返回true，表示现在正在**硬件中断上下文**中。有些不规范的驱动，可能会在硬件中断处理函数primary handler中调用local\_bh\_disable()/local\_bh\_enable()，其实**硬件中断处理函数primary handler是在关中断环境(CPU自动关闭的本地中断！！！！)下执行**的，关中断是比关BH更猛烈的一种锁机制。因此在**关中断情况**下，**没有必要在调用关BH**相关操作。irqs\_disabled()返回true, 说明现在处于**关中断状态**，也**不适合调用关BH**操作，原理和前者一样。

位置2，preempt\_count计数减去(SOFTIRQ\_DISABLE\_OFFSET \- l), 这里并没有完全减去SOFTIRQ\_DISABLE\_OFFSET, 为什么还留了1呢？**留1表示关闭本地CPU的抢占**，接下来**调用do\_softirq**()时**不希望被其他高优先级任务抢占**了或者**当前任务被迁移到其他CPU**上。

假如**当前进程P运行在CPU0**上，在**位置3**时发生了**中断**，**中断返回前**被**高优先级任务抢占**，那么进程P再被调度时有可能会选择在其他CPU上唤醒(见select\_task\_rq\_fair()函数)，例如CPU1，“**软中断的状态寄存器**” \_\_**softirq\_pending**是Per\-CPU变量，进程P在CPU1上重新运行到位置3代码时发现\_\_softirq\_pending并没有软中断触发，因此**之前的软中断会被延迟执行(！！！**)。

位置3, 在**非中断上下文(！！！**)环境下**执行软中断处理**。

位置4, 打开抢占

位置5, 之前执行软中断处理时可能会漏掉一些高优先级任务的抢占需求，这里重新检查。

总之，local\_bh\_disable()/local\_bh\_enable()是关BH的接口API, 运行在**进程上下文**中，内核中**网络子系统有大量使用**该接口的例子。

# 4 小结

**软中断**是Linux内核中最常见的一种**下半部机制**，适合系统对**性能和实时响应要求很高**的场合，例如网络子系统、块设备、高精度定时器、RCU等。

- **软中断**类型是**静态定义**的，Linux内核**不希望**驱动开发者**新增软中断类型**。
- 软中断的**回调函数**在**开中断环境下**执行。
- **同一类型的软中断**可以在**多个CPU**上并行执行。以**TASKLET\_SOFTIRQ**类型的软中断为例，多个CPU可以同时tasklet\_schedule，并且多个CPU也可能同时从中断处理返回，然后同时触发和执行TASKLET\_SOFTIRQ类型的软中断。
- 假如有驱动开发者要新增一个软中断类型，那软中断的处理函数需要考虑同步问题。
- 软中断的**回调函数不能睡眠**。
- 软中断的**执行时间点**是在**中断返回前**，即**退出硬中断上下文**时，首先检查**是否有pending的软中断**，然后才检查**是否需要抢占当前进程**。因此，软中断上下文总是抢占进程上下文。

**tasklet**是基于**软中断**的一种下半部机制。

- tasklet可以**静态定义**，也可以**动态初始化**。
- tasklet是**串行执行**的。一个**tasklet**在**tasklet\_schedule**()时会绑定某个CPU的**tasklet\_vec链表**，它必须要在该CPU上**执行完tasklet的回调函数**才会和该CPU**松绑**。
- **TASKLET\_STATE\_SCHED**和**TASKLET\_STATE\_RUN标志位**巧妙地构成了**串行执行**。
- 同一个tasklet只能同时在一个cpu上执行，但不同的tasklet可以同时在不同的cpu上执行；
- 一旦tasklet\_schedule被调用，内核会保证tasklet一定会在某个cpu上执行一次；
- 如果tasklet\_schedule被调用时，tasklet不是出于正在执行状态，则它只会执行一次；
- 如果tasklet\_schedule被调用时，tasklet已经正在执行，则它会在稍后被调度再次被执行；
- 两个tasklet之间如果有资源冲突，应该要用自旋锁进行同步保护；

**软中断上下文优先级高于进程上下文**，因此**软中断包括tasklet总是抢占进程(！！！**)的运行。当**进程A在运行时发生中断**，在**中断返回**时**先判断本地CPU上有没有pending的软中断**，如果有，那么首先**执行软中断包括tasklet**, 然后**检查是否有高优先级任务需要抢占中断点的进程**，即进程A。如果在执行软中断和tasklet过程时间很长，那么高优先级任务就长时间得不到运行，势必会影响系统的实时性，这也是RT Linux社区里有专家一直**要求用workqueue机制来替代tasklet机制**的原因。

![config](./images/10.png)

目前Linux内核中有大量的驱动程序使用tasklet机制来实现下半部操作，任何一个tasklet回调函数执行时间过长，都会影响系统实时性，可以预见在不久的将来**tasklet机制**有可能会被Linux内核社区**舍弃**。

**中断上下文**包括**硬中断上下文**（hardirq context)和**软中断上下文**（softirq context)。

- **硬件中断上下文**表示**硬件中断处理过程**。
- **软中断上下文**包括**三部分**
    - 一是在**下半部执行的软中断处理包括tasklet**，调用过程是**irq\_exit()\->invoke\_softirq**();
    - 二是**ksoftirqd内核线程执行的软中断**，例如系统使能了**强制中断线程化**force\_irqthreads (见invoke\_softirq()函数)，还有一种情况是**软中断执行时间太长**，在\_do\_softirq()中**唤醒ksoftirqd内核线程**；
    - 三是**进程上下文(！！！**)中调用**local\_bh\_enable**()时也会去**执行软中断处理**，调用过程是**local\_bh\_enable()-〉do\_softirq**()。

软中断上下文中前者**运行在中断下半部**中，属于传统意义上的**中断上下文**，而**后两者(！！！)运行在进程上下文中**，但是Linux内核统一把它们归纳到软中断上下文范畴里。因此Linux内核中有几个宏来描述和判断这些情况：

```c
[include/linux/preempt_mask.h]
#define in_irq()		(hardirq_count())
#define in_softirq()		(softirq_count())
#define in_interrupt()		(irq_count())
#define in_serving_softirq()	(softirq_count() & SOFTIRQ_OFFSET)
```

- in\_irq()判断当前是否在硬件中断上下文中;
- in\_softirq()判断当前是否在软中断上下文中或者处于关BH的临界区里；
- in\_serving\_softirq()判断当前是否正在软中断处理中，包括前文提到的三种情况。
- in\_interrupt()则包括所有的硬件中断上下文、软中断上下文和关BH临界区。