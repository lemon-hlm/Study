
<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

* [0 概述](#0-概述)
* [1 spinlock实现](#1-spinlock实现)
* [2 spinlock变种](#2-spinlock变种)
* [3 spinlock和raw\_spin\_lock](#3-spinlock和raw_spin_lock)
* [4 总结](#4-总结)

<!-- /code_chunk_output -->


本章思考题

- 为什么spinlock的临界区不能睡眠（不考虑RT\-Linux的情况）？
- Linux内核中经典spinlock的实现有什么缺点？
- 为什么spinlock临界区不允许发生抢占？
- Ticket-based的 spinlock机制是如何实现的？
- 如果在spin\_lock()和spin\_unlock()的临界区中发全了中断，并且中断处理程序也恰巧修改了该临界资源，那么会发生什么后果？该如何避免呢？

# 0 概述

如果**临界区**只是**一个变量**，那么**原子变量**可以解决问题，但是**临界区大多**是一个**数据操作的集合**，例如先从一个数据结构中移出数据，对其进行数据解析，然后再写回到该数据结构或者其他数据结构中，类 似 “read->modify->write”操作；再比如临界区是一个链表操作等。整个执行过程需要保证原子性，在数据被更新完毕前，不能有其他内核代码路径访问和改写这些数据。这个过程使用原子变量显得不合适，需要**锁机制**来完成，**自旋锁(spinlock**) 是 Linux内核中**最常见的锁机制**。

spinlock同一时刻只能被一个内核代码路径持有，如果有另外一个内核代码路径试图获取一个己经被持有的spinlock, 那么该**内核代码路径**需要一直**自旋忙等待**，直到锁持有者释放了该锁。如果该锁没有被别人持有（或争用，lock contention)，那么可以立即获得该锁。

spinlock锁的特性如下。

- **忙等待的锁机制**。操作系统中**锁的机制分为两类(！！！**)，一类是**忙等待**，另一类是**睡眠等待**。**spinlock**属于前者，当无法获取spinlock锁时会**不断尝试**，直到获取锁为止。
-  **同一时刻**只能有**一个内核代码路径**可以获得该锁。
- 要求spinlock锁**持有者尽快完成临界区的执行任务**。如果临界区执行时间过长，在锁外面忙等待的CPU比较浪费，特别是spinlock**临界区里不能睡眠**。
- spinlock锁可以在****中断上下文中使用****。

# 1 spinlock实现

先看spinlock数据结构的定义。

```c
[include/linux/spinlock_types.h]
typedef struct spinlock {
	union {
		struct raw_spinlock rlock; //重点
	};
} spinlock_t;

typedef struct raw_spinlock {
	arch_spinlock_t raw_lock; // 重点
} raw_spinlock_t;

[arch/arm/include/asm/spinlock_types.h]
// ARM
typedef struct {
	union {
		u32 slock;
		struct __raw_tickets {
			u16 next;
			u16 owner;
		} tickets;
	};
} arch_spinlock_t;

[arch/x86/include/asm/spinlock_types.h]
// x86
#ifdef CONFIG_QUEUED_SPINLOCKS
#include <asm-generic/qspinlock_types.h>
#else
typedef struct arch_spinlock {
	union {
		__ticketpair_t head_tail;
		struct __raw_tickets {
			__ticket_t head, tail;
		} tickets;
	};
} arch_spinlock_t;
```

spinlock数据结构定义考虑到了**不同处理器体系结构**的支持和**实时性内核**（RT patches)的要求，定义了 **raw\_spinlock**和**arch\_spinlock\_t**数据结构，其中arch\_spinlock\_t数据结构和体系结构有关，下面给出ARM32架构上的实现。在 Linux 2.6.25之前，**spinlock数据结构**就是一个简单的**无符号类型变量**，slock值为1表示锁未被持有，值为0 或者负数表示锁被持有。**之前的spinlock机制实现比较简洁**，特别是在**没有锁争用**的情况下，但是也存在很多问题，特别是在**很多CPU争用同一个spinlock**时，会导致**严重的不公平性及性能下降**。当该锁释放时，事实上有可能**刚刚释放该锁的CPU(！！！CPU！！！**)马上又获得了该锁的**使用权**，或者说在**同一个NUMA节点**上的**CPU**都有可能**抢先获取了该锁**，而没有考虑那些己经在锁外面**等待了很久的CPU**。因为刚**刚释放锁的CPU的L1 cache中存储了该锁(！！！**)，它**比别的CPU更快获得锁**，这对于那些已经等待很久的CPU是不公平的。在**NUMA处理器**中，**锁争用**的情况会严重影响系统的性能。有测试表明，在一个2 socket的 8 核处理器中，spinlock争用情况愈发明显，有些线程甚至需要尝试1000000次才能获取锁。为此在LinuX 2.6.25内核后, **spinlock**实现了一套名为“**FIFO ticket\-based**”算法的spinlock机制，本文简称为**排队自旋锁**。

![config](./images/5.png)

ticket\-based的 spinlock仍然使用原来的数据结构，但**slock被拆分成两个部分(联合体实现！！！**)，如图4.1所示，**owner**表示**锁持有者**的**等号牌**，**next**表示外面排队**队列**中**末尾者**的**等号牌**。这类似于排队吃饭的场景，在用餐高峰时段，各大饭店人满为患，顾客来晚了都需要排队。为了模型简化，假设某个饭店只有一张饭桌，刚开市时，next和 owner都是0。

第一个客户A来时，因为**next和owner都是0**,说明**锁没有人持有**。此时因为饭馆还没有顾客，所以客户**A 的等号牌是0**, 直接进餐，这时**next\+\+(！！！**)。

第二个客户B来时，因为**next为1**，**owner为0**, 说明**锁被人持有**。这时服务员给他**1号的等号牌**，让他在饭店门口等待，**next++(！！！**)。

第三个客户C来了，因为**next为2**, **owner为0** , 服务员给他**2号的等号牌**，让他在饭店门口排队等待，**next++(！！！**)。

这时第一个客户**A吃完买单**了，**owner\+\+(！！！**)，**owner的值变为1**。服务员会让**等号牌**和**owner值相等**的客户就餐，客户B的等号牌是1 , 所以现在客户B就餐。有新客户来时next\+\+, 服务员分配等号牌；客户埋单时owner\+\+，服务员叫号，**owner值**和**等号牌相等**的客户就餐。

```c
[include/linux/spinlock.h]
static inline void spin_lock(spinlock_t *lock)
{
	raw_spin_lock(&lock->rlock);
}

static inline void __raw_spin_lock(raw_spinlock_t *lock)
{
	preempt_disable();   // 关内核抢占
	spin_acquire(&lock->dep_map, 0, 0, _RET_IP_);
	LOCK_CONTENDED(lock, do_raw_spin_trylock, do_raw_spin_lock);
}
```

**spin\_lock**()函数最终调用\_\_raw\_spin\_lock()函数来实现。首先**关闭内核抢占**，这是**spinlock锁的实现关键点之一**。那么为什么**spinlock临界区不允许发生抢占**呢？

如果**spinlock临界区**中**允许抢占**，那么如果**临界区内发生中断**，**中断返回**时会去**检查抢占调度**，这里有两个问题，一是**抢占调度相当于持有锁的进程睡眠**，违背了**spinlock锁不能睡眠**和**快速执行**完成的设计语义；二是**抢占调度进程**也有可能会去**申请spinlock锁**，那么会**导致发生死锁**。关于**中断返回时检查抢占调度**的相关内容可以参考第5.1.4节。

如果系统没有打开**CONFIG\_LOCKDEP**和**CONFIG\_LOCK\_STAT**选项，**spin\_acquire**()函数其实是一个空函数，并且**LOCK\_CONTENDED**()只是**直接调用do\_raw\_spin\_lock**()函数。

```c
void do_raw_spin_lock(raw_spinlock_t *lock)
{
	arch_spin_lock(&lock->raw_lock)
}
```

x86的arch\_spin\_lock()函数的实现.

```c
[arch/x86/include/asm/spinlock.h]
static __always_inline void arch_spin_lock(arch_spinlock_t *lock)
{
	register struct __raw_tickets inc = { .tail = TICKET_LOCK_INC };

	inc = xadd(&lock->tickets, inc);
	if (likely(inc.head == inc.tail))
		goto out;

	for (;;) {
		unsigned count = SPIN_THRESHOLD;

		do {
			inc.head = READ_ONCE(lock->tickets.head);
			if (__tickets_equal(inc.head, inc.tail))
				goto clear_slowpath;
			cpu_relax();
		} while (--count);
		__ticket_lock_spinning(lock, inc.tail);
	}
clear_slowpath:
	__ticket_check_and_clear_slowpath(lock, inc.head);
out:
	barrier();	/* make sure nothing creeps before the lock is taken */
}
```

下面来看ARM的arch\_spin\_lock()函数的实现。

```c
[arch/arm/include/asm/spinlock.h]
static inline void arch_spin_lock(arch_spinlock_t *lock)
{
	unsigned long tmp;
	u32 newval;
	arch_spinlock_t lockval;

	prefetchw(&lock->slock);
	__asm__ __volatile__(
"1:	ldrex	%0, [%3]\n"
"	add	%1, %0, %4\n"
"	strex	%2, %1, [%3]\n"
"	teq	%2, #0\n"
"	bne	1b"
	: "=&r" (lockval), "=&r" (newval), "=&r" (tmp)
	: "r" (&lock->slock), "I" (1 << TICKET_SHIFT)
	: "cc");
    // 位置1
	while (lockval.tickets.next != lockval.tickets.owner) {
		wfe();
		lockval.tickets.owner = ACCESS_ONCE(lock->tickets.owner);
	}

	smp_mb();
}
```

这是一段GCC嵌入式汇编，与前文中的atomic_add()函数类似。首先通过**ldrex指令**把**lock->slock**的值加载到**变量lockval**中，lockval中的**next域加1**，并且**保存到newval变量**中，然后把**newval值**写入到**lock->slock**中，也就是**增加锁中next域的值**，即next\+\+。此时lockval是原有的lock的内容.

位置1，判断变量**lockval中的next域**和**owner域是否相等**，如果**不相等**，则调用**wfe指令**让**CPU进入等待状态**。当有**其他CPU唤醒本CPU**时，说明该**spinlock锁的owner域发生了变化**，即**有人释放了该锁**；当**新owner域**的值和**next相等**时，即**owner**等于**该CPU持有的等号牌(lockval.next**)时，说明**该CPU成功获取了spinlock锁(以CPU为单位！！！**)，arch\_spin\_lock()函数返回。

下面来说明ARM体系结构中的wfe指令。ARM体系结构中的WFI(Wait for interrupt)和WFE(Wait for event)指令都是让ARM核进入standby睡眠模式。WFI是直到有WFI唤醒事件发生才会唤醒CPU, WFE是直到有WFE唤醒事件发生，这两类事件大部分相同，唯一不同在于WFE可以被其他CPU上的SEV指令唤醒，SEV指令用于修改Event寄存器的指令。

下面来看释放spinlock的arch\_spin\_imlock()函数的实现。

```c
static inline void arch_spin_unlock(arch_spinlock_t *lock)
{
	smp_mb();
	lock->tickets.owner++;
	dsb_sev();
}
```

**arch\_spin\_unlock**()函数实现比较简单，首先调用smp\_mb()**内存屏障指令**，在ARM中smp\_mb()函数也是调用dmb指令来保证把**调用该函数之前所有的访问内存指令都执行完成**，然后给**lock\->owner域加1(！！！**)。最后调用dsb\_sev()函数，该函数有两个作用，一个是**调用dsb指令**保证**owner域己经写入内存**中，二是执行**SEV指令**来**唤醒**通过WFE指令进入**睡眠状态的CPU**。

# 2 spinlock变种

在**驱动代码**编写过程中常常会遇到这样一个问题，假设某个驱动程序中有一个**链表a\_driver\_list**，在驱动中很多操作都需要**访问和更新该链表**，例如open、ioctl等。因此**操作链表的地方**就是一个**临界区**，需要**spinlock来保护**。当处于**临界区**时发生了**外部硬件中断**, 此时系统**暂停当前进程的执行**而转去**处理该中断**。假设**中断处理程序**恰巧也要**操作该链表**，链表的操作是一个**临界区**，所以在**操作之前**要调用**spin\_lock**()函数来**对该链表进行保护**。**中断处理函数**试图去**获取该spinlock**，但因为它己经被别人持有了，于是导致**中断处理函数**进入**忙等待状态**或者**WFE睡眠状态**。

在**中断上下文**出现**忙等待或者睡眠状态**是**致命的**，中断处理程序要求“短”和“快”，锁的持有者因为被中断打断而不能尽快释放锁，而中断处理程序一直在忙等待锁，从而导致死锁的发生。Linux内核的spinlock的变种**spin\_lock\_irq()函数**在获取**spinlock**时**关闭本地CPU中断**，可以解决该问题。

```c
[include/linux/spinlock.h]
static inline void spin_lock_irq(spinlock_t *lock)
{
	raw_spin_lock_irq(&lock->rlock);
}

[include/linux/spinlock_api_smp.h]
static inline void __raw_spin_lock_irq(raw_spinlock_t *lock)
{
	local_irq_disable();
	preempt_disable();
	do_raw_spin_lock();
}
```

spin\_lock\_irq()函数的实现比spin\_lock()函数多了一个**local\_irq\_disable()函数**，该函数用于关闭本地处理器中断，这样在获取spinlock锁时可以**确保不会发生中断**，从而避免发生死锁问题，因此spin\_lock\_irq()主要防止本地中断处理程序和持有锁者之间存在锁的争用。可能有的读者会有疑问，既然**关闭了本地CPU的中断**，那么**别的CPU**依然可以**响应外部中断**，会不会也有可能死锁？**持有锁者在CPU0**上，**CPU1**响应了外部中断且中断处理函数也同样试图去获取该锁，因为**CPU0上的锁持有者**也在继续**执行**，所以它很快会离开临界区释放了锁，这样CPU1上的中断处理函数可以很快获得该锁。

在上述场景中，如果**CPU0**在**临界区**中发生了**进程切换**，会是什么情况？注意**进入spinlock之前**己经显式地**调用preempt\_disable()关闭了抢占**，因此**内核不会主动发生抢占**。但令人担心的是，驱动编写者**主动调用睡眠函数**，从而**发生了调度**。

使用spinlock的重要原则是：**拥有spinlock锁**的**临界区代码**必须是**原子执行**，**不能休眠和主动调度(！！！**)。但在实际工程中，驱动代码编写者却常常容易犯错误。例如调用分配内存函数kmalloc()时，就有可能因为系统空闲内存不足而睡眠等待，除非显式地使用GFP\_ATOMIC分配掩码。

**spin\_lock\_irqsave**()函数会**保存本地CPU当前的irq状态**并且**关闭本地CPU中断**，然后获取spinlock锁。**local\_irq\_save**()函数在**关闭本地CPU中断前**把**CPU当前的中断状态保存到flags变量**中；在调用**local\_irq\_restore**()函数时把**flags值恢复到相关寄存器**中，例如ARM的CPSR寄存器中，这样做的目的是防止破坏掉中断响应的状态。

spinlock还有另外一个常用的变种**spin\_lock\_bh**()函数，用于处理**进程和延迟处理机制**导致的**并发访问的互斥问题**。

# 3 spinlock和raw\_spin\_lock

有的代码中使用了spin\_lock()，而有的代码使用raw\_spin\_lock()，并且发现spin\_lock()直接调用raw\_spin\_lock()，读者可能会有困惑。

这要从Linux内核的实时补丁RT\-patch说起，**实时补丁**旨在提升**Linux内核的实时性**,它允许在**spinlock锁的临界区**内**被抢占**，且**临界区内允许进程睡眠等待**，这样会导致**spinlock语义被修改**。当时内核中大约有10000多处使用了spinlock，直接修改spinlock的工作量巨大，但是可以修改那些真正不允许抢占和休眠的地方，大概有100多处，因此改为使用raw\_spin\_lock。spinlock和raw\_spin\_lock的区别在于：

- 在**绝对不允许被抢占和睡眠的临界区**，应该使用**raw\_spin\_lock**，否则使用**spinlock**。

因此对于**没有打上RT\-patch**的Linux内核来说，spin\_lock()直接调用raw\_spin\_lock();对于打上了**RT\-patch的Linux内核**，spinlock变成**可抢占和睡眠的锁(！！！**)，这一点需要特别注意。

# 4 总结

**spinlock**主要针对**数据操作集合的临界区**, 临界区是**一个变量**, **原子变量**可以解决. 抢到锁的**进程不能睡眠**, 并要**快速执行**(这是spinlock的**设计语义**).

"FIFO ticket\-based算法": 

锁由slock(和\<next, owner\>组成union)构成

- 获取锁: CPU先领ticket(当前next值), 然后锁的next加1, owner等于ticket, CPU获得锁, 返回, 否则循环忙等待
- 释放锁: 锁的owner加1

获取锁接口(这里只提这两个):

- spin\_lock(): 关内核抢占, 循环抢锁, 但来中断(中断会抢占所有)可能导致死锁
- spin\_lock\_irq(): 关本地中断, 关内核抢占(内核不会主动抢占), 循环抢锁

spin\_lock()和raw\_spin\_lock():

- 在绝对不允许被抢占和睡眠的临界区，使用raw\_spin\_lock
- Linux实时补丁spin\_lock()允许**临界区抢占**和**进程睡眠**, 否则spin\_lock()直接调用raw\_spin\_lock()

spin\_lock特点:

- 忙等待, 不断尝试
- **同一时刻只能有一个获得**
- spinlock临界区尽快完成, 不能睡眠
- 可以在中断上下文使用