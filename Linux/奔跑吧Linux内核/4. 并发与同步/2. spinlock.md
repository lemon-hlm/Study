[TOC]

本章思考题

- 为什么spinlock的临界区不能睡眠（不考虑RT\-Linux的情况）？
- Linux内核中经典spinlock的实现有什么缺点？
- 为什么spinlock临界区不允许发生抢占？
- Ticket-based的 spinlock机制是如何实现的？
- 如果在spin\_lock()和spin\_unlock()的临界区中发全了中断，并且中断处理程序也恰巧修改了该临界资源，那么会发生什么后果？该如何避免呢？

# 0 概述

如果**临界区**只是**一个变量**，那么**原子变量**可以解决问题，但是**临界区大多**是一个**数据操作的集合**，例如先从一个数据结构中移出数据，对其进行数据解析，然后再写回到该数据结构或者其他数据结构中，类 似 “read->modify->write”操作；再比如临界区是一个链表操作等。整个执行过程需要保证原子性，在数据被更新完毕前，不能有其他内核代码路径访问和改写这些数据。这个过程使用原子变量显得不合适，需要**锁机制**来完成，**自旋锁(spinlock**) 是 Linux内核中**最常见的锁机制**。

spinlock同一时刻只能被一个内核代码路径持有，如果有另外一个内核代码路径试图获取一个己经被持有的spinlock, 那么该**内核代码路径**需要一直**自旋忙等待**，直到锁持有者释放了该锁。如果该锁没有被别人持有（或争用，lock contention)，那么可以立即获得该锁。

spinlock锁的特性如下。

- **忙等待的锁机制**。操作系统中**锁的机制分为两类(！！！**)，一类是**忙等待**，另一类是**睡眠等待**。spinlock属于前者，当无法获取spinlock锁时会**不断尝试**，直到获取锁为止。
-  **同一时刻**只能有**一个内核代码路径**可以获得该锁。
- 要求spinlock锁**持有者尽快完成临界区的执行任务**。如果临界区执行时间过长，在锁外面忙等待的CPU比较浪费，特别是spinlock**临界区里不能睡眠**。
- spinlock锁可以在****中断上下文中使用****。

# 1 spinlock实现

先看spinlock数据结构的定义。

```c
[include/linux/spinlock_types.h]
typedef struct raw_spinlock {
	arch_spinlock_t raw_lock; // 重点
} raw_spinlock_t;


typedef struct spinlock {
	union {
		struct raw_spinlock rlock; //重点

#ifdef CONFIG_DEBUG_LOCK_ALLOC
# define LOCK_PADSIZE (offsetof(struct raw_spinlock, dep_map))
		struct {
			u8 __padding[LOCK_PADSIZE];
			struct lockdep_map dep_map;
		};
#endif
	};
} spinlock_t;

[arch/arm/include/asm/spinlock_types.h]
// ARM
typedef struct {
	union {
		u32 slock;
		struct __raw_tickets {
			u16 next;
			u16 owner;
		} tickets;
	};
} arch_spinlock_t;

[arch/x86/include/asm/spinlock_types.h]
// x86
#ifdef CONFIG_QUEUED_SPINLOCKS
#include <asm-generic/qspinlock_types.h>
#else
typedef struct arch_spinlock {
	union {
		__ticketpair_t head_tail;
		struct __raw_tickets {
			__ticket_t head, tail;
		} tickets;
	};
} arch_spinlock_t;
```

spinlock数据结构定义考虑到了**不同处理器体系结构**的支持和**实时性内核**（RT patches)的要求，定义了 **raw\_spinlock**和**arch\_spinlock\_t**数据结构，其中arch\_spinlock\_t数据结构和体系结构有关，下面给出ARM32架构上的实现。在 Linux 2.6.25之前，**spinlock数据结构**就是一个简单的**无符号类型变量**，slock值为1表示锁未被持有，值为0 或者负数表示锁被持有。**之前的spinlock机制实现比较简洁**，特别是在**没有锁争用**的情况下，但是也存在很多问题，特别是在**很多CPU争用同一个spinlock**时，会导致**严重的不公平性及性能下降**。当该锁释放时，事实上有可能**刚刚释放该锁的CPU(！！！CPU！！！**)马上又获得了该锁的**使用权**，或者说在**同一个NUMA节点**上的**CPU**都有可能**抢先获取了该锁**，而没有考虑那些己经在锁外面**等待了很久的CPU**。因为刚**刚释放锁的CPU的L1 cache中存储了该锁(！！！**)，它**比别的CPU更快获得锁**，这对于那些已经等待很久的CPU是不公平的。在**NUMA处理器**中，锁争用的情况会严重影响系统的性能。有测试表明，在一个2 socket的 8 核处理器中，spinlock争用情况愈发明显，有些线程甚至需要尝试1000000次才能获取锁。为此在LinuX 2.6.25内核后, spinlock实现了一套名为“FIFO ticket-based”算法的spinlock机制1，本文简称为排队自旋锁。