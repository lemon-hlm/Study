- 1 原子操作
- 2 内存屏障

思考题:

1. 在ARM处理器中，如何实现独占访问内存？
2. atomic\_cmpxchg()和 atomic\_xchg()分别表示什么含义？

# 1 原子操作

原子操作是指保证**指令以原子的方式执行**，执行过程不会被打断。如下, 假设线程A和线程B都尝试进行操作，请问线程A和B函数执行完后，i的值是多少？

```c++
static int i =0;
//线程 A 函数
void thread_A_func()
{
    i++;
}

// 线程B函数

void thread_A_func()
{
    i++;
}
```

可能是2, 也可能不是.

![config](./images/1.png)

上面执行看, 最终可能等于1. 变量i是一个临界资源, CPU0和CPU1都可能同时访问, 发生并发访问. 从CPU角度看, 变量i是静态全局变量存储在数据段中, 首先读取变量值到通用寄存器中, 然后在通用寄存器里做i\+\+运算, 最后将寄存器数值写回变量i所在内存中. 多处理器架构中, 上述动作可能同时. 若**线程B函数**在某个**中断处理**函数中, **单处理器架构**上仍然可能会发生并发访问.

上述例子, 使用加锁方式, 比如spinlock保证i\+\+操作的原子性, 但加锁开销较大, 这里浪费. Linux提供了**atomic\_t类型的原子变量**, 该实现依赖不同的体系结构. atomic\_t类型的具体定义为:

```c
[include/linux/types.h]
typedef struct {
	int counter;
} atomic_t;
```

Linux提供了很多**原子变量操作函数**.

```c
[include/asm-generic/atomic.h]

#define ATOMIC_INIT(i) 声明一个原子变量并初始化为 i
#define atomic_read(v) 读取原子变量的值
#define atomic_set(v,i ) 设置变量v的值为i
#define atomic_inc(v)  原子地给v加1
#define atomic_dec(v)  原子地给v减1
#define atomic_add(i,v) 原子地给v增加 i
#define atomic_inc_and_test (v) 原子地给v加1 ， 结果为0 返回 true，否则返回false
#define atomic_dec_and_test(v) 原子地给v减1，结果为 0 返回 true，否则返回false
#define atomic_inc_return(v) 原子地给 v 加 1 并且返回最新 v 的值
#define atomic_dec_return(v) 原子地给 v 减 1 并且返回最新 v 的值
#define atomic_add_negative(i,v) 给原子变量 v 增加 i ， 然后判断 v 的最新值是否为负数
#define atoinic_cmpxchg(v, old, new) 比较old和原子变量v的值，如果相等则把new赋值给 V， 返回原子变量v的旧值
#define atomic_xchg(v, new) 把new赋值给原子变量v， 返回原子变量v的旧值
```

上面函数在内核中很常见, 特别是对一些引用计数进行操作，例如struct page的\_count和\_mapcount引用计数。atomic\_cmpxchg()和atomic_xchg()在**MCS锁**的实现中起到非常重要的作用。

x86中实现atomic\_add()函数. 带**lock前缀**的**指令执行前**会**完成之前的读写**操作.

```c
/**
 * atomic_add - add integer to atomic variable
 * @i: integer value to add
 * @v: pointer of type atomic_t
 *
 * Atomically adds @i to @v.
 */
static inline void atomic_add(int i, atomic_t *v)
{
	asm volatile(LOCK_PREFIX "addl %1,%0"
		     : "+m" (v->counter)
		     : "ir" (i));
}
```
```
/* Atomic operations are already serializing on x86 */
#define smp_mb__before_atomic_dec()	barrier()
#define smp_mb__after_atomic_dec()	barrier()
#define smp_mb__before_atomic_inc()	barrier()
#define smp_mb__after_atomic_inc()	barrier()
```

**x86**的**atomic操作**大多使用**原子指令**或者**带lock前缀**的指令。带lock前缀的**指令执行前**会**完成之前的读写操作**，对于**原子操作**来说不会受之前对同一位置的读写操作，所以这里只是用**空操作barrier()代替**。barrier()的作用相当于告诉编译器这里有一个**内存屏障**，**放弃在寄存器中的暂存值**，重新**从内存中读入**。

下面来看在ARM32架构中如何实现atomic\_add()函数。

```c++
#define ATOMIC_OP(op, c_op, asm_op)					\
static inline void atomic_##op(int i, atomic_t *v)			\
{									\
	unsigned long tmp;						\
	int result;							\
									\
	prefetchw(&v->counter);						\
	__asm__ __volatile__("@ atomic_" #op "\n"			\
"1:	ldrex	%0, [%3]\n"						\
"	" #asm_op "	%0, %0, %4\n"					\
"	strex	%1, %0, [%3]\n"						\
"	teq	%1, #0\n"						\
"	bne	1b"							\
	: "=&r" (result), "=&r" (tmp), "+Qo" (v->counter)		\
	: "r" (&v->counter), "Ir" (i)					\
	: "cc");							\
}

static inline void atomic_add(int i, atomic_t *v)			\
{									\
	unsigned long tmp;						\
	int result;							\
									\
	prefetchw(&v->counter);						\
	__asm__ __volatile__("@ atomic_add "\n"			\
"1:	ldrex	%0, [%3]\n"						\
"	add	%0, %0, %4\n"					\
"	strex	%1, %0, [%3]\n"						\
"	teq	%1, #0\n"						\
"	bne	1b"							\
	: "=&r" (result), "=&r" (tmp), "+Qo" (v->counter)		\
	: "r" (&v->counter), "Ir" (i)					\
	: "cc");							\
}
```

**ARM**使用**ldrex**和**strex指令**来保证add操作的原子性，指令后缀ex表示exclusive。这两条指令的格式如下。

```assembly
ldrex Rt, [Rn]      ;把Rn寄存器指向内存地址的内容加载到Rt寄存器中
strex Rd, Rt, [Rn]  ;把Rt寄存器的值保存到Rn寄存器指向的内存地址中，Rd保存更新的结果，0表示更新成功，1表示失败。
```

**ARM**处理器核心中有**Local monitor**和 Global monitor来实现ldrex和strex指令的独占访问。第5行代码，**prefetchw**提前把**原子变量的值**加载到**cache**中，以便提高性能。第 6〜14行代码，**GCC嵌入式汇编**，GCC嵌入式汇编的格式如下。

```assembly
__asm__ __volatile__(指令部：输出部：输入部：损坏部)
```

GCC嵌入汇编在处理**变量和寄存器**的问题上提供了一个模板和一些约束条件。在**指令部**中**数字加上前缀**%，例如%0、%1等 ，表示需要**使用寄存器**的样板操作数。指令部用到几个不同的操作数就说明有几个变量需要和寄存器结合。指令部后面的**输出部**，用于规定**对输出变量的约束条件**。每个输出约束(constraint)通常以号开头，接着是一个字母表示对操作数类型的说明，然后是关于变量结合的约束。

例如%0操作数对应"=&r" (result) , 指的是函数里的**result变量**。其中“&”表示该操作符只能用作输出，“= ”表示该操作符只写。％1操作数对应"=&r"(tmp), 指的是函数里的tmp变量. %2操作数是"+Qo"(v->counter),指的是原子变量v->counter，“+ ’’表示该操作符具有可读可写属性。“r”表示使用一个通用寄存器。

**输入部**有两个操作数，％3操作数对应"r"(&v->counter), 指的是原子变量v->counter的地址，％4操作数对应”Ir"(i)，指的是函数的参数i。

**损坏部**一般以“**memory**”结束。“memory”告诉**GCC**编译器**内嵌汇编指令改变了内存中的值**，强迫编译器在**执行该汇编代码前存储所有缓存的值**，在**执行完汇编代码之后重新加载该值**，目的是**防止编译乱序**。“cc”表示condition register, **状态寄存器标志位**。

第6行代码，\_\_volatile\_\_**防止编译器优化**。其中"@"符号标识是**注释**。这里首先使用ldrex指令把原子变量v->counter的值加载到result变量中，然后在result变量中增加i值，使用strex指令把result变量的值存放到原子变量v->counter中，其中变量tmp保存着strex指令更新后的结果。最后比较该结果是否为0 , 为 0 则表示strex指令更新成功。如果不为0 , 那么跳转到标签“1”处重新再来一次。

ARM GCC嵌入式操作符和修饰符如表4.1所示。

![config](./images/2.png)

# 2 内存屏障

程序在运行时的**实际内存访问顺序**和**程序代码编写的访问顺序**不一致，会导致**内存乱序访问**。内存乱序访问的出现是为了提高**程序运行时的性能**。

**内存乱序访问**主要发生在如下两个阶段。

（1）编译时，**编译器优化**导致内存乱序访问。

（2）运行时，**多CPU间**交互引起的内存乱序访问。

编译器了解底层CPU的思维逻辑，因此它会在翻译成汇编时进行优化。例如内存访问指令的重新排序，提高指令级并行效率。然而，这些优化可能会违背程序员原始的代码逻辑，导致发生一些错误。编译时的乱序访问可以通过barrier()函数来规避。

```
#define barrier() __asm__ __volatile__ ("" ::: "memory")
```

barrier()函数告诉编译器，不要为了性能优化而将这些代码重排.

第1章中己经介绍过ARM体系结构中的如下3 条内存屏障指令。

- **数据存储**屏障**DMB(Data Memory Barrier**)。

**数据存储器隔离**。DMB指令保证：仅当所有在它前面的**存储器访问操作(存取**)都执行完毕后，才**提交**（commit）在它后面的**存取访问操作指令**。当位于此指令前的所有内存访问均完成时，DMB指令才会完成。

- **数据同步**屏障**DSB(Data Synchronization Barrier**)。

**数据同步隔离**。比DMB要严格一些，仅当所有在它前面的**存储访问操作指令**都执行完毕后，才会**执行**在它后面的指令，即**任何指令都要等待DSB前面的存储访问完成**。位于**此指令前**的**所有缓存**，如**分支预测**和**TLB**（**Translation Look\-aside Buffer**）维护操作全部完成。

- **指令同步**屏障**ISB(Instruction Synchronization Barrier**)。

**指令同步隔离**。它最严格，**冲洗流水线（Flush Pipeline**）和**预取buffers（pretcLbuffers**）后，才会从**cache**或者**内存**中**预取ISB 指令之后的指令(！！！**)。**ISB通常用来保证上下文切换的效果(！！！**)，例如更改ASID（Address Space Identifier）、TLB 维护操作和 C15 寄存器的修改等。

下面来介绍Linux内核中的**内存屏障接口函数**，如表4.2所示。

![config](./images/3.png)

在x86 Linux中内存屏障函数实现如下.

```c
[arch/x86/include/asm/barrier.h]

#ifdef CONFIG_X86_32 // 32位

#define mb() alternative("lock; addl $0,0(%%esp)", "mfence", X86_FEATURE_XMM2)
#define rmb() alternative("lock; addl $0,0(%%esp)", "lfence", X86_FEATURE_XMM2)
#define wmb() alternative("lock; addl $0,0(%%esp)", "sfence", X86_FEATURE_XMM)

#else               // 64位
#define mb() 	asm volatile("mfence" ::: "memory")
#define rmb()	asm volatile("lfence" ::: "memory")
#define wmb()	asm volatile("sfence" ::: "memory")
#endif

#ifdef CONFIG_X86_PPRO_FENCE
#define dma_rmb()	rmb()      // DMA读内存屏障, 读操作
#else
#define dma_rmb()	barrier()  // DMA读内存屏障, 不让重排
#endif

#define dma_wmb()	barrier()  // DMA写内存屏障, 不让重排

#ifdef CONFIG_SMP
#define smp_mb()	mb()        // SMP屏障, 读写操作
#define smp_rmb()	dma_rmb()   // SMP读内存屏障, DMA的读内存屏障
#define smp_wmb()	barrier()   // SMP写屏障, 不让重排
#define set_mb(var, value) do { (void)xchg(&var, value); } while (0)

#else /* !SMP */
#define smp_mb()	barrier()
#define smp_rmb()	barrier()
#define smp_wmb()	barrier()
#define set_mb(var, value) do { var = value; barrier(); } while (0)
#endif /* SMP */
```

sfence: 在**sfence指令前**的**写操作**当必须在**sfence指令后**的**写操作前完成**。 
lfence：在**lfence指令前**的**读操作**当必须在**lfence指令后**的**读操作前完成**。 
mfence：在**mfence指令前**的**读写操作**当必须在**mfence指令后**的**读写操作前完成**。

在**ARM** Linux中内存屏障函数实现如下.

```c
[arch/arm/include/asm/barrier.h]

#ifdef CONFIG_ARCH_HAS_BARRIERS
#include <mach/barriers.h>
#elif defined(CONFIG_ARM_DMA_MEM_BUFFERABLE) || defined(CONFIG_SMP)

#define mb()		do { dsb(); outer_sync(); } while (0)  //读写内存屏障, 数据同步屏障指令
#define rmb()		dsb()     // 读内存屏障, 数据同步屏障指令
#define wmb()		do { dsb(st); outer_sync(); } while (0)   //写内存屏障, 数据同步屏障指令
#define dma_rmb()	dmb(osh)  // DMA读内存屏障, 数据存储屏障指令, 也就是读操作的
#define dma_wmb()	dmb(oshst) // DMA写内存屏障, 数据存储屏障指令

#else

#define mb()		barrier()
#define rmb()		barrier()
#define wmb()		barrier()
#define dma_rmb()	barrier()
#define dma_wmb()	barrier()

#endif

#ifndef CONFIG_SMP

#define smp_mb()	barrier()
#define smp_rmb()	barrier()
#define smp_wmb()	barrier()

#else

#define smp_mb()	dmb(ish)
#define smp_rmb()	smp_mb()
#define smp_wmb()	dmb(ishst)

#endif
```

在 Linux内核中有很多使用内存屏障指令的例子，下面举两个例子来介绍。

例 1: 一个**网卡驱动**中**发送数据包**。**网络数据包**写入**buffer**后交给**DMA引擎负责发送**，**wmb**()保证在**DMA传输之前(！！！**)，数据被**完全写入到buffer**中。

```c
[drivers\net\ethernet\realtek\8139too.c]

static netdev_tx_t rtl8139_start_xmit (struct sk_buff *skb,
					     struct net_device *dev)
{
	skb_copy_and_csum_dev(skb, tp->tx_buf[entry]);
	/*
	 * Writing to TxStatus triggers a DMA transfer of the data
	 * copied to tp->tx_buf[entry] above. Use a memory barrier
	 * to make sure that the device sees the updated data.
	 */
	wmb();  // 写内存屏障
	RTL_W32_F (TxStatus0 + (entry * sizeof (u32)),
		   tp->tx_flag | max(len, (unsigned int)ETH_ZLEN));
	...
}
```

例 2: Linux内核里面的**睡眠和唤醒API**也运用了**内存屏障指令**，通常一个**进程**因为**等待某些事件**需要**睡眠**，例如调用wait\_even()。**睡眠者代码片段(！！！**)如下：

```c
for (;;) {
    set_current_state(TASK_UNINTERRUPTIBLE);
    if (event_indicated)
        break;
    schedule();
}
```

其中，**set\_current\_state**()在**修改进程的状态**时隐含插入了**内存屏障函数smp\_mb**()。

```c
[include/linux/sched.h]
#define set_current_state(state_value)  \
    set_mb(current->state, (state_value))

[arch/arm/include/asm/barrier.h]
#define set_mb(var, value)  do { var = value; smp_mb(); } while (0)
```

唤醒者通常会调用wake\_up()，在**修改task状态之前**也隐含地插入内存屏障函数smp\_wmb()。

```c
[wake_up() -> autoremove_wake_function() -> try_to_wake_up()]
wake_up(): kernel/sched/wait.c
try_to_wake_up(): kernel/sched/core.c

static int
try_to_wake_up(struct task_struct *p, unsigned int state, int wake_flags)
{
	/*
	 * If we are going to wake up a thread waiting for CONDITION we
	 * need to ensure that CONDITION=1 done by the caller can not be
	 * reordered with p->state check below. This pairs with mb() in
	 * set_current_state() the waiting thread does.
	 */
	smp_rmb();  // 读屏障, DMB数据存储屏障指令

	return success;
}
```

在**SMP**的情况下来观察**睡眠者**和**唤醒者**之间的关系如下。

![config](./images/4.png)

- **睡眠者**：**CPU1**在**更改当前进程current\->state**后，插入一个**内存屏障指令**，保证**加载唤醒标记**load event\_indicated**不会出现**在**修改current\->state之前**。
- **唤醒者**：CPU2在**store唤醒标记操作**和把**进程状态修改成RUNNING的store操作**之间插入了**写屏障**，保证**唤醒标记event indicated的修改**能被**其他CPU看到(！！！**)。