## 一、RCU有什么用？

RCU主要用于对性能要求苛刻的并行实时计算。例如：天气预报、模拟核爆炸计算、内核同步等等。

假设你正在编写一个并行实时程序，该程序需要访问随时变化的数据。这些数据可能是随着温度、湿度的变化而逐渐变化的大气压。这个程序的实时响应要求是如此严格，需要处理的数据量如此巨大，以至于不允许任何自旋或者阻塞，因此不能使用任何锁。

幸运的是，温度和压力的范围通常变化不大，因此使用默认的数据集也是可行的。当温度、湿度和压力抖动时，有必要使用实时数据。但是温度、湿度和压力是逐渐变化的，我们可以在几分钟内更新数据，但没必要实时更新值。

在这种情况下，可以使用一个全局指针，即gptr，通常为NULL，表示要使用默认值。偶尔也可以将gptr指向假设命名为a、b和c的变量，以反映气压的变化。

传统的软件可以使用自旋锁这样的同步机制，来保护gptr指针的读写。一旦旧的值不被使用，就可以将旧指针指向的数据释放。这种简单的方法有一个最大的问题：它会使软件效率下降数个数量级（注意，不是下降数倍而是下降数个数量级）。

在现代计算系统中，向gptr写入a、b、c这样的值，并发的读者要么看到一个NULL指针要么看到指向新结构gptr的指针，不会看到中间结果。也就是说，对于指针赋值来说，某种意义上这种赋值是原子的。读者不会看到a、b、c之外的其他结果。并且，更好的一点，也是更重要的一点是：读者不需要使用任何代价高昂的同步原语，因此这种方法非常适合于实时使用。

真正的难点在于：在读者获得gptr的引用时，它可能看到a、b、c这三个值中任意一个值，写者何时才能安全的释放a、b、c所指向的内存数据结构？

引用计数的方案很有诱惑力，但正如锁和顺序锁一样，引用计数可能消耗掉数百个CPU指令周期，更致命的是，它会引用缓存行在CPU之间的来回颠簸，破坏各个CPU的缓存，引起系统整体性能的下降。很明显，这种选择不是我们所期望的。

想要理解Linux经典RCU实现的读者，应当认真阅读下面这段话：

一种实现方法是，写者完全不知道有哪些读者存在。这种方法显然让读者的性能最佳，但留给写者的问题是：如何才能确定所有的老读者已经完成。

最简单的实现是：让线程不会被抢占，或者说，读者在读RCU数据期间不能被抢占。在这种不可抢占的环境中，每个线程将一直运行，直到它明确地和自愿地阻塞自己（现实世界确实有这样的操作系统，它由线程自己决定何时释放CPU。例如大名鼎鼎的Solaris操作系统）。这要求一个不能阻塞的无限循环将使该CPU在循环开始后无法用于任何其他目的，还要求还要求线程在持有自旋锁时禁止阻塞。否则会形成死锁。

这种方法的示意图下所示，图中的时间从顶部推移到底部，CPU 1的list_del()操作是RCU写者操作，CPU2、CPU3在读端读取list节点。

![config](images/12.png)

Linux经典RCU的概念即是如此。虽然这种方法在生产环境上的实现可能相当复杂，但是玩具实现却非常简单。

```
for_each_online_cpu(cpu)
run_on(cpu);
```

for\_each\_online\_cpu()原语遍历所有CPU，run\_on()函数导致当前线程在指定的CPU上执行，这会强制目标CPU执行上下文切换。因此，一旦for\_each\_online\_cpu()完成，每个CPU都执行了一次上下文切换，这又保证了所有之前存在的读线程已经完成。

请注意，这个方法不能用于生产环境。正确处理各种边界条件和对性能优化的强烈要求意味着用于生产环境的代码实现将十分复杂。此外，可抢占环境的RCU实现需要读者实际做点什么事情（也就是在读临界区内，禁止抢占。这是Linux经典RCU读锁的实现）。不过，这种简单的不可抢占的方法在概念上是完整的，有助于我们理解RCU的基本原理。

## 二、RCU是什么？

RCU是read-copy-update的简称，翻译为中文有点别扭“读-复制-更新”。它是是一种同步机制，有三种角色或者操作：读者、写者和复制操作，我理解其中的复制操作就是不同CPU上的读者复制了不同的数据值，或者说拥有同一个指针的不同拷贝值，也可以理解为：在读者读取值的时候，写者复制并替换其内容（后一种理解来自于RCU作者的解释）。它于2002年10月引入Linux内核。

RCU允许读操作可以与更新操作并发执行，这一点提升了程序的可扩展性。常规的互斥锁让并发线程互斥执行，并不关心该线程是读者还是写者，而读/写锁在没有写者时允许并发的读者，相比于这些常规锁操作，RCU在维护对象的多个版本时确保读操作保持一致，同时保证只有所有当前读端临界区都执行完毕后才释放对象。RCU定义并使用了高效并且易于扩展的机制，用来发布和读取对象的新版本，还用于延后旧版本对象的垃圾收集工作。这些机制恰当地在读端和更新端并行工作，使得读端特别快速。在某些场合下（比如非抢占式内核里），RCU读端的函数完全是零开销。

Seqlock也可以让读者和写者并发执行，但是二者有什么区别？

首先是二者的目的不一样。Seqlock是为了保证读端在读取值的时候，写者没有对它进行修改，而RCU是为了多核扩展性。

其次是保护的数据结构大小不一样。Seqlock可以保护一组相关联的数据，而RCU只能保护指针这样的unsigned long类型的数据。

最重要的区别还在于效率，Seqlock本质上是与自旋锁同等重量级的原语，其效率与RCU不在同一个数量级上面。

下面从三个基础机制来阐述RCU究竟是什么？

RCU由三种基础机制构成，第一个机制用于插入，第二个用于删除，第三个用于让读者可以不受并发的插入和删除干扰。分别是：

发布/订阅机制，用于插入。

等待已有的RCU读者完成的机制，用于删除。

维护对象多个版本的机制，以允许并发的插入和删除操作。

### 1、发布/订阅机制

RCU的一个关键特性是可以安全的读取数据，即使数据此时正被修改。RCU通过一种发布/订阅机制达成了并发的数据插入。举个例子，假设初始值为NULL的全局指针gp现在被赋值指向一个刚分配并初始化的数据结构。如下所示的代码片段：

```
struct foo  {
    int a;
    int b;
    int c;
};
 
struct foo  *gp  = NULL;
 
/* .  .  .  */  
 
p =  kmalloc(sizeof(*p),  GFP_KERNEL);
p->a =  1;  
p->b =  2;  
p->c =  3;  
gp  =  p;
```

“发布”数据结构（不安全）

不幸的是，这块代码无法保证编译器和CPU会按照编程顺序执行最后4条赋值语句。如果对gp的赋值发生在初始化p的各字段之前，那么并发的读者会读到未初始化的值。这里需要内存屏障来保证事情按顺序发生，可是内存屏障又向来以难用而闻名。所以这里我们用一句rcu\_assign\_ pointer()原语将内存屏障封装起来，让其拥有发布的语义。最后4行代码如下。

