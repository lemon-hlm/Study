[TOC]

- 1 前言
- 2 用户将一个work挂入workqueue
    - 2.1 queue\_work\_on函数
    - 2.2 \_\_WQ\_DRAINING的解释
    - 2.3 选择pool workqueue
    - 2.4 选择worker thread pool
    - 2.5 选择work挂入的队列
    - 2.6 唤醒idle的worker来处理该work
- 3 线程池如何创建worker线程？
    - 3.1 per cpu worker pool什么时候创建worker线程？
    - 3.2 unbound thread pool什么时候创建worker线程？
    - 3.3 如何创建worker
- 4 work的处理
    - 4.1 PF\_WQ\_WORKER标记
    - 4.2 管理线程池中的线程
    - 4.3 worker线程开始处理work

# 1 前言

本文主要讲述下面两部分的内容：

1、将work挂入workqueue的处理过程

2、如何处理挂入workqueue的work

# 2 用户将一个work挂入workqueue

## 2.1 queue\_work\_on函数

使用workqueue机制的模块可以调用queue\_work\_on（有其他变种的接口，这里略过，其实思路是一致的）将一个定义好的work挂入workqueue，具体代码如下：

```c
bool queue_work_on(int cpu, struct workqueue_struct *wq, struct work_struct *work) 
{ 
    ……

    if (!test_and_set_bit(WORK_STRUCT_PENDING_BIT, work_data_bits(work))) { 
        __queue_work(cpu, wq, work);－－－挂入work list并通知worker thread pool来处理 
        ret = true; 
    }

    …… 
}
```

work\_struct的data member中的WORK\_STRUCT\_PENDING\_BIT这个bit标识了该work是处于pending状态还是正在处理中，pending状态的work只会挂入一次。大部分的逻辑都是在\_\_queue\_work函数中，下面的小节都是描述该函数的执行过程。

## 2.2 \_\_WQ\_DRAINING的解释

\_\_queue\_work函数一开始会校验\_\_WQ\_DRAINING这个flag，如下：

```c
if (unlikely(wq->flags & __WQ_DRAINING) && WARN_ON_ONCE(!is_chained_work(wq))) 
        return;
```

\_\_WQ\_DRAINING这个flag表示该workqueue正在进行draining的操作，这多半是发送在销毁workqueue的时候，既然要销毁，那么挂入该workqueue的所有的work都要处理完毕，才允许它消亡。当想要将一个workqueue中所有的work都清空的时候，如果还有work挂入怎么办？一般而言，这时候当然是不允许新的work挂入了，毕竟现在的目标是清空workqueue中的work。但是有一种特例（通过is\_chained\_work判定），也就是正在清空的work（隶属于该workqueue）又触发了一个queue work的操作（也就是所谓chained work），这时候该work允许挂入。

## 2.3 选择pool workqueue

```c
if (req_cpu == WORK_CPU_UNBOUND) 
        cpu = raw_smp_processor_id();

if (!(wq->flags & WQ_UNBOUND)) 
        pwq = per_cpu_ptr(wq->cpu_pwqs, cpu); 
    else 
        pwq = unbound_pwq_by_node(wq, cpu_to_node(cpu));
```

WORK\_CPU\_UNBOUND表示并不指定cpu，这时候，选择当前代码运行的那个cpu了。一旦确定了cpu了，对于非unbound的workqueue，当然使用per cpu的pool workqueue。如果是unbound的workqueue，那么要根据numa node id来选择。cpu\_to\_node可以从cpu id获取node id。需要注意的是：这里选择的pool wq只是备选的，可能用也可能不用，它有可能会被替换掉，具体参考下一节描述。

## 2.4 选择worker thread pool

与其说挂入workqueue，不如说挂入worker thread pool，因为毕竟是线程池来处理具体的work。pool\_workqueue有一个相关联的worker thread pool（struct pool\_workqueue的pool成员），因此看起来选择了pool wq也就选定了worker pool了，但是，不是当前选定的那个pool wq对应的worker pool就适合该work，因为有时候该work可能正在其他的worker thread上执行中，在这种情况下，为了确保work的callback function不会重入，该work最好还是挂在那个worker thread pool上，具体代码如下：

```c
last_pool = get_work_pool(work); 
    if (last_pool && last_pool != pwq->pool) { 
        struct worker *worker;

        spin_lock(&last_pool->lock);

        worker = find_worker_executing_work(last_pool, work);

        if (worker && worker->current_pwq->wq == wq) { 
            pwq = worker->current_pwq; 
        } else { 
            /* meh... not running there, queue here */ 
            spin_unlock(&last_pool->lock); 
            spin_lock(&pwq->pool->lock); 
        } 
    } else { 
        spin_lock(&pwq->pool->lock); 
    }
```

last\_pool记录了上一次该work是被哪一个worker pool处理的，如果last\_pool就是pool wq对应的worker pool，那么皆大欢喜，否则只能使用last pool了。使用last pool的例子比较复杂一些，因为这时候需要根据last worker pool找到对应的pool workqueue。find\_worker\_executing\_work函数可以找到具体哪一个worker线程正在处理该work，如果没有找到，那么还是使用第3节中选定的pool wq吧，否则，选择该worker线程当前的那个pool workqueue（其实也就是选定了线程池）。

## 2.5 选择work挂入的队列

队列有两个，一个是被推迟执行的队列（pwq->delayed_works），一个是线程池要处理的队列（pwq->pool->worklist），如果挂入线程池要处理的队列，也就意味着该work进入active状态，线程池会立刻启动处理流程，如果挂入推迟执行的队列，那么该work还是pending状态：

```c
    pwq->nr_in_flight[pwq->work_color]++; 
    work_flags = work_color_to_flags(pwq->work_color);

    if (likely(pwq->nr_active < pwq->max_active)) { 
        pwq->nr_active++; 
        worklist = &pwq->pool->worklist; 
    } else { 
        work_flags |= WORK_STRUCT_DELAYED; 
        worklist = &pwq->delayed_works; 
    }

    insert_work(pwq, work, worklist, work_flags);
```

具体的挂入队列的动作是在insert_work函数中完成的。

## 2.6 唤醒idle的worker来处理该work

在insert\_work函数中有下面的代码：

```c
if (__need_more_worker(pool)) 
        wake_up_worker(pool);
```

当线程池中正在运行状态的worker线程数目等于0的时候，说明需要wakeup线程池中处于idle状态的的worker线程来处理work。

# 3 线程池如何创建worker线程？

## 3.1 per cpu worker pool什么时候创建worker线程？

对于per\-CPU workqueue，每个cpu有两个线程池，一个是normal，一个是high priority的。在初始化函数init\_workqueues中有对这两个线程池的初始化：

```c
for_each_online_cpu(cpu) { 
    struct worker_pool *pool;

    for_each_cpu_worker_pool(pool, cpu) { 
        pool->flags &= ~POOL_DISASSOCIATED; 
        BUG_ON(!create_worker(pool)); 
    } 
}
```

因此，在系统初始化的时候，per cpu workqueue共享的那些线程池（2 x cpu nr）就会通过create_worker创建一个initial worker。

一旦initial worker启动，该线程会执行worker_thread函数来处理work，在处理过程中，如果有需要， worker会创建新的线程。

## 3.2 unbound thread pool什么时候创建worker线程？

我们先看看unbound thread pool的建立，和per-CPU不同的是unbound thread pool是全局共享的，因此，每当创建不同属性的unbound workqueue的时候，都需要创建pool\_workqueue及其对应的worker pool，这时候就会调用get\_unbound\_pool函数在当前系统中现存的线程池中找是否有匹配的worker pool，如果没有就需要创建新的线程池。在创建新的线程池之后，会立刻调用create\_worker创建一个initial worker。和per cpu worker pool一样，一旦initial worker启动，随着work不断的挂入以及worker处理work的具体情况，线程池会动态创建worker。

## 3.3 如何创建worker

代码如下：

```c
static struct worker *create_worker(struct worker_pool *pool) 
{ 
    struct worker *worker = NULL; 
    int id = -1; 
    char id_buf[16];

    id = ida_simple_get(&pool->worker_ida, 0, 0, GFP_KERNEL);－－－－分配ID

    worker = alloc_worker(pool->node);－－－－－分配worker struct的内存

    worker->pool = pool; 
    worker->id = id;

    if (pool->cpu >= 0)－－－－－－－－－worker的名字 
        snprintf(id_buf, sizeof(id_buf), "%d:%d%s", pool->cpu, id,  pool->attrs->nice < 0  ? "H" : ""); 
    else 
        snprintf(id_buf, sizeof(id_buf), "u%d:%d", pool->id, id);

worker->task = kthread_create_on_node(worker_thread, worker, pool->node,   "kworker/%s", id_buf);

    set_user_nice(worker->task, pool->attrs->nice); －－－创建task并设定nice value 
    worker->task->flags |= PF_NO_SETAFFINITY;  
    worker_attach_to_pool(worker, pool); －－－－－建立worker和线程池的关系

    spin_lock_irq(&pool->lock); 
    worker->pool->nr_workers++; 
    worker_enter_idle(worker); 
    wake_up_process(worker->task);－－－－－－让worker运行起来 
    spin_unlock_irq(&pool->lock);

    return worker; 
}
```

代码不复杂，通过线程池（struct worker\_pool）绑定的cpu信息（struct worker\_pool的cpu成员）可以知道该pool是per-CPU还是unbound，对于per\-CPU线程池，pool\->cpu是大于等于0的。对于对于per-CPU线程池，其worker线程的名字是kworker/cpu：worker id，如果是high priority的，后面还跟着一个H字符。对于unbound线程池，其worker线程的名字是kworker/u pool id：worker id。

# 4 work的处理

本章主要描述worker\_thread函数的执行流程，部分代码有删节，保留主干部分。

## 4.1 PF\_WQ\_WORKER标记

worker线程函数一开始就会通过PF\_WQ\_WORKER来标注自己：

```c
worker->task->flags |= PF_WQ_WORKER;
```

有了这样一个flag，调度器在调度当前进程sleep的时候可以检查这个准备sleep的进程是否是一个worker线程，如果是的话，那么调度器不能鲁莽的调度到其他的进程，这时候，还需要找到该worker对应的线程池，唤醒一个idle的worker线程。通过workqueue模块和调度器模块的交互，当work A被阻塞后（处理该work的worker线程进入sleep），调度器会唤醒其他的worker线程来处理其他的work B，work C……

## 4.2 管理线程池中的线程

```c
recheck: 
    if (!need_more_worker(pool)) 
        goto sleep;

    if (unlikely(!may_start_working(pool)) && manage_workers(worker)) 
        goto recheck;
```

如何判断是否需要创建更多的worker线程呢？原则如下：

（1）有事情做：挂在worker pool中的work list不能是空的，如果是空的，那么当然sleep就好了

（2）比较忙：worker pool的nr\_running成员表示线程池中当前正在干活（running状态）的worker线程有多少个，当nr\_running等于0表示所有的worker线程在处理work的时候阻塞了，这时候，必须要启动新的worker线程来处理worker pool上处于active状态的work链表上的work们。

## 4.3 worker线程开始处理work

```c
worker_clr_flags(worker, WORKER_PREP | WORKER_REBOUND);

do { 
    struct work_struct *work =   list_first_entry(&pool->worklist,  struct work_struct, entry);

    if (likely(!(*work_data_bits(work) & WORK_STRUCT_LINKED))) { 
        process_one_work(worker, work); 
        if (unlikely(!list_empty(&worker->scheduled))) 
            process_scheduled_works(worker); 
    } else { 
        move_linked_works(work, &worker->scheduled, NULL); 
        process_scheduled_works(worker); 
    } 
} while (keep_working(pool));

worker_set_flags(worker, WORKER_PREP);
```

按理说worker线程处理work应该比较简单，从线程池的worklist中取一个work，然后调用process\_one\_work处理之就OK了，不过现实稍微复杂一些，work和work之间并不是独立的，也就是说，work A和work B可能是linked work，这些linked work应该被一个worker来处理。WORK\_STRUCT\_LINKED标记了work是属于linked work，如果是linked work，worker并不直接处理，而是将其挂入scheduled work list，然后调用process\_scheduled\_works来处理。毫无疑问，process\_scheduled\_works也是调用process\_one_work来处理一个一个scheduled work list上的work。

scheduled work list并非仅仅应用在linked work，在worker处理work的时候，有一个原则要保证：同一个work不能被同一个cpu上的多个worker同时执行。这时候，如果worker发现自己要处理的work正在被另外一个worker线程处理，那么本worker线程将不处理该work，只需要挂入正在执行该work的worker线程的scheduled work list即可。