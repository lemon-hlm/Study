随着互联网的发展，面对海量用户高并发业务，传统的阻塞式的服务端架构模式已经无能为力。为大家提供有用的高性能网络编程的I/O模型概览以及网络服务进程模型的比较，以揭开设计和实现高性能网络架构的神秘面纱。

# 1 互联网服务端处理网络请求的原理

首先看看一个**典型互联网服务端处理网络请求**的典型过程。由图可以看到，主要处理步骤包括：

![config](./images/1.jpeg)

由上图可以看到，主要处理步骤包括： 

1. 获取请求数据，客户端与服务器建立连接发出请求，服务器接受请求（1-3）；
2. 构建响应，当服务器接收完请求，并在用户空间处理客户端的请求，直到构建响应完成（4）；
3. 返回数据，服务器将已构建好的响应再通过内核空间的网络 I/O 发还给客户端（5-7）。

设计**服务端并发模型**时，主要有如下**两个关键点**： 

1. 服务器如何管理连接，获取输入数据；
2. 服务器如何处理请求。

以上两个关键点最终都与操作系统的 I/O 模型以及线程(进程)模型相关，这也是本文和下篇《高性能网络编程(六)：一文读懂高性能网络编程中的线程模型》将要介绍的内容。下面先详细介绍这I/O模型。

# 2 “I/O 模型”的基本认识

介绍操作系统的 I/O 模型之前，先了解一下几个概念： 

1) **阻塞调用**与**非阻塞调用**；
2) **阻塞调用**是指调**用结果返回之前**，**当前线程会被挂起**，调用线程只有在得到结果之后才会返回；
3) 非阻塞调用指在不能立刻得到结果之前，该**调用不会阻塞当前线程**。

两者的最大区别在于**被调用方**在**收到请求到返回结果之前的这段时间**内，**调用方是否一直在等待**。

阻塞是指调用方一直在等待而且别的事情什么都不做；非阻塞是指调用方先去忙别的事情。

**同步处理与异步处理**：**同步处理**是指**被调用方得到最终结果之后**才**返回给调用方**；**异步处理**是指**被调用方先返回应答**，然后**再计算调用结果**，计算完**最终结果后再通知并返回给调用方**。

阻塞、非阻塞和同步、异步的区别（阻塞、非阻塞和同步、异步其实针对的对象是不一样的）：

1) **阻塞**、**非阻塞**的讨论对象是**调用者**；
2) **同步**、**异步**的讨论对象是**被调用者**。

**recvfrom 函数**：

recvfrom 函数(经 Socket 接收数据)，这里把它视为系统调用。

一个输入操作通常包括两个不同的阶段：

1）等待数据准备好；
2）从内核向进程复制数据。

对于一个套接字上的输入操作，第一步通常涉及等待数据从网络中到达。当所等待分组到达时，它被复制到内核中的某个缓冲区。第二步就是把数据从内核缓冲区复制到应用进程缓冲区。

实际应用程序在系统调用完成上面的 2 步操作时，调用方式的阻塞、非阻塞，操作系统在处理应用程序请求时，处理方式的同步、异步处理的不同，可以分为 5 种 I/O 模型（下面的章节将逐个展开介绍）。（参考《[UNIX网络编程卷1]()》）

