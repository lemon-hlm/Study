随着互联网的发展，面对海量用户高并发业务，传统的阻塞式的服务端架构模式已经无能为力。为大家提供有用的高性能网络编程的I/O模型概览以及网络服务进程模型的比较，以揭开设计和实现高性能网络架构的神秘面纱。

# 1 互联网服务端处理网络请求的原理

首先看看一个**典型互联网服务端处理网络请求**的典型过程。由图可以看到，主要处理步骤包括：

![config](./images/1.jpeg)

由上图可以看到，主要处理步骤包括： 

1. 获取请求数据，客户端与服务器建立连接发出请求，服务器接受请求（1-3）；
2. 构建响应，当服务器接收完请求，并在用户空间处理客户端的请求，直到构建响应完成（4）；
3. 返回数据，服务器将已构建好的响应再通过内核空间的网络 I/O 发还给客户端（5-7）。

设计**服务端并发模型**时，主要有如下**两个关键点**： 

1. 服务器如何管理连接，获取输入数据；
2. 服务器如何处理请求。

以上两个关键点最终都与操作系统的 I/O 模型以及线程(进程)模型相关，这也是本文和下篇《高性能网络编程(六)：一文读懂高性能网络编程中的线程模型》将要介绍的内容。下面先详细介绍这I/O模型。

# 2 “I/O 模型”的基本认识

介绍操作系统的 I/O 模型之前，先了解一下几个概念： 

1) **阻塞调用**与**非阻塞调用**；
2) **阻塞调用**是指调**用结果返回之前**，**当前线程会被挂起**，调用线程只有在得到结果之后才会返回；
3) 非阻塞调用指在不能立刻得到结果之前，该**调用不会阻塞当前线程**。

两者的最大区别在于**被调用方**在**收到请求到返回结果之前的这段时间**内，**调用方是否一直在等待**。

阻塞是指调用方一直在等待而且别的事情什么都不做；非阻塞是指调用方先去忙别的事情。

**同步处理与异步处理**：**同步处理**是指**被调用方得到最终结果之后**才**返回给调用方**；**异步处理**是指**被调用方先返回应答**，然后**再计算调用结果**，计算完**最终结果后再通知并返回给调用方**。

阻塞、非阻塞和同步、异步的区别（阻塞、非阻塞和同步、异步其实针对的对象是不一样的）：

1) **阻塞**、**非阻塞**的讨论对象是**调用者**；
2) **同步**、**异步**的讨论对象是**被调用者**。

**recvfrom 函数**：

recvfrom 函数(经 Socket 接收数据)，这里把它视为**系统调用**。

一个输入操作通常包括两个不同的阶段：

1）等待数据准备好；
2）从内核向进程复制数据。

对于一个应用程序**套接字上的输入操作**，第一步通常涉及**等待数据从网络中到达**。当所等待分组到达时，它被复制到内核中的某个缓冲区。第二步就是把数据从**内核缓冲区**复制到**应用进程缓冲区**。

实际应用程序在系统调用完成上面的 2 步操作时，**调用方式**的**阻塞**、**非阻塞**，操作系统在处理应用程序请求时，**处理方式的同步**、**异步**处理的不同，可以分为 5 种 I/O 模型（下面的章节将逐个展开介绍）。（参考《[UNIX网络编程卷1]()》）

# 3 I/O模型1: 阻塞式I/O模型(blocking I/O)

![config](./images/2.jpeg)

在阻塞式 I/O 模型中，应用程序在从调用 recvfrom 开始到它返回有数据报准备好这段时间是阻塞的，recvfrom 返回成功后，应用进程开始处理数据报。

比喻：一个人在钓鱼，当没鱼上钩时，就坐在岸边一直等。

优点：程序简单，在阻塞等待数据期间进程/线程挂起，基本不会占用 CPU 资源。

缺点：每个连接需要独立的进程/线程单独处理，当并发请求量大时为了维护程序，内存、线程切换开销较大，这种模型在实际生产中很少使用。

# 4 I/O模型2：非阻塞式 I/O 模型(non-blocking I/O

![config](./images/3.jpeg)

在非阻塞式 I/O 模型中，应用程序把一个套接口设置为非阻塞，就是告诉内核，当所请求的 I/O 操作无法完成时，不要将进程睡眠。

而是返回一个错误，应用程序基于 I/O 操作函数将不断的轮询数据是否已经准备好，如果没有准备好，继续轮询，直到数据准备好为止。

比喻：边钓鱼边玩手机，隔会再看看有没有鱼上钩，有的话就迅速拉杆。

优点：不会阻塞在内核的等待数据过程，每次发起的 I/O 请求可以立即返回，不用阻塞等待，实时性较好。

缺点：轮询将会不断地询问内核，这将占用大量的 CPU 时间，系统资源利用率较低，所以一般 Web 服务器不使用这种 I/O 模型。

# 5 