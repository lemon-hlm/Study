
<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

* [0 概述](#0-概述)
* [1 多队列网卡](#1-多队列网卡)
* [2 SR\-IOV](#2-sr-iov)
* [3 其它](#3-其它)

<!-- /code_chunk_output -->

# 0 概述

I/O设备的性能是影响虚拟化方案性能的一个重要因素, 尤其是网络设备和存储设备. 由于数据中心中的存储设备往往也是通过网络共享, 如SAN和iSCSI等, 因此I/O设备的性能问题也就主要是网络设备的性能问题, 智能设备也主要指网络智能设备.

**传统的基于软件的设备共享方案**由**虚拟机监控器**为**上层虚拟机**提供**虚拟的I/O设备**, 如**基于设备模型的完全虚拟化仿真设备**和**采用前后端分离设备模型的类虚拟化**. 基于软件的设备模型都是通过虚拟机监控器对客户机I/O操作的介入来实现将物理资源在多台客户机间实现共享, 如对仿真设备I/O读写的捕捉和仿真, 以及对分离式设备中I/O读写的递推等. 由于存在虚拟机监控器的介入, 基于软件的设备共享必定会对系统的整体性能产生负面的影响, 例如Xen虚拟化平台上基于仿真的Intel E1000网卡的传输带宽性能大概只有真是硬件能力的十几分之一; 类虚拟化下的虚拟网络设备的性能通常较仿真设备要好, 但对**万兆网卡也只能最多达1/3**, 并且这是牺牲大量CPU资源情况下取得的.

随着万兆网设备的普及以及数据中心对高速网络的需求, 基于软件的设备共享方法面临难以满足用户对设备性能需求的问题. 基于**IOMMU技术**的**完全硬件设备共享方案**, 如Intel VT\-d技术, 通过直接在**物理硬件层面**进行**设备虚拟**, 并将虚拟产生的PCI设备直接赋给客户机从而获得高性能的方法得到业界重视, 但是一台计算机中**可插入的PCI设备数目有限**, 而支持的虚拟机数目可能动态增加. 这也造成基于完全硬件的设备共享方案面临系统的**可扩展性问题**, 而且使用的物理硬件设备数量也直接关系到数据中心的建设和运转成本.

**智能设备**就是这样一种介于**基于软件的设备共享**和**基于完全硬件的设备共享**方案之间的**混合型解决方案**, 其具体形式可以有多种多样, 但他们都具有利用**在硬件功能减少虚拟机监控器介入**的同时, 又**不完全摒弃虚拟机监控器辅助**的共同特点. 

智能设备可以是**基于公开的工业规范实现**, 也可以是一家**公司独享的私有方案**. 其中, 比较有代表性的实现有使用**多队列(Multi Queue)的网卡**、**PCI SIG**的Single Root IO Virtualization(**SR\-IOV**)和SolarFlare公司的10G网卡等.

# 1 多队列网卡

**多队列技术**已经在今天的原生操作系统得到广泛应用, 如Linux操作系统在2.6.24版本的内核中就引入了该项技术. 它利用**硬件！！！提供的多个网络包发送队列和接受队列特性**, 将**重要进程的网络操作！！！** 直接**绑定到一个或多个网络包处理队列！！！**上, 从而由硬件保证网络带宽.

如图9\-5, 一个典型的**多队列网卡**具有**硬件网络包分发功能！！！**, 可以基于**不同的策略**将收到的**包**分发给**不同的队列**, **每个队列**可以有**独立的DMA引擎**, 以及**独立的中断资源**. 这意味着拥有**独立队列**的**客户机**在**网络包处理过程中**可以**减少虚拟机监控器的介入**, 从而实现网络I/O的高性能, 例如Intel的VMDq网卡.

![](./images/2019-05-06-16-39-07.png)

# 2 SR\-IOV

PCI SIG制定了由PCIe设备硬件支持的I/O虚拟化方案(I/O Virtualization, IOV). IOV分为单根PCI桥IOV(Single Root IOV, SR\-IOV)和多根PCI桥IOV(Multi\-Root IOV, MR\-IOV). SR\-IOV的1.0标准已经发布.

支持SR\-IOV的设备硬件具有**一个或多个物理功能模块**(Physical Function, PF)如图9\-6, **每个功能模块**可以有**一个或多个虚拟功能模块**(Virtual Funciton, VF)与之关联.

![](./images/2019-05-06-16-51-27.png)

在SR\-IOV中, **每个VF**都具有**独立！！！的运行所需要的资源**, 如**中断寄存器**、**DMA引擎**和**I/O寄存器**等, 并且可以**被绑定到指定的客户机**. **一个虚拟功能模块**对客户机来说就如同一个传统的**PCIe设备**, 具有一个PCI总线中**唯一的BDF识别号**, 这也是虚拟功能模块上DMA操作时硬件用来作为向PCIe总线发送访问请求时的识别号. **客户机**可以访问**虚拟功能模块的PCI配置空间**, 但是不同于基于完全硬件的PCI设备共享, 对**虚拟功能模块的PCI配置空间访问**必须存在**虚拟监控器的介入！！！**. 因为虚拟功能模块的PCI配置空间中的寄存器一部分可以**直接来自物理功能模块**, 且为**防止虚拟功能模块间**在设置上的**相互干扰**, 这些寄存器一般被**设置为只读**; 而**另一部分寄存器**可以完全由**虚拟机监控器辅助仿真实现**. 在SRIOV中, 物理功能模块用来控制跟物理设备相关的全局操作, 如链路控制、复位等。

为减少**DMA运行时虚拟机监控器的介入**, SR\-IOV设备需要进行地址转换, 将**客户机驱动程序！！！** 设置的**客户机物理地址！！！** 转换成**主机物理地址！！！**, 这一点与基于完全硬件的设备共享方案相同, 使用**IOMMU**完成. 为更好支持SRIOV设备的地址转换, PCIe规范还增加了由设备本身进行地址转换的支持, 这可以提高虚拟功能模块与虚拟功能模块间, 或者虚拟功能模块与其他PCIe设备间访问的效率, 使设备之间的访问不需要由IOMMU完成. 另外, 这种在PCIe设备上的内嵌TLB地址转换, 可以减少对IOMMU上TLB的压力, 从而进一步提高效率.

不同于多队列设备, SRIOV设备的DMA操作可以由IOMMU或设备内嵌TLB实现直接内存访问而不需要虚拟机监控器的介入. 因此, SRIOV设备具有比多队列设备更好地性能. 绑定到SRIOV设备上虚拟功能模块的客户机可以获得与绑定到基于完全硬件的共享设备的客户机在运行时接近的性能, 因为它们在运行时都不需要虚拟机监控器的介入. 两种方案间的不同主要表现在初始化及控制方式上, 绑定到虚拟功能模块的客户机不能直接访问PCI配置空间, 需要虚拟机监控器和物理功能模块等介入. 一个SRIOV的设备, 可以具有成百上千个虚拟功能模块, 因此比起基于完全硬件的方法具有更好地可扩展性.

# 3 其它

