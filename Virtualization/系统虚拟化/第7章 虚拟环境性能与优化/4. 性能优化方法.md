
<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

* [0 概述](#0-概述)
* [1 降低客户机退出事件发生频率](#1-降低客户机退出事件发生频率)
	* [1.1 硬件加速](#11-硬件加速)
	* [1.2 共享内存](#12-共享内存)
	* [1.3 影子页表](#13-影子页表)
	* [1.4 直接分配I/O](#14-直接分配io)
	* [1.5 批Hypercall](#15-批hypercall)
* [2 降低客户机退出事件处理时间](#2-降低客户机退出事件处理时间)
* [3 降低处理器利用率](#3-降低处理器利用率)

<!-- /code_chunk_output -->

# 0 概述

无论什么虚拟化技术, 相对于物理机而言, 处理器在Hypervisor上执行开销都将构成额外的虚拟化开销. 处理器在Hypervisor上执行的时间越长, 虚拟化开销越高, 虚拟环境的吞吐量和性能就越差, 反之则虚拟环境的性能越好. 

因此, 优化的重点就应该考虑如何降低这种额外开销. 

虚拟环境性能优化方法很多, 而且是具体问题具体分析. 下面归纳一些以往优化中常用方法, 供参考.

# 1 降低客户机退出事件发生频率

下面给出常见降低客户机退出事件频率的优化方法.

## 1.1 硬件加速

硬件虚拟化技术本身提供了对某些高频虚拟化事件的硬件加速支持, 充分利用这些硬件功能可降低客户机退出事件频率. 如打开影子TPR/CR8寄存器技术可减少甚至避免客户机TPR/CR8操作导致的客户机退出事件; 通过置位客户机异常位图可直接由硬件将客户机异常注入到客户机IDT中, 等等.

## 1.2 共享内存

客户机对于虚拟化资源的访问一般需要VMM的介入, 以便VMM以合理的虚拟化策略共享物理资源. 客户机和VMM间的共享内存可使客户机在不采用Hypercall服务请求的同时, 直接得到由Hypervisor预先存放在共享内存中的客户机虚拟化内容. 这种方法尤其适合客户机OS对虚拟资源的读取, 如VCPU的状态等, 这可以直接降低客户机退出事件发生的频率.

## 1.3 影子页表

对于采用影子页表的客户机, 如何有效构建影子页表以降低由影子页表引起的主机上页缺失是一个影响整体虚拟化性能很重要的因素, 也是一个研究热点. 

当然, 采用硬件技术EPT可大大降低客户机退出事件发生的频率.

## 1.4 直接分配I/O

客户机I/O操作引起的客户机退出是实现I/O资源共享的基本方法, 但对于直接分配设备的客户机, 则可以直接访问该设备资源, 包括I/O. 因此, 对于直接分配设备的客户机, 可通过修改该客户机VCPU的VMCS控制结构中的IO\_Bitmap, 使得这些设备的I/O操作引起的客户机退出被完全避免.

## 1.5 批Hypercall

Hypercall是类虚拟化OS向Hypervisor申请服务的基本方法, 它本身不可完全避免.

# 2 降低客户机退出事件处理时间

如何降低处理时间是一个挑战, 这同时也依赖开发者系统编程经验. 一些常用的技巧在这里也适用, 但同时也有一些和虚拟化相关的通用方法, 比如I/O的并行处理.

在采用设备模型仿真客户机设备情况下, 如IDE, 一个触发客户机IDE进行磁盘读写的端口访问可能需要等待很长时间直到设备模型完成对物理设备的操作(读或写), 这导致该VGPU的端口响应时间非常慢, 有时甚至是几十毫秒. 这样的处理方式在虚拟化环境下很导致很严重的延迟.

如果将这种同步处理方式改为异步方式, 就可以避免VCPU的等待时间.

具体流程如下:

VCPU发出的端口访问命令发送给设备模型后;

设备模型启动后台服务进程去响应对虚拟端口的操作;

前端设备模型则直接向VCPU返回操作完成的信号;

请求完成;

之后, 设备模型向VCPU发出中断请求表示数据准备完成.

如图7\-5.

![](./images/2019-04-17-22-24-23.png)

除了I/O并行处理, 还有非主动FP、非主动宿主机状态保存/恢复等, 可降低客户机退出事件处理时间.

# 3 降低处理器利用率

除了降低系统延迟外, VMM还必须尽可能降低对资源主要是处理器资源的利用. 否则, 当一定情况下, 特别是高负载情况下, 系统的资源如处理器就可能饱和从而限制吞吐量的提高. 

一个典型例子就是高速网络设备. 在Xen的类虚拟化网络驱动中, 提供网络服务的后端程序需要将物理网卡收到的网络包复制到客户机接收缓冲区, 这要利用大量的处理器资源, 并且最终会使物理网卡饱和