

<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

* [1 VT\-d概述](#1-vt-d概述)
	* [1.1 3种客户机设备类型](#11-3种客户机设备类型)
	* [1.2 VT\-d的硬件支持和软件使用](#12-vt-d的硬件支持和软件使用)
	* [1.3 VT\-d的3个缺点和解决方案](#13-vt-d的3个缺点和解决方案)
* [2 VFIO简介](#2-vfio简介)
	* [2.1 VFIO相对于pci\-stub的改进](#21-vfio相对于pci-stub的改进)
* [3 VT\-d环境配置](#3-vt-d环境配置)
	* [3.1 硬件支持和BIOS设置](#31-硬件支持和bios设置)
	* [3.2 宿主机内核的配置](#32-宿主机内核的配置)
		* [3.2.1 VT\-d相关内核编译选项以及启动参数](#321-vt-d相关内核编译选项以及启动参数)
		* [3.2.2 VFIO相关内核编译选项](#322-vfio相关内核编译选项)
		* [3.2.3 系统检查](#323-系统检查)
	* [3.3 在宿主机中隐藏设备](#33-在宿主机中隐藏设备)
	* [3.4 通过QEMU命令行分配设备给客户机](#34-通过qemu命令行分配设备给客户机)

<!-- /code_chunk_output -->

# 1 VT\-d概述

## 1.1 3种客户机设备类型

在QEMU/KVM中，**客户机可以使用的设备**大致可分为如下**3种类型**。

1）Emulated device：**QEMU纯软件模拟**的设备，比如\-device rt8139等。

2）virtio device：实现**VIRTIO API**的**半虚拟化驱动的设备**，比如\-device virtio\-net\-pci等。

3）PCI device assignment：**PCI设备直接分配**。

**模拟I/O设备**方式的优点是对硬件平台依赖性较低，可以方便地模拟一些流行的和较老久的设备，不需要宿主机和客户机的额外支持，因此**兼容性高**；而其缺点是I/O路径较长，VM-Exit次数很多，因此**性能较差**。一般适用于对I/O性能要求不高的场景，或者模拟一些老旧遗留（legacy）设备（如RTL8139的网卡）。

**virtio半虚拟化设备**方式的优点是实现了VIRTIO API，减少了VM\-Exit次数，提高了客户机I/O执行效率，比普通模拟I/O的**效率高很多**；而其缺点是需要客户机中与virtio相关驱动的支持（较老的系统默认没有自带这些驱动，Windows系统中需要额外手动安装virtio驱动），因此**兼容性较差**，而且I/O频繁时CPU使用率较高。

**PCI设备直接分配**（Device Assignment，或PCI pass\-through），它允许将宿主机中的物理PCI（或PCI\-E）设备直接分配给客户机完全使用，这正是本节要介绍的重点内容。兼具**高性能**和**高兼容性**.

## 1.2 VT\-d的硬件支持和软件使用

较新的**x86架构**的主要硬件平台（包括服务器级、桌面级）都已经支持设备直接分配，其中**Intel**定义的I/O虚拟化技术规范为“Intel(R)Virtualization Technology for Directed I/O”（**VT\-d**），而AMD的I/O虚拟化技术规范为“**AMD\-Vi**”（也叫作**IOMMU**）。

KVM虚拟机支持将宿主机中的**PCI**、**PCI\-E设备**附加到虚拟化的客户机. 在KVM中通过VT\-d技术使用一个PCI\-E网卡的系统架构示例如图6-12所示。

![](./images/2019-05-23-21-44-17.png)￼

运行在支持VT\-d平台上的QEMU/KVM，可以分配**网卡**、**磁盘控制器**、**USB控制器**、**VGA显卡**等供客户机**直接使用**。而为了设备分配的**安全性**，还需要**中断重映射（interrupt remapping！！！**）的支持。

尽管在使用**qemu命令**行进行设备分配时并**不直接检查中断重映射功能是否开启**，但是在通过**一些工具使用KVM时**（如**libvirt！！！**）默认**需要有中断重映射的功能支持**，才能使用VT\-d分配设备供客户机使用。

## 1.3 VT\-d的3个缺点和解决方案

不过，VT\-d也有自己的缺点，

- 一台服务器**主板上的空间比较有限**，允许添加的**PCI和PCI\-E设备是有限**的，如果一台宿主机上有较多数量的客户机，则很难向每台客户机都独立分配VT\-d的设备。

- 另外，大量使用VT\-d独立分配设备给客户机，导致硬件设备数量增加，这会增加**硬件投资成本**。

为了避免这两个缺点，可以考虑采用如下两个方案：

- 一是在一台**物理宿主机**上，仅对**I/O（如网络**）**性能要求较高**的**少数客户机**使用**VT\-d直接分配设备**（如网卡），而对**其余的客户机**使用**纯模拟（emulated**）或使用**virtio**，以达到多个客户机共享同一个设备的目的；
- 二是对于**网络I/O**的解决方法，可以选择**SR\-IOV**，使一个网卡产生多个独立的虚拟网卡，将每个虚拟网卡分别分配给一个客户机使用，这也正是后面6.2.5节要介绍的内容。

另外，**设备直接分配**还有一个**缺点**是，对于使用**VT\-d**直接分配了设备的客户机，其**动态迁移功能将会受限**，不过也可以用**热插拔**或**libvirt工具**等方式来缓解这个问题，详细内容将在8.1.5节介绍。

# 2 VFIO简介

在上一版中，VT\-d部分依然是以**pci\-stub模块**为例讲解的。

**Kernel 3.10**发布，**VFIO**正式被引入，取代了原来的pci\-stub的VT\-d方式。

## 2.1 VFIO相对于pci\-stub的改进

与Legacy KVM Device Assignment（使用**pci\-stub driver**）相比，VFIO（Virtual Function IO￼）最大的改进就是**隔离了设备之间的DMA和中断！！！**，以及对**IOMMU Group！！！的支持**，从而有了更好的安全性。

IOMMU Group可以认为是**对PCI设备的分组**，**每个group**里面的**设备**被视作**IOMMU可以操作的最小整体**；换句话说，**同一个IOMMU Group**里的设备￼**不可以分配给不同的客户机**。

在以前的Legacy KVM Device Assignment中，并不会检查这一点，而后面的操作却注定是失败的。新的VFIO会检查并及时报错。

另外，新的VFIO架构也做到了平台无关，有更好的可移植性。

本书后续就以VFIO为例讲解VT\-d。

# 3 VT\-d环境配置

在KVM中使用VT\-d技术进行设备直接分配，需要以下几方面的环境配置。

## 3.1 硬件支持和BIOS设置

目前市面上的**x86硬件平台**基本都**支持VT\-d**，包括服务器平台Xeon以及桌面级的酷睿系列。

除了在硬件平台层面对VT\-d支持之外，还需要在**BIOS将VT\-d功能打开**，使其处于“Enabled”状态。由于各个BIOS和硬件厂商的标识的区别，VT-d在BIOS中设置选项的名称也有所不同。笔者见到BIOS中VT-d设置选项一般为“Intel(R)VT for Directed I/O”或“Intel VT\-d”等，在图3-2中已经演示了在BIOS设置中打开VT-d选项的情况。

![2019-05-15-09-02-49.png](./images/2019-05-15-09-02-49.png)

## 3.2 宿主机内核的配置

在**宿主机系统**中，内核也需要配置相应的选项。

### 3.2.1 VT\-d相关内核编译选项以及启动参数

在RHEL 7自带的Kernel config中，也都已经使这些类似的配置**处于打开状态**。

```
CONFIG_GART_IOMMU=y         #AMD平台相关￼
# CONFIG_CALGARY_IOMMU is not set      #IBM平台相关￼
CONFIG_IOMMU_HELPER=y￼
CONFIG_VFIO_IOMMU_TYPE1=m￼
CONFIG_VFIO_NOIOMMU=y￼
CONFIG_IOMMU_API=y￼
CONFIG_IOMMU_SUPPORT=y￼
CONFIG_IOMMU_IOVA=y￼
CONFIG_AMD_IOMMU=y            #AMD平台的IOMMU设置￼
CONFIG_AMD_IOMMU_STATS=y￼
CONFIG_AMD_IOMMU_V2=m￼
CONFIG_INTEL_IOMMU=y         #Intel平台的VT-d设置￼
# CONFIG_INTEL_IOMMU_DEFAULT_ON is not set#Intel平台的VT-d是否默认打开。这里没有选上，需要在kernel boot parameter中加上“intel_iommu=on”￼
CONFIG_INTEL_IOMMU_FLOPPY_WA=y￼
# CONFIG_IOMMU_DEBUG is not set￼
# CONFIG_IOMMU_STRESS is not set
```

**CONFIG_INTEL\_IOMMU\_DEFAULT\_ON**, 表明的是Intel平台的**VT\-d是否默认打开**。这里没有选上，需要在**kernel boot parameter**中加上“**intel\_iommu=on**”

而在较旧的Linux内核（3.0版本及以下，如2.6.32版本）中，应该配置如下几个VT\-d相关的配置选项。

```
CONFIG_DMAR=y￼
# CONFIG_DMAR_DEFAULT_ON is not set   #本选项可设置为y，也可不设置￼
CONFIG_DMAR_FLOPPY_WA=y￼
CONFIG_INTR_REMAP=y
```

### 3.2.2 VFIO相关内核编译选项

另外，为了配合接下来的第3步设置（用于**隐藏设备**），还需要配置**vfio\-pci**这个内核模块，相关的内核配置选项如下。

在RHEL 7**默认内核**中，都将**CONFIG\_KVM\_VFIO配置为y**（直接编译到内核），其他的功能配置为模块（m）。

```
CONFIG_VFIO_IOMMU_TYPE1=m￼
CONFIG_VFIO=m￼
CONFIG_VFIO_NOIOMMU=y         #支持用户空间的VFIO框架￼
CONFIG_VFIO_PCI=m￼
# CONFIG_VFIO_PCI_VGA is not set      #这个是for显卡的VT-d￼
CONFIG_VFIO_PCI_MMAP=y￼
CONFIG_VFIO_PCI_INTX=y￼
CONFIG_KVM_VFIO=y
```

### 3.2.3 系统检查

在启动宿主机系统（这里需要手动修改grub）￼后，可以通过内核的打印信息来检查VT\-d是否处于打开可用状态，如下所示：

```
[root@kvm-host ~]# dmesg | grep -i dmar￼
[    0.000000] ACPI: DMAR 000000007b6a0000 00100 (v01 INTEL   S2600WT 00000001 INTL 20091013)￼
[    0.000000] DMAR: IOMMU enabled￼
[    0.303666] DMAR: Host address width 46￼
[    0.303670] DMAR: DRHD base: 0x000000fbffc000 flags: 0x0￼
[    0.303683] DMAR: dmar0: reg_base_addr fbffc000 ver 1:0 cap 8d2078c106f0466 ecap￼
     f020de￼
[    0.303686] DMAR: DRHD base: 0x000000c7ffc000 flags: 0x1￼
[    0.303696] DMAR: dmar1: reg_base_addr c7ffc000 ver 1:0 cap 8d2078c106f0466 ecap￼
     f020de￼
[    0.303699] DMAR: RMRR base: 0x0000007a3e3000 end: 0x0000007a3e5fff￼
[    0.303702] DMAR: ATSR flags: 0x0￼
[    0.303707] DMAR-IR: IOAPIC id 10 under DRHD base  0xfbffc000 IOMMU 0￼
[    0.303710] DMAR-IR: IOAPIC id 8 under DRHD base  0xc7ffc000 IOMMU 1￼
[    0.303713] DMAR-IR: IOAPIC id 9 under DRHD base  0xc7ffc000 IOMMU 1￼
[    0.303716] DMAR-IR: HPET id 0 under DRHD base 0xc7ffc000￼
[    0.303719] DMAR-IR: Queued invalidation will be enabled to support x2apic and ￼
     Intr-remapping.￼
[    0.304885] DMAR-IR: Enabled IRQ remapping in x2apic mode￼
[   36.384332] DMAR: dmar0: Using Queued invalidation￼
[   36.384603] DMAR: dmar1: Using Queued invalidation￼
[   36.384898] DMAR: Setting RMRR:￼
[   36.384965] DMAR: Setting identity map for device 0000:00:1a.0 [0x7a3e3000 - ￼
    0x7a3e5fff]￼
[   36.385067] DMAR: Setting identity map for device 0000:00:1d.0 [0x7a3e3000 - ￼
    0x7a3e5fff]￼
[   36.385140] DMAR: Prepare 0-16MiB unity mapping for LPC￼
[   36.385177] DMAR: Setting identity map for device 0000:00:1f.0 [0x0 - 0xffffff]￼
[   36.385221] DMAR: Intel(R) Virtualization Technology for Directed I/O￼
[root@kvm-host ~]# dmesg | grep -i iommu￼
...￼
[    0.000000] DMAR: IOMMU enabled￼
[    0.303707] DMAR-IR: IOAPIC id 10 under DRHD base  0xfbffc000 IOMMU 0￼
[    0.303710] DMAR-IR: IOAPIC id 8 under DRHD base  0xc7ffc000 IOMMU 1￼
[    0.303713] DMAR-IR: IOAPIC id 9 under DRHD base  0xc7ffc000 IOMMU 1￼
[   36.385596] iommu: Adding device 0000:ff:08.0 to group 0￼
[   36.385674] iommu: Adding device 0000:ff:08.2 to group 0￼
[   36.385751] iommu: Adding device 0000:ff:08.3 to group 0￼
[   36.386041] iommu: Adding device 0000:ff:09.0 to group 1￼
[   36.386119] iommu: Adding device 0000:ff:09.2 to group 1￼
[   36.386196] iommu: Adding device 0000:ff:09.3 to group 1￼
...（iommu grouping）￼
[   36.422115] iommu: Adding device 0000:80:05.2 to group 49￼
[   36.422257] iommu: Adding device 0000:80:05.4 to group 49
```

如果**只有“DMAR：IOMMU enabled”输出**，则需要**检查BIOS中VT\-d**是否已打开。

## 3.3 在宿主机中隐藏设备

使用vfio\_pci这个内核模块来对需要分配给客户机的设备进行隐藏

需要通过如下3步来隐藏一个设备。

1）加载**vfio\-pci驱动**（前面已提及将“**CONFIG\_VFIO\_PCI=m**”作为内核编译的配置选项），如下所示：

```
[root@gerrylee ~]# modprobe vfio_pci
[root@gerrylee ~]# lsmod | grep vfio_pci
vfio_pci               41268  0
vfio                   32657  2 vfio_iommu_type1,vfio_pci
irqbypass              13503  2 kvm,vfio_pci
[root@gerrylee ~]# ls /sys/bus/pci/drivers/vfio-pci/
bind  module  new_id  remove_id  uevent  unbind
```

如果**vfio\_pci**已**被编译到内核**而**不是作为module**，则**仅需最后一个命令**来检查/**sys/bus/pci/drivers/vfio\-pci**/目录是否存在即可。

2）查看**设备的vendor ID和device ID**，如下所示（假设此设备的BDF为03：10.3）：

```
[root@kvm-host ~]# lspci -s 03:10.3 -Dn￼
0000:03:10.3 0200: 8086:1520 (rev 01)
```

在上面lspci命令行中，

- \-D选项表示在输出信息中显示设备的domain，
- \-n选项表示用**数字的方式**显示设备的**vendor ID**和**device ID**，
- \-s选项表示仅显示后面指定的一个设备的信息。

在该命令的输出信息中，“0000：03：10.3”表示设备在**PCI/PCI\-E总线**中的具体位置，依次是设备的**domain**（0000）、**bus**（03）、**slot**（10）、**function**（3），其中domain的值一般为0（当机器有多个host bridge时，其取值范围是0~0xffff），bus的取值范围是0～0xff，slot取值范围是0～0x1f，function取值范围是0～0x7，其中后面3个值一般简称为BDF（即bus：device：function）。

在输出信息中，设备的**vendor ID**是“**8086**”（“8086”ID代表**Intel Corporation**），**device ID**是“1520”（代表**i350 VF**）。

3）**绑定设备到vfio\-pci驱动**，命令行操作如下所示。

查看它目前的驱动，如不是vfio\-pci，则解绑当前驱动，然后绑定到vfio\-pci上。

```
[root@kvm-host ~]# lspci -s 03:10.3 -k￼
03:10.3 Ethernet controller: Intel Corporation I350 Ethernet Controller Virtual Function (rev 01)￼
Subsystem: Intel Corporation Device 35c4￼
Kernel driver in use: igbvf￼
Kernel modules: igbvf￼

[root@kvm-host ~]# echo 0000:03:10.3 > /sys/bus/pci/drivers/igbvf/unbind￼

[root@kvm-host ~]# echo -n "8086 1520" > /sys/bus/pci/drivers/vfio-pci/new_id￼

[root@kvm-host ~]# lspci -s 03:10.3 -k￼
03:10.3 Ethernet controller: Intel Corporation I350 Ethernet Controller Virtual Function (rev 01)￼
Subsystem: Intel Corporation Device 35c4￼
Kernel driver in use: vfio-pci￼
Kernel modules: igbvf
```

在绑定前，用lspci命令查看BDF为03：10.3的设备使用的驱动是Intel的igbvf驱动，而绑定到vfio\_pci后，通过命令可以可查看到它目前使用的驱动是vfio\-pci而不是igbvf，其中lspci的 **\-k选项** 表示输出信息中显示**正在使用的驱动**和**内核中可以支持该设备的模块**。

而在客户机不需要使用该设备后，让宿主机使用该设备，则需要将其恢复到使用原本的驱动。

本节的**隐藏和恢复设备**，利用如下一个Shell脚本可以方便实现

```sh
#!/bin/bash￼
# A script to hide/unhide PCI/PCIe device for KVM  (using 'vfio-pci')￼
#set -x￼
hide_dev=0￼
unhide_dev=0￼
driver=0￼
￼
# check if the device exists￼
function dev_exist()￼
{￼
local line_num=$(lspci -s "$1" 2>/dev/null | wc -l)￼
if [ $line_num = 0 ]; then￼
    echo "Device $pcidev doesn't exists. Please check your system or your command line."￼
    exit 1￼
else￼
    return 0￼
fi￼
}￼
￼
# output a format "<domain>:<bus>:<slot>.<func>" (e.g. 0000:01:10.0) of device￼
function canon() ￼
{￼
f='expr "$1" : '.*\.\(.\)''￼
d='expr "$1" : ".*:\(.*\).$f"'￼
b='expr "$1" : "\(.*\):$d\.$f"'￼
￼
if [ 'expr "$d" : '..'' == 0 ]￼
then￼
    d=0$d￼
fi￼
if [ 'expr "$b" : '.*:'' != 0 ]￼
then￼
    p='expr "$b" : '\(.*\):''￼
    b='expr "$b" : '.*:\(.*\)''￼
else￼
    p=0000￼
fi￼
if [ 'expr "$b" : '..'' == 0 ]￼
then￼
    b=0$b￼
fi￼
echo $p:$b:$d.$f￼
}￼
￼
# output the device ID and vendor ID￼
function show_id() ￼
{￼
lspci -Dn -s "$1" | awk '{print $3}' | sed "s/:/ /" > /dev/null 2>&1￼
if [ $? -eq 0 ]; then￼
    lspci -Dn -s "$1" | awk '{print $3}' | sed "s/:/ /"￼
else￼
    echo "Can't find device id and vendor id for device $1"￼
    exit 1￼
fi￼
}￼
￼
# hide a device using 'vfio-pci' driver/module￼
function hide_pci()￼
{￼
local pre_driver=NULL￼
local pcidev=$(canon $1)￼
local pciid=$(show_id $pcidev)￼
￼
dev_exist $pcidev￼
￼
if [ -e /sys/bus/pci/drivers/vfio-pci ]; then￼
    pre_driver=$(basename $(readlink /sys/bus/pci/devices/"$pcidev"/driver))￼
    echo "Unbinding $pcidev from $pre_driver"￼
    echo -n "$pciid" > /sys/bus/pci/drivers/vfio-pci/new_id￼
    echo -n "$pcidev" > /sys/bus/pci/devices/"$pcidev"/driver/unbind￼
￼
fi￼
￼
echo "Binding $pcidev to vfio-pci"￼
echo -n "$pcidev" > /sys/bus/pci/drivers/vfio-pci/bind￼
return $?￼
}￼
￼
function unhide_pci() {￼
local driver=$2￼
local pcidev='canon $1'￼
local pciid='show_id $pcidev'￼
￼
if [ $driver != 0 -a ! -d /sys/bus/pci/drivers/$driver ]; then￼
    echo "No $driver interface under sys, return fail"￼
    exit 1￼
fi￼
￼
if [ -h /sys/bus/pci/devices/"$pcidev"/driver ]; then￼
    local tmpdriver='basename $(readlink /sys/bus/pci/devices/"$pcidev"/driver)'￼
    if [ "$tmpdriver" = "$driver" ]; then￼
        echo "$1 has been already bind with $driver, no need to unhide"￼
        exit 1￼
    elif [ "$tmpdriver" != "vfio-pci" ]; then￼
        echo "$1 is not bind with vfio-pci, it is bind with $tmpdriver, no need to unhide"￼
        exit 1￼
    else￼
        echo "Unbinding $pcidev from" $(basename $(readlink /sys/bus/pci/devices/"$pcidev"/driver))￼
        echo -n "$pcidev" > /sys/bus/pci/drivers/vfio-pci/unbind￼
        if [ $? -ne 0 ]; then￼
            return $?￼
        fi￼
    fi￼
fi￼
￼
if [ $driver != 0 ]; then￼
    echo "Binding $pcidev to $driver"￼
    echo -n "$pcidev" > /sys/bus/pci/drivers/$driver/bind￼
fi￼
￼
return $?￼
}￼
￼
function usage()￼
{￼
echo "Usage: vfio-pci.sh -h pcidev "￼
echo " -h pcidev: <pcidev> is BDF number of the device you want to hide"￼
echo " -u pcidev: Optional. <pcidev> is BDF number of the device you want to unhide."￼
echo " -d driver: Optional. When unhiding the device, bind the device with <driver>. The option should be used together with '-u' option"￼
echo ""￼
echo "Example1: sh vfio-pci.sh -h 06:10.0          Hide device 06:10.0 to 'vfio-pci' driver"￼
echo "Example2: sh vfio-pci.sh -u 08:00.0 -d e1000e   Unhide device 08:00.0 and bind the device with 'e1000e' driver"￼
exit 1￼
}￼
￼
if [ $# -eq 0 ] ; then￼
usage￼
fi￼
￼
# parse the options in the command line￼
OPTIND=1￼
while getopts ":h:u:d:" Option￼
do￼
case $Option in￼
    h ) hide_dev=$OPTARG;;￼
    u ) unhide_dev=$OPTARG;;￼
    d ) driver=$OPTARG;;￼
    * ) usage ;;￼
esac￼
done￼

if [ ! -d /sys/bus/pci/drivers/vfio-pci ]; then￼
modprobe vfio_pci￼
echo 0￼
if [ ! -d /sys/bus/pci/drivers/vfio-pci ]; then￼
    echo "There's no 'vfio-pci' module? Please check your kernel config."￼
    exit 1￼
fi￼
fi￼
￼
if [ $hide_dev != 0 -a $unhide_dev != 0 ]; then￼
echo "Do not use -h and -u option together."￼
exit 1￼
fi￼
￼
if [ $unhide_dev = 0 -a $driver != 0 ]; then￼
echo "You should set -u option if you want to use -d option to unhide a device and bind it with a specific driver"￼
    exit 1￼
fi￼
￼
if [ $hide_dev != 0 ]; then￼
hide_pci $hide_dev￼
elif [ $unhide_dev != 0 ]; then￼
unhide_pci $unhide_dev $driver￼
fi￼
exit $?
```

## 3.4 通过QEMU命令行分配设备给客户机

利用qemu\-system\-x86\_64命令行中“\-**device**”选项可以为客户机分配一个设备，配合其中的“**vfio\-pci！！！**” 作为**子选项！！！** 可以实现**设备直接分配**。

```
-device driver[,prop[=value][,...]]
```

其中**driver**是设备**使用的驱动**，有很多种类，如

- **vfio\-pci**表示**VFIO方式**的**PCI设备直接分配**，
- **virtio\-balloon\-pci**（又为virtio\-balloon）表示**ballooning设备**（这与6.1.3节提到的“-balloon virtio”的意义相同）。

prop\[\=value]是设置**驱动的各个属性值**。

“\-**device help**”可以查看有哪些**可用的驱动**，“\-**device driver，help**”可查看某个驱动的各个属性值，如下面命令行所示：

```
[root@kvm-host ~]# qemu-system-x86_64 -device help￼
Controller/Bridge/Hub devices:￼
name "i82801b11-bridge", bus PCI￼
...￼
￼
USB devices:￼
......￼
￼
Storage devices:￼
......￼
name "virtio-blk-pci", bus PCI, alias "virtio-blk"￼
name "virtio-scsi-device", bus virtio-bus￼
name "virtio-scsi-pci", bus PCI, alias "virtio-scsi"￼
￼
Network devices:￼
......￼
name "e1000e", bus PCI, desc "Intel 82574L GbE Controller"￼
......￼
name "virtio-net-device", bus virtio-bus￼
name "virtio-net-pci", bus PCI, alias "virtio-net"￼
......￼
￼
Input devices:￼
......￼
name "virtconsole", bus virtio-serial-bus￼
......￼
￼
Display devices:￼
......￼
￼
Sound devices:￼
......￼
￼
Misc devices:￼
......￼
name "vfio-pci", bus PCI, desc "VFIO-based PCI device assignment"￼
name "virtio-balloon-device", bus virtio-bus￼
name "virtio-balloon-pci", bus PCI, alias "virtio-balloon"￼
name "virtio-mmio", bus System￼
name "virtio-rng-device", bus virtio-bus￼
name "virtio-rng-pci", bus PCI, alias "virtio-rng"￼
￼
Uncategorized devices:￼
......￼
￼
[root@kvm-host ~]# qemu-system-x86_64 -device vfio-pci,help￼
vfio-pci.x-pci-sub-device-id=uint32￼
vfio-pci.x-no-kvm-msi=bool￼
vfio-pci.rombar=uint32￼
vfio-pci.x-pcie-lnksta-dllla=bool (on/off)￼
vfio-pci.x-igd-opregion=bool (on/off)￼
vfio-pci.x-vga=bool (on/off)￼
vfio-pci.x-pci-vendor-id=uint32￼
vfio-pci.multifunction=bool (on/off)￼
vfio-pci.bootindex=int32￼
vfio-pci.x-req=bool (on/off)￼
vfio-pci.x-igd-gms=uint32￼
vfio-pci.romfile=str￼
vfio-pci.x-no-kvm-intx=bool￼
vfio-pci.x-pci-device-id=uint32￼
vfio-pci.host=str (Address (bus/device/function) of the host device, example: 04:10.0)￼
vfio-pci.x-no-kvm-msix=bool￼
vfio-pci.x-intx-mmap-timeout-ms=uint32￼
vfio-pci.command_serr_enable=bool (on/off)￼
vfio-pci.addr=int32 (Slot and optional function number, example: 06.0 or 06)￼
vfio-pci.x-pci-sub-vendor-id=uint32￼
vfio-pci.sysfsdev=str￼
vfio-pci.x-no-mmap=bool
```

在\-device vfio\-pci的属性中，**host属性**指定分配的PCI设备在**宿主机！！！** 中的地址（BDF号），addr属性表示设备在客户机中的PCI的slot编号（即BDF中的D-device的值）。

qemu-system-x86_64命令行工具在启动时分配一个设备给客户机，命令行如下所示：

```
[root@kvm-host ~]# qemu-system-x86_64 -enable-kvm -smp 4 -m 8G rhel7.3.img -device vfio-pci,host=03:10.3,addr=08
```

如果要一次性分配多个设备给客户机，只需在qemu-system-x86_64命令行中重复多次“-device pci-assign，host=$BDF”这样的选项即可。由于设备直接分配是客户机独占该设备，因此一旦将一个设备分配给客户机使用，就不能再将其分配给另外的客户机使用了，否则在通过命令行启动另一个客户机再分配这个设备时，会遇到如下的错误提示：

```
[root@kvm-host ~]# qemu-system-x86_64 -enable-kvm -smp 4 -m 8G rhel7.3.img -device vfio-pci,host=03:10.3,addr=08 -net none￼ qemu-system-x86_64: -device vfio-pci,host=03:10.3,addr=08: vfio: error opening /dev/vfio/50: Device or resource busy￼ qemu-system-x86_64: -device vfio-pci,host=03:10.3,addr=08: vfio: failed to get group 50￼ qemu-system-x86_64: -device vfio-pci,host=03:10.3,addr=08: Device initialization failed
```

除了在客户机启动时就分配直接分配设备之外，QEUM/KVM还支持设备的热插拔（hot\-plug），在客户机运行时添加所需的直接分配设备，这需要在QEMU monitor中运行相应的命令，相关内容将在6.3节中详细介绍。
