

<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

* [1 VT\-d概述](#1-vt-d概述)
	* [1.1 3种客户机设备类型](#11-3种客户机设备类型)
	* [1.2 VT\-d的硬件支持和软件使用](#12-vt-d的硬件支持和软件使用)
	* [1.3 VT\-d的3个缺点和解决方案](#13-vt-d的3个缺点和解决方案)
* [2 VFIO简介](#2-vfio简介)
	* [2.1 VFIO相对于pci\-stub的改进](#21-vfio相对于pci-stub的改进)
* [3 VT\-d环境配置](#3-vt-d环境配置)
	* [3.1 硬件支持和BIOS设置](#31-硬件支持和bios设置)
	* [3.2 宿主机内核的配置](#32-宿主机内核的配置)
		* [3.2.1 VT\-d相关内核编译选项以及启动参数](#321-vt-d相关内核编译选项以及启动参数)
		* [3.2.2 VFIO相关内核编译选项](#322-vfio相关内核编译选项)
		* [3.2.3 系统检查](#323-系统检查)
	* [3.3 在宿主机中隐藏设备](#33-在宿主机中隐藏设备)

<!-- /code_chunk_output -->

# 1 VT\-d概述

## 1.1 3种客户机设备类型

在QEMU/KVM中，**客户机可以使用的设备**大致可分为如下**3种类型**。

1）Emulated device：**QEMU纯软件模拟**的设备，比如\-device rt8139等。

2）virtio device：实现**VIRTIO API**的**半虚拟化驱动的设备**，比如\-device virtio\-net\-pci等。

3）PCI device assignment：**PCI设备直接分配**。

**模拟I/O设备**方式的优点是对硬件平台依赖性较低，可以方便地模拟一些流行的和较老久的设备，不需要宿主机和客户机的额外支持，因此**兼容性高**；而其缺点是I/O路径较长，VM-Exit次数很多，因此**性能较差**。一般适用于对I/O性能要求不高的场景，或者模拟一些老旧遗留（legacy）设备（如RTL8139的网卡）。

**virtio半虚拟化设备**方式的优点是实现了VIRTIO API，减少了VM\-Exit次数，提高了客户机I/O执行效率，比普通模拟I/O的**效率高很多**；而其缺点是需要客户机中与virtio相关驱动的支持（较老的系统默认没有自带这些驱动，Windows系统中需要额外手动安装virtio驱动），因此**兼容性较差**，而且I/O频繁时CPU使用率较高。

**PCI设备直接分配**（Device Assignment，或PCI pass\-through），它允许将宿主机中的物理PCI（或PCI\-E）设备直接分配给客户机完全使用，这正是本节要介绍的重点内容。兼具**高性能**和**高兼容性**.

## 1.2 VT\-d的硬件支持和软件使用

较新的**x86架构**的主要硬件平台（包括服务器级、桌面级）都已经支持设备直接分配，其中**Intel**定义的I/O虚拟化技术规范为“Intel(R)Virtualization Technology for Directed I/O”（**VT\-d**），而AMD的I/O虚拟化技术规范为“**AMD\-Vi**”（也叫作**IOMMU**）。

KVM虚拟机支持将宿主机中的**PCI**、**PCI\-E设备**附加到虚拟化的客户机. 在KVM中通过VT\-d技术使用一个PCI\-E网卡的系统架构示例如图6-12所示。

![](./images/2019-05-23-21-44-17.png)￼

运行在支持VT\-d平台上的QEMU/KVM，可以分配**网卡**、**磁盘控制器**、**USB控制器**、**VGA显卡**等供客户机**直接使用**。而为了设备分配的**安全性**，还需要**中断重映射（interrupt remapping！！！**）的支持。

尽管在使用**qemu命令**行进行设备分配时并**不直接检查中断重映射功能是否开启**，但是在通过**一些工具使用KVM时**（如**libvirt！！！**）默认**需要有中断重映射的功能支持**，才能使用VT\-d分配设备供客户机使用。

## 1.3 VT\-d的3个缺点和解决方案

不过，VT\-d也有自己的缺点，

- 一台服务器**主板上的空间比较有限**，允许添加的**PCI和PCI\-E设备是有限**的，如果一台宿主机上有较多数量的客户机，则很难向每台客户机都独立分配VT\-d的设备。

- 另外，大量使用VT\-d独立分配设备给客户机，导致硬件设备数量增加，这会增加**硬件投资成本**。

为了避免这两个缺点，可以考虑采用如下两个方案：

- 一是在一台**物理宿主机**上，仅对**I/O（如网络**）**性能要求较高**的**少数客户机**使用**VT\-d直接分配设备**（如网卡），而对**其余的客户机**使用**纯模拟（emulated**）或使用**virtio**，以达到多个客户机共享同一个设备的目的；
- 二是对于**网络I/O**的解决方法，可以选择**SR\-IOV**，使一个网卡产生多个独立的虚拟网卡，将每个虚拟网卡分别分配给一个客户机使用，这也正是后面6.2.5节要介绍的内容。

另外，**设备直接分配**还有一个**缺点**是，对于使用**VT\-d**直接分配了设备的客户机，其**动态迁移功能将会受限**，不过也可以用**热插拔**或**libvirt工具**等方式来缓解这个问题，详细内容将在8.1.5节介绍。

# 2 VFIO简介

在上一版中，VT\-d部分依然是以**pci\-stub模块**为例讲解的。

**Kernel 3.10**发布，**VFIO**正式被引入，取代了原来的pci\-stub的VT\-d方式。

## 2.1 VFIO相对于pci\-stub的改进

与Legacy KVM Device Assignment（使用**pci\-stub driver**）相比，VFIO（Virtual Function IO￼）最大的改进就是**隔离了设备之间的DMA和中断！！！**，以及对**IOMMU Group！！！的支持**，从而有了更好的安全性。

IOMMU Group可以认为是**对PCI设备的分组**，**每个group**里面的**设备**被视作**IOMMU可以操作的最小整体**；换句话说，**同一个IOMMU Group**里的设备￼**不可以分配给不同的客户机**。

在以前的Legacy KVM Device Assignment中，并不会检查这一点，而后面的操作却注定是失败的。新的VFIO会检查并及时报错。

另外，新的VFIO架构也做到了平台无关，有更好的可移植性。

本书后续就以VFIO为例讲解VT\-d。

# 3 VT\-d环境配置

在KVM中使用VT\-d技术进行设备直接分配，需要以下几方面的环境配置。

## 3.1 硬件支持和BIOS设置

目前市面上的**x86硬件平台**基本都**支持VT\-d**，包括服务器平台Xeon以及桌面级的酷睿系列。

除了在硬件平台层面对VT\-d支持之外，还需要在**BIOS将VT\-d功能打开**，使其处于“Enabled”状态。由于各个BIOS和硬件厂商的标识的区别，VT-d在BIOS中设置选项的名称也有所不同。笔者见到BIOS中VT-d设置选项一般为“Intel(R)VT for Directed I/O”或“Intel VT\-d”等，在图3-2中已经演示了在BIOS设置中打开VT-d选项的情况。

![2019-05-15-09-02-49.png](./images/2019-05-15-09-02-49.png)

## 3.2 宿主机内核的配置

在**宿主机系统**中，内核也需要配置相应的选项。

### 3.2.1 VT\-d相关内核编译选项以及启动参数

在RHEL 7自带的Kernel config中，也都已经使这些类似的配置**处于打开状态**。

```
CONFIG_GART_IOMMU=y         #AMD平台相关￼
# CONFIG_CALGARY_IOMMU is not set      #IBM平台相关￼
CONFIG_IOMMU_HELPER=y￼
CONFIG_VFIO_IOMMU_TYPE1=m￼
CONFIG_VFIO_NOIOMMU=y￼
CONFIG_IOMMU_API=y￼
CONFIG_IOMMU_SUPPORT=y￼
CONFIG_IOMMU_IOVA=y￼
CONFIG_AMD_IOMMU=y            #AMD平台的IOMMU设置￼
CONFIG_AMD_IOMMU_STATS=y￼
CONFIG_AMD_IOMMU_V2=m￼
CONFIG_INTEL_IOMMU=y         #Intel平台的VT-d设置￼
# CONFIG_INTEL_IOMMU_DEFAULT_ON is not set#Intel平台的VT-d是否默认打开。这里没有选上，需要在kernel boot parameter中加上“intel_iommu=on”￼
CONFIG_INTEL_IOMMU_FLOPPY_WA=y￼
# CONFIG_IOMMU_DEBUG is not set￼
# CONFIG_IOMMU_STRESS is not set
```

**CONFIG_INTEL\_IOMMU\_DEFAULT\_ON**, 表明的是Intel平台的**VT\-d是否默认打开**。这里没有选上，需要在**kernel boot parameter**中加上“**intel\_iommu=on**”

而在较旧的Linux内核（3.0版本及以下，如2.6.32版本）中，应该配置如下几个VT\-d相关的配置选项。

```
CONFIG_DMAR=y￼
# CONFIG_DMAR_DEFAULT_ON is not set   #本选项可设置为y，也可不设置￼
CONFIG_DMAR_FLOPPY_WA=y￼
CONFIG_INTR_REMAP=y
```

### 3.2.2 VFIO相关内核编译选项

另外，为了配合接下来的第3步设置（用于**隐藏设备**），还需要配置**vfio\-pci**这个内核模块，相关的内核配置选项如下。

在RHEL 7**默认内核**中，都将**CONFIG\_KVM\_VFIO配置为y**（直接编译到内核），其他的功能配置为模块（m）。

```
CONFIG_VFIO_IOMMU_TYPE1=m￼
CONFIG_VFIO=m￼
CONFIG_VFIO_NOIOMMU=y         #支持用户空间的VFIO框架￼
CONFIG_VFIO_PCI=m￼
# CONFIG_VFIO_PCI_VGA is not set      #这个是for显卡的VT-d￼
CONFIG_VFIO_PCI_MMAP=y￼
CONFIG_VFIO_PCI_INTX=y￼
CONFIG_KVM_VFIO=y
```

### 3.2.3 系统检查

在启动宿主机系统（这里需要手动修改grub）￼后，可以通过内核的打印信息来检查VT\-d是否处于打开可用状态，如下所示：

```
[root@kvm-host ~]# dmesg | grep -i dmar￼
[    0.000000] ACPI: DMAR 000000007b6a0000 00100 (v01 INTEL   S2600WT 00000001 INTL 20091013)￼
[    0.000000] DMAR: IOMMU enabled￼
[    0.303666] DMAR: Host address width 46￼
[    0.303670] DMAR: DRHD base: 0x000000fbffc000 flags: 0x0￼
[    0.303683] DMAR: dmar0: reg_base_addr fbffc000 ver 1:0 cap 8d2078c106f0466 ecap￼
     f020de￼
[    0.303686] DMAR: DRHD base: 0x000000c7ffc000 flags: 0x1￼
[    0.303696] DMAR: dmar1: reg_base_addr c7ffc000 ver 1:0 cap 8d2078c106f0466 ecap￼
     f020de￼
[    0.303699] DMAR: RMRR base: 0x0000007a3e3000 end: 0x0000007a3e5fff￼
[    0.303702] DMAR: ATSR flags: 0x0￼
[    0.303707] DMAR-IR: IOAPIC id 10 under DRHD base  0xfbffc000 IOMMU 0￼
[    0.303710] DMAR-IR: IOAPIC id 8 under DRHD base  0xc7ffc000 IOMMU 1￼
[    0.303713] DMAR-IR: IOAPIC id 9 under DRHD base  0xc7ffc000 IOMMU 1￼
[    0.303716] DMAR-IR: HPET id 0 under DRHD base 0xc7ffc000￼
[    0.303719] DMAR-IR: Queued invalidation will be enabled to support x2apic and ￼
     Intr-remapping.￼
[    0.304885] DMAR-IR: Enabled IRQ remapping in x2apic mode￼
[   36.384332] DMAR: dmar0: Using Queued invalidation￼
[   36.384603] DMAR: dmar1: Using Queued invalidation￼
[   36.384898] DMAR: Setting RMRR:￼
[   36.384965] DMAR: Setting identity map for device 0000:00:1a.0 [0x7a3e3000 - ￼
    0x7a3e5fff]￼
[   36.385067] DMAR: Setting identity map for device 0000:00:1d.0 [0x7a3e3000 - ￼
    0x7a3e5fff]￼
[   36.385140] DMAR: Prepare 0-16MiB unity mapping for LPC￼
[   36.385177] DMAR: Setting identity map for device 0000:00:1f.0 [0x0 - 0xffffff]￼
[   36.385221] DMAR: Intel(R) Virtualization Technology for Directed I/O￼
[root@kvm-host ~]# dmesg | grep -i iommu￼
...￼
[    0.000000] DMAR: IOMMU enabled￼
[    0.303707] DMAR-IR: IOAPIC id 10 under DRHD base  0xfbffc000 IOMMU 0￼
[    0.303710] DMAR-IR: IOAPIC id 8 under DRHD base  0xc7ffc000 IOMMU 1￼
[    0.303713] DMAR-IR: IOAPIC id 9 under DRHD base  0xc7ffc000 IOMMU 1￼
[   36.385596] iommu: Adding device 0000:ff:08.0 to group 0￼
[   36.385674] iommu: Adding device 0000:ff:08.2 to group 0￼
[   36.385751] iommu: Adding device 0000:ff:08.3 to group 0￼
[   36.386041] iommu: Adding device 0000:ff:09.0 to group 1￼
[   36.386119] iommu: Adding device 0000:ff:09.2 to group 1￼
[   36.386196] iommu: Adding device 0000:ff:09.3 to group 1￼
...（iommu grouping）￼
[   36.422115] iommu: Adding device 0000:80:05.2 to group 49￼
[   36.422257] iommu: Adding device 0000:80:05.4 to group 49
```

如果**只有“DMAR：IOMMU enabled”输出**，则需要**检查BIOS中VT\-d**是否已打开。

## 3.3 在宿主机中隐藏设备

使用vfio\_pci这个内核模块来对需要分配给客户机的设备进行隐藏

需要通过如下3步来隐藏一个设备。

1）加载**vfio\-pci驱动**（前面已提及将“**CONFIG\_VFIO\_PCI=m**”作为内核编译的配置选项），如下所示：

```
[root@gerrylee ~]# modprobe vfio_pci
[root@gerrylee ~]# lsmod | grep vfio_pci
vfio_pci               41268  0
vfio                   32657  2 vfio_iommu_type1,vfio_pci
irqbypass              13503  2 kvm,vfio_pci
[root@gerrylee ~]# ls /sys/bus/pci/drivers/vfio-pci/
bind  module  new_id  remove_id  uevent  unbind
```

如果**vfio\_pci**已**被编译到内核**而**不是作为module**，则**仅需最后一个命令**来检查/**sys/bus/pci/drivers/vfio\-pci**/目录是否存在即可。

2）查看**设备的vendor ID和device ID**，如下所示（假设此设备的BDF为03：10.3）：

```
[root@kvm-host ~]# lspci -s 03:10.3 -Dn￼
0000:03:10.3 0200: 8086:1520 (rev 01)
```

在上面lspci命令行中，

- \-D选项表示在输出信息中显示设备的domain，
- \-n选项表示用**数字的方式**显示设备的**vendor ID**和**device ID**，
- \-s选项表示仅显示后面指定的一个设备的信息。

在该命令的输出信息中，“0000：03：10.3”表示设备在PCI/PCI-E总线中的具体位置，依次是设备的domain（0000）、bus（03）、slot（10）、function（3），其中domain的值一般为0（当机器有多个host bridge时，其取值范围是0~0xffff），bus的取值范围是0～0xff，slot取值范围是0～0x1f，function取值范围是0～0x7，其中后面3个值一般简称为BDF（即bus：device：function）。在输出信息中，设备的vendor ID是“8086”（“8086”ID代表Intel Corporation），device ID是“1520”（代表i350 VF）。

3）**绑定设备到vfio\-pci驱动**，命令行操作如下所示。

查看它目前的驱动，如不是vfio\-pci，则解绑当前驱动，然后绑定到vfio\-pci上。

```
[root@kvm-host ~]# lspci -s 03:10.3 -k￼
03:10.3 Ethernet controller: Intel Corporation I350 Ethernet Controller Virtual Function (rev 01)￼
Subsystem: Intel Corporation Device 35c4￼
Kernel driver in use: igbvf￼
Kernel modules: igbvf￼

[root@kvm-host ~]# echo 0000:03:10.3 > /sys/bus/pci/drivers/igbvf/unbind￼

[root@kvm-host ~]# echo -n "8086 1520" > /sys/bus/pci/drivers/vfio-pci/new_id￼

[root@kvm-host ~]# lspci -s 03:10.3 -k￼
03:10.3 Ethernet controller: Intel Corporation I350 Ethernet Controller Virtual Function (rev 01)￼
Subsystem: Intel Corporation Device 35c4￼
Kernel driver in use: vfio-pci￼
Kernel modules: igbvf
```

在绑定前，用lspci命令查看BDF为03：10.3的设备使用的驱动是Intel的igbvf驱动，而绑定到vfio\_pci后，通过命令可以可查看到它目前使用的驱动是vfio\-pci而不是igbvf，其中lspci的 **\-k选项** 表示输出信息中显示**正在使用的驱动**和**内核中可以支持该设备的模块**。

而在客户机不需要使用该设备后，让宿主机使用该设备，则需要将其恢复到使用原本的驱动。

本节的**隐藏和恢复设备**，手动操作起来还是有点效率低和容易出错，利用如下一个Shell脚本可以方便实现