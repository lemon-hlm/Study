
<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

* [1 动态迁移的概念](#1-动态迁移的概念)

<!-- /code_chunk_output -->

# 1 动态迁移的概念
本节首先介绍迁移的基本概念，然后介绍有无虚拟化环境下的迁移，最后详细介绍动态迁移。
迁移（migration）包括系统整体的迁移和某个工作负载的迁移。系统整体迁移是将系统上的所有软件（也包括操作系统）完全复制到另一台物理硬件机器之上。而工作负载的迁移，是将系统上的某个工作负载转移到另一台物理机器上继续运行。服务器系统迁移的作用在于简化了系统维护管理，提高了系统负载均衡，增强了系统容错性并优化了系统电源管理。
虚拟化的概念和技术的出现，给迁移带来了更丰富的含义和实践。在传统应用环境中，没有虚拟化技术的支持，系统整体的迁移主要是静态迁移。这种迁移主要依靠系统备份和恢复技术，将系统的软件完全复制到另一台机器上，可以通过先做出系统的镜像文件，然后复制到其他机器上，或者直接通过硬盘相互复制来达到迁移的目的。在非虚拟化环境中也有动态迁移的概念，但都是对某个（或某一组）工作负载的迁移，需要特殊系统的支持才能实现，而且技术也不够成熟。如哥伦比亚大学的Zap￼系统，它通过在操作系统上提供了一个很薄的虚拟化层（这和现在主流的虚拟化技术不一样），可以实现将工作负载迁移到另一台机器上。
在虚拟化环境中的迁移，又分为静态迁移（static migration）和动态迁移（live migra-tion），也有部分人称之为冷迁移（cold migration）和热迁移（hot migration），或者离线迁移（offline migration）和在线迁移（online migration）。静态迁移和动态迁移最大的区别就是，静态迁移有一段明显时间客户机中的服务不可用，而动态迁移则没有明显的服务暂停时间。虚拟化环境中的静态迁移也可以分为两种，一种是关闭客户机后，将其硬盘镜像复制到另一台宿主机上然后恢复启动起来，这种迁移不能保留客户机中运行的工作负载；另一种是两台宿主机共享存储系统，只需在暂停（而不是完全关闭）客户机后，复制其内存镜像到另一台宿主机中恢复启动即可，这种迁移可以保持客户机迁移前的内存状态和系统运行的工作负载。
动态迁移是指在保证客户机上应用服务正常运行的同时，让客户机在不同的宿主机之间进行迁移，其逻辑步骤与前面静态迁移几乎一致，有硬盘存储和内存都复制的动态迁移，也有仅复制内存镜像的动态迁移。不同的是，为了保证迁移过程中客户机服务的可用性，迁移过程仅有非常短暂的停机时间。动态迁移允许系统管理员将客户机在不同的物理机上迁移，同时不会断开访问客户机中服务的客户端或应用程序的连接。一个成功的动态迁移需要保证客户机的内存、硬盘存储、网络连接在迁移到目的主机后依然保持不变，而且迁移过程的服务暂停时间较短。
另外，对于虚拟化环境的迁移，不仅包括相同Hypervisor之间的客户机迁移（如KVM迁移到KVM、Xen迁移到Xen），还包括不同Hypervisor之间的客户机迁移（如Xen迁移到KVM、VMware迁移到KVM等，8.2节会详细介绍）。
8.1.2　动态迁移的效率和应用场景
虚拟机迁移主要增强了系统的可维护性，其主要目标是在客户没有感觉的情况下，将客户机迁移到了另一台物理机器上，并保证其各个服务都正常使用。可以从如下几个方面来衡量虚拟机迁移的效率。
1）整体迁移时间：从源主机（source host）中迁移操作开始到客户机被迁移到目的主机（destination host）并恢复其服务所花费的时间。
2）服务器停机时间（service down-time）：在迁移过程中，源主机和目的主机上客户机的服务都处于不可用状态的时间，此时源主机上客户机已暂停服务，目的主机上客户机还未恢复服务。
3）对服务的性能影响：不仅包括迁移后的客户机中应用程序的性能与迁移前相比是否有所降低，还包括迁移后对目的主机上的其他服务（或其他客户机）的性能影响。
动态迁移的整体迁移时间受诸多因素的影响，如Hypervisor和迁移工具的种类、磁盘存储的大小（如果需要复制磁盘镜像）、内存大小及使用率、CPU的性能及利用率、网络带宽大小及是否拥塞等，整体迁移时间一般为几秒到几十分钟不等。动态迁移的服务停机时间也受Hypervisor的种类、内存大小、网络带宽等因素的影响，服务停机时间一般在几毫秒到几秒不等。其中，服务停机时间在几毫秒到几百毫秒，而且在终端用户毫无察觉的情况下实现迁移，这种动态迁移也被称为无缝的动态迁移。而静态迁移的服务暂停时间一般都较长，少则几秒钟，多则几分钟，需要依赖于管理员的操作速度和CPU、内存、网络等硬件设备。所以说，静态迁移一般适合于对服务可用性要求不高的场景，而动态迁移的停机时间很短，适合对服务可用性要求较高的场景。动态迁移一般对服务的性能影响不大，这与两台宿主机的硬件配置情况、Hypervisor是否稳定等因素相关。
动态迁移的好处是非常明显的了，下面来看一下动态迁移的几个应用场景。
1）负载均衡：当一台物理服务器的负载较高时，可以将其上运行的客户机动态迁移到负载较低的宿主机服务器中，以保证客户机的服务质量（QoS）。而前面提到的，CPU、内存的过载使用可以解决某些客户机的资源利用问题，之后当物理资源长期处于超负荷状态时，对服务器稳定性能和服务质量都有损害的，这时需要通过动态迁移来进行适当的负载均衡。
2）解除硬件依赖：当系统管理员需要在宿主机上升级、添加、移除某些硬件设备的时候，可以动态迁移的概念
本节首先介绍迁移的基本概念，然后介绍有无虚拟化环境下的迁移，最后详细介绍动态迁移。
迁移（migration）包括系统整体的迁移和某个工作负载的迁移。系统整体迁移是将系统上的所有软件（也包括操作系统）完全复制到另一台物理硬件机器之上。而工作负载的迁移，是将系统上的某个工作负载转移到另一台物理机器上继续运行。服务器系统迁移的作用在于简化了系统维护管理，提高了系统负载均衡，增强了系统容错性并优化了系统电源管理。
虚拟化的概念和技术的出现，给迁移带来了更丰富的含义和实践。在传统应用环境中，没有虚拟化技术的支持，系统整体的迁移主要是静态迁移。这种迁移主要依靠系统备份和恢复技术，将系统的软件完全复制到另一台机器上，可以通过先做出系统的镜像文件，然后复制到其他机器上，或者直接通过硬盘相互复制来达到迁移的目的。在非虚拟化环境中也有动态迁移的概念，但都是对某个（或某一组）工作负载的迁移，需要特殊系统的支持才能实现，而且技术也不够成熟。如哥伦比亚大学的Zap￼系统，它通过在操作系统上提供了一个很薄的虚拟化层（这和现在主流的虚拟化技术不一样），可以实现将工作负载迁移到另一台机器上。
在虚拟化环境中的迁移，又分为静态迁移（static migration）和动态迁移（live migra-tion），也有部分人称之为冷迁移（cold migration）和热迁移（hot migration），或者离线迁移（offline migration）和在线迁移（online migration）。静态迁移和动态迁移最大的区别就是，静态迁移有一段明显时间客户机中的服务不可用，而动态迁移则没有明显的服务暂停时间。虚拟化环境中的静态迁移也可以分为两种，一种是关闭客户机后，将其硬盘镜像复制到另一台宿主机上然后恢复启动起来，这种迁移不能保留客户机中运行的工作负载；另一种是两台宿主机共享存储系统，只需在暂停（而不是完全关闭）客户机后，复制其内存镜像到另一台宿主机中恢复启动即可，这种迁移可以保持客户机迁移前的内存状态和系统运行的工作负载。
动态迁移是指在保证客户机上应用服务正常运行的同时，让客户机在不同的宿主机之间进行迁移，其逻辑步骤与前面静态迁移几乎一致，有硬盘存储和内存都复制的动态迁移，也有仅复制内存镜像的动态迁移。不同的是，为了保证迁移过程中客户机服务的可用性，迁移过程仅有非常短暂的停机时间。动态迁移允许系统管理员将客户机在不同的物理机上迁移，同时不会断开访问客户机中服务的客户端或应用程序的连接。一个成功的动态迁移需要保证客户机的内存、硬盘存储、网络连接在迁移到目的主机后依然保持不变，而且迁移过程的服务暂停时间较短。
另外，对于虚拟化环境的迁移，不仅包括相同Hypervisor之间的客户机迁移（如KVM迁移到KVM、Xen迁移到Xen），还包括不同Hypervisor之间的客户机迁移（如Xen迁移到KVM、VMware迁移到KVM等，8.2节会详细介绍）。
8.1.2　动态迁移的效率和应用场景
虚拟机迁移主要增强了系统的可维护性，其主要目标是在客户没有感觉的情况下，将客户机迁移到了另一台物理机器上，并保证其各个服务都正常使用。可以从如下几个方面来衡量虚拟机迁移的效率。
1）整体迁移时间：从源主机（source host）中迁移操作开始到客户机被迁移到目的主机（destination host）并恢复其服务所花费的时间。
2）服务器停机时间（service down-time）：在迁移过程中，源主机和目的主机上客户机的服务都处于不可用状态的时间，此时源主机上客户机已暂停服务，目的主机上客户机还未恢复服务。
3）对服务的性能影响：不仅包括迁移后的客户机中应用程序的性能与迁移前相比是否有所降低，还包括迁移后对目的主机上的其他服务（或其他客户机）的性能影响。
动态迁移的整体迁移时间受诸多因素的影响，如Hypervisor和迁移工具的种类、磁盘存储的大小（如果需要复制磁盘镜像）、内存大小及使用率、CPU的性能及利用率、网络带宽大小及是否拥塞等，整体迁移时间一般为几秒到几十分钟不等。动态迁移的服务停机时间也受Hypervisor的种类、内存大小、网络带宽等因素的影响，服务停机时间一般在几毫秒到几秒不等。其中，服务停机时间在几毫秒到几百毫秒，而且在终端用户毫无察觉的情况下实现迁移，这种动态迁移也被称为无缝的动态迁移。而静态迁移的服务暂停时间一般都较长，少则几秒钟，多则几分钟，需要依赖于管理员的操作速度和CPU、内存、网络等硬件设备。所以说，静态迁移一般适合于对服务可用性要求不高的场景，而动态迁移的停机时间很短，适合对服务可用性要求较高的场景。动态迁移一般对服务的性能影响不大，这与两台宿主机的硬件配置情况、Hypervisor是否稳定等因素相关。
动态迁移的好处是非常明显的了，下面来看一下动态迁移的几个应用场景。
1）负载均衡：当一台物理服务器的负载较高时，可以将其上运行的客户机动态迁移到负载较低的宿主机服务器中，以保证客户机的服务质量（QoS）。而前面提到的，CPU、内存的过载使用可以解决某些客户机的资源利用问题，之后当物理资源长期处于超负荷状态时，对服务器稳定性能和服务质量都有损害的，这时需要通过动态迁移来进行适当的负载均衡。
2）解除硬件依赖：当系统管理员需要在宿主机上升级、添加、移除某些硬件设备的时候，可以将该宿主机上运行的客户机非常安全、高效地动态迁移到其他宿主机上。在系统管理员升级硬件系统之时，使用动态迁移，可以让终端用户完全感知不到服务有任何暂停时间。
3）节约能源：在目前的数据中心的成本支出中，其中有一项重要的费用是电能的开销。当有较多服务器的资源使用率都偏低时，可以通过动态迁移将宿主机上的客户机集中迁移到其中几台服务器上，而在某些宿主机上的客户机完全迁移走之后，就可以关闭其电源，以节省电能消耗，从而降低数据中心的运营成本。
4）实现客户机地理位置上的远程迁移：假设某公司运行某类应用服务的客户机本来仅部署在上海电信的IDC中，后来发现来自北京及其周边地区的网通用户访问量非常大，但是由于距离和网络互联带宽拥堵（如电信与网通之间的带宽）的问题，北方用户使用该服务的网络延迟较大，这时系统管理员可以将上海IDC中的部分客户机通过动态迁移部署到位于北京的网通的IDC中，从而让终端用户使用该服务的质量更高。
8.1.3　KVM动态迁移原理
在KVM中，既支持离线的静态迁移，又支持在线的动态迁移。对于静态迁移，可以在源宿主机上某客户机的QEMU monitor中，用“savevm my_tag”命令来保存一个完整的客户机镜像快照（标记为my_tag），然后在源宿主机中关闭或暂停该客户机。将该客户机的镜像文件复制到另外一台宿主机中，用于源宿主机中启动客户机时以相同的命令启动复制过来的镜像，在其QEMU monitor中用“loadvm my_tag”命令来恢复刚才保存的快照，即可完全加载保存快照时的客户机状态。这里的“savevm”命令保存的完整客户机状态包括CPU状态、内存、设备状态、可写磁盘中的内容。注意，这种保存快照的方法需要qcow2、qed等格式的磁盘镜像文件，因为只有它们才支持快照这个特性（可参见前面5.4节中对镜像文件格式的介绍）。
本节主要介绍KVM中比静态迁移更实用、更方便的动态迁移。如果源宿主机和目的宿主机共享存储系统，则只需要通过网络发送客户机的vCPU执行状态、内存中的内容、虚拟设备的状态到目的主机上即可，否则，还需要将客户机的磁盘存储发送到目的主机上去。KVM中一个基于共享存储的动态迁移过程如图8-1所示。
￼
图8-1　基于共享存储的KVM动态迁移
在不考虑磁盘存储复制的情况下（基于共享存储系统），KVM动态迁移的具体迁移过程为：在客户机动态迁移开始后，客户机依然在源宿主机上运行，与此同时，客户机的内存页被传输到目的主机之上。QEMU/KVM会监控并记录下迁移过程中所有已被传输的内存页的任何修改，并在所有的内存页都被传输完成后即开始传输在前面过程中内存页的更改内容。QEMU/KVM也会估计迁移过程中的传输速度，当剩余的内存数据量能够在一个可设定的迁移停机时间（目前QEMU中默认为300毫秒）内传输完成时，QEMU/KVM将会关闭源宿主机上的客户机，再将剩余的数据量传输到目的主机上去，最后传输过来的内存内容在目的宿主机上恢复客户机的运行状态。至此，KVM的一个动态迁移操作就完成了。迁移后的客户机状态尽可能与迁移前一致，除非目的宿主机上缺少一些配置。例如，在源宿主机上有给客户机配置好网桥类型的网络，但目的主机上没有网桥配置会导致迁移后客户机的网络不通。而当客户机中内存使用量非常大且修改频繁，内存中数据被不断修改的速度大于KVM能够传输的内存速度之时，动态迁移过程是不会完成的，这时要进行迁移只能进行静态迁移。笔者就曾遇到这样的情况，KVM宿主机上一个拥有4个vCPU、4GB内存的客户机中运行着一个SPECjbb2005（一个基准测试工具），使客户机的负载较重且内存频繁地更新，这时进行动态迁移无论怎样也不能完成，直到客户机中SPECjbb2005测试工具停止运行后，迁移过程才真正完成。
在KVM中，动态迁移服务停机时间会与实际的工作负载和网络带宽等诸多因素有关，一般在数十毫秒到几秒钟之间，当然如果网络带宽过小或网络拥塞，会导致服务停机时间变长。必要的时候，服务器端在动态迁移时暂停数百毫秒或数秒钟后恢复服务，对于一些终端用户来说是可以接受的，可能表现为：浏览器访问网页速度会慢一点，或者ssh远程操作过程中有一两秒不能操作但ssh连接并没有断开（不需要重新建立连接）。笔者曾经测试过KVM动态迁移过程中的服务停机时间，当时在客户机中运行了一个UnixBench（一个基准测试工具），然后进行动态迁移，经过测量，某次动态迁移中服务停机时间约为900毫秒。这次测试是在客户机中运行netperf（一个测试网络的基准测试工具）的服务端，在另外一台机器上运行netperf的客户端，通过查看netperf客户端收到服务端响应数据包在迁移过程中中断的间隔时间来粗略地估算客户机迁移过程中服务停机时间。某次实验的粗略结果如图8-2所示，可以看出时间从4.6秒到5.5秒为动态迁移过程中大致的服务停机时间。
￼
图8-2　KVM动态迁移中服务停机时间的某次测量结果
从上面的介绍可知，KVM的动态迁移是比较高效也是很有用处的功能，在实际测试中也是比较稳定的（而且在一般情况下，就算迁移不成功，源宿将该宿主机上运行的客户机非常安全、高效地动态迁移到其他宿主机上。在系统管理员升级硬件系统之时，使用动态迁移，可以让终端用户完全感知不到服务有任何暂停时间。
3）节约能源：在目前的数据中心的成本支出中，其中有一项重要的费用是电能的开销。当有较多服务器的资源使用率都偏低时，可以通过动态迁移将宿主机上的客户机集中迁移到其中几台服务器上，而在某些宿主机上的客户机完全迁移走之后，就可以关闭其电源，以节省电能消耗，从而降低数据中心的运营成本。
4）实现客户机地理位置上的远程迁移：假设某公司运行某类应用服务的客户机本来仅部署在上海电信的IDC中，后来发现来自北京及其周边地区的网通用户访问量非常大，但是由于距离和网络互联带宽拥堵（如电信与网通之间的带宽）的问题，北方用户使用该服务的网络延迟较大，这时系统管理员可以将上海IDC中的部分客户机通过动态迁移部署到位于北京的网通的IDC中，从而让终端用户使用该服务的质量更高。
8.1.3　KVM动态迁移原理
在KVM中，既支持离线的静态迁移，又支持在线的动态迁移。对于静态迁移，可以在源宿主机上某客户机的QEMU monitor中，用“savevm my_tag”命令来保存一个完整的客户机镜像快照（标记为my_tag），然后在源宿主机中关闭或暂停该客户机。将该客户机的镜像文件复制到另外一台宿主机中，用于源宿主机中启动客户机时以相同的命令启动复制过来的镜像，在其QEMU monitor中用“loadvm my_tag”命令来恢复刚才保存的快照，即可完全加载保存快照时的客户机状态。这里的“savevm”命令保存的完整客户机状态包括CPU状态、内存、设备状态、可写磁盘中的内容。注意，这种保存快照的方法需要qcow2、qed等格式的磁盘镜像文件，因为只有它们才支持快照这个特性（可参见前面5.4节中对镜像文件格式的介绍）。
本节主要介绍KVM中比静态迁移更实用、更方便的动态迁移。如果源宿主机和目的宿主机共享存储系统，则只需要通过网络发送客户机的vCPU执行状态、内存中的内容、虚拟设备的状态到目的主机上即可，否则，还需要将客户机的磁盘存储发送到目的主机上去。KVM中一个基于共享存储的动态迁移过程如图8-1所示。
￼
图8-1　基于共享存储的KVM动态迁移
在不考虑磁盘存储复制的情况下（基于共享存储系统），KVM动态迁移的具体迁移过程为：在客户机动态迁移开始后，客户机依然在源宿主机上运行，与此同时，客户机的内存页被传输到目的主机之上。QEMU/KVM会监控并记录下迁移过程中所有已被传输的内存页的任何修改，并在所有的内存页都被传输完成后即开始传输在前面过程中内存页的更改内容。QEMU/KVM也会估计迁移过程中的传输速度，当剩余的内存数据量能够在一个可设定的迁移停机时间（目前QEMU中默认为300毫秒）内传输完成时，QEMU/KVM将会关闭源宿主机上的客户机，再将剩余的数据量传输到目的主机上去，最后传输过来的内存内容在目的宿主机上恢复客户机的运行状态。至此，KVM的一个动态迁移操作就完成了。迁移后的客户机状态尽可能与迁移前一致，除非目的宿主机上缺少一些配置。例如，在源宿主机上有给客户机配置好网桥类型的网络，但目的主机上没有网桥配置会导致迁移后客户机的网络不通。而当客户机中内存使用量非常大且修改频繁，内存中数据被不断修改的速度大于KVM能够传输的内存速度之时，动态迁移过程是不会完成的，这时要进行迁移只能进行静态迁移。笔者就曾遇到这样的情况，KVM宿主机上一个拥有4个vCPU、4GB内存的客户机中运行着一个SPECjbb2005（一个基准测试工具），使客户机的负载较重且内存频繁地更新，这时进行动态迁移无论怎样也不能完成，直到客户机中SPECjbb2005测试工具停止运行后，迁移过程才真正完成。
在KVM中，动态迁移服务停机时间会与实际的工作负载和网络带宽等诸多因素有关，一般在数十毫秒到几秒钟之间，当然如果网络带宽过小或网络拥塞，会导致服务停机时间变长。必要的时候，服务器端在动态迁移时暂停数百毫秒或数秒钟后恢复服务，对于一些终端用户来说是可以接受的，可能表现为：浏览器访问网页速度会慢一点，或者ssh远程操作过程中有一两秒不能操作但ssh连接并没有断开（不需要重新建立连接）。笔者曾经测试过KVM动态迁移过程中的服务停机时间，当时在客户机中运行了一个UnixBench（一个基准测试工具），然后进行动态迁移，经过测量，某次动态迁移中服务停机时间约为900毫秒。这次测试是在客户机中运行netperf（一个测试网络的基准测试工具）的服务端，在另外一台机器上运行netperf的客户端，通过查看netperf客户端收到服务端响应数据包在迁移过程中中断的间隔时间来粗略地估算客户机迁移过程中服务停机时间。某次实验的粗略结果如图8-2所示，可以看出时间从4.6秒到5.5秒为动态迁移过程中大致的服务停机时间。
￼
图8-2　KVM动态迁移中服务停机时间的某次测量结果
从上面的介绍可知，KVM的动态迁移是比较高效也是很有用处的功能，在实际测试中也是比较稳定的（而且在一般情况下，就算迁移不成功，源宿主机上的客户机依然在正常运行）。不过，对于KVM动态迁移，也有如下几点建议和注意事项。
1）源宿主机和目的宿主机之间尽量用网络共享的存储系统来保存客户机磁盘镜像，尽管KVM动态迁移也支持连同磁盘镜像一起复制（加上一个参数即可，后面会介绍）。共享存储（如NFS）在源宿主机和目的宿主机上的挂载位置必须完全一致。
2）为了提高动态迁移的成功率，尽量在同类型CPU的主机上面进行动态迁移，尽管KVM动态迁移也支持从Intel平台迁移到AMD平台（或者反向）。不过在Intel的两代不同平台之间进行动态迁移一般是比较稳定的，如后面介绍实际操作步骤时，就是从一台Intel Broadwell平台上运行的KVM中将一个客户机动态迁移到Skylake平台上。
3）64位的客户机只能在64位宿主机之间迁移，而32位客户机可以在32位宿主机和64位宿主机之间迁移。
4）动态迁移的源宿主机和目的宿主机对NX￼（Never eXecute）位的设置是相同，要么同为关闭状态，要么同为打开状态。在Intel平台上的Linux系统中，用“cat/proc/cpuinfo|grep nx”命令可以查看是否有NX的支持。
5）在进行动态迁移时，被迁移客户机的名称是唯一的，在目的宿主机上不能有与源宿主机中被迁移客户机同名的客户机存在。另外，客户机名称可以包含字母、数字和“_”“.”“-”等特殊字符。
6）目的宿主机和源宿主机的软件配置要尽可能地相同。例如，为了保证动态迁移后客户机中的网络依然正常工作，需要在目的宿主机上配置与源宿主机同名的网桥，并让客户机以桥接的方式使用网络（参见5.5.2节）。
8.1.4　KVM动态迁移实践
下面详细介绍在KVM上进行动态迁移的具体操作步骤。这里的客户机镜像文件存放在NFS的共享存储上面，源宿主机（kvm-host1）和目的宿主机（kvm-host2）都对NFS上的镜像文件具有可读写权限。
1）在源宿主机挂载NFS的上客户机镜像，并启动客户机。命令行操作如下：

[root@kvm-host1 ~]# mount my-nfs:/rw-images/ /mnt/images/￼ [root@kvm-host1 ~]# df -h | grep images￼ 192.168.11.3:/mnt/images  734G  1.7G  695G   1% /mnt/images￼ [root@kvm-host1 ~]# qemu-system-x86_64 /mnt/images/rhel7.img -smp 2 -m 2048 -net nic -net tap

这里的特别之处是没有指定客户机中的CPU模型，默认是qemu64这个基本的模型。当然也可自行设置为“-cpu Broadwell”等指定特定的模型，不过要保证在目的主机上也用相同的命令。在5.2.4节中已提及，同时指定相同的某个CPU模型，可以让客户机在不同的几代平台上的迁移更加稳定。
另外，还要在客户机中运行一个程序（这里执行了“top”命令），以便在动态迁移后检查它是否仍然正常地继续执行。在动态迁移前，客户机运行“top”命令的状态如图8-3所示。
￼
图8-3　动态迁移前在客户机中运行“top”命令
2）目的宿主机上也挂载NFS上的客户机镜像的目录，并且启动一个客户机用于接收动态迁移过来内存内容等。命令行操作如下：

[root@kvm-host2 ~]# mount my-nfs:/rw-images/ /mnt/￼ [root@kvm-host2 ~]# df -h | grep images￼ 192.168.11.3:/mnt/images  734G  1.7G  695G   1% /mnt/images￼ [root@kvm-host2 ~]# qemu-system-x86_64 /mnt/images/rhel7.img -smp 2 -m 2048 -net nic -net tap -incoming tcp:0:6666

在这一步骤中，目的宿主机上的操作有两个值得注意的地方：一是NFS的挂载目录必须与源宿主机上保持完全一致；二是启动客户机的命令与源宿主机上的启动命令一致，但是需要增加“-incoming”选项。
这里在启动客户机的qemu命令行中添加了“-incoming tcp：0：6666”这个参数，它表示在6666端口建立一个TCP Socket连接，用于接收来自源主机的动态迁移的内容，其中“0”表示允许来自任何主机的连接。“-incoming”这个参数使这里的QEMU进程进入迁移监听（migration-listen）模式，而不是真正以命令行中的镜像文件运行客户机。从VNC中看到，客户机是黑色的，没有任何显示，没有像普通客户机一样启动，而是在等待动态迁移数据的传入，如图8-4所示。
