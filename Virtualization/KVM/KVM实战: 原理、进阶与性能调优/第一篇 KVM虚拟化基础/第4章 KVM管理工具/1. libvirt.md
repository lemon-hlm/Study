
<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

* [1 libvirt简介](#1-libvirt简介)
	* [1.1 多种虚拟化方案支持](#11-多种虚拟化方案支持)
	* [1.2 LGPL许可证](#12-lgpl许可证)
	* [1.3 编程语言支持、AMQP和加密认证](#13-编程语言支持-amqp和加密认证)
	* [1.4 基本架构](#14-基本架构)
	* [1.5 重要概念](#15-重要概念)
	* [1.6 管理功能](#16-管理功能)
		* [1.6.1 域的管理](#161-域的管理)
		* [1.6.2 远程节点的管理](#162-远程节点的管理)
		* [1.6.3 存储的管理](#163-存储的管理)
		* [1.6.4 网络的管理](#164-网络的管理)
		* [1.6.5 应用程序接口](#165-应用程序接口)
	* [1.7 libvirt组成](#17-libvirt组成)
* [2 libvirt的安装与配置](#2-libvirt的安装与配置)
	* [2.1 libvirt安装](#21-libvirt安装)
	* [2.2 libvirt的配置文件](#22-libvirt的配置文件)
		* [2.2.1 /etc/libvirt/libvirt.conf](#221-etclibvirtlibvirtconf)
		* [2.2.2 /etc/libvirt/libvirtd.conf](#222-etclibvirtlibvirtdconf)
		* [2.2.3 /etc/libvirt/qemu.conf](#223-etclibvirtqemuconf)
		* [2.2.4 /etc/libvirt/qemu/目录](#224-etclibvirtqemu目录)
* [3 libvirtd的使用](#3-libvirtd的使用)
* [3 libvirt域的XML配置文件](#3-libvirt域的xml配置文件)
	* [3.1 客户机的XML配置文件格式的示例](#31-客户机的xml配置文件格式的示例)
	* [3.2 CPU、内存、启动顺序等基本配置](#32-cpu-内存-启动顺序等基本配置)
		* [3.2.1 CPU的配置](#321-cpu的配置)
		* [3.2.2 内存的配置](#322-内存的配置)
		* [3.2.3 客户机系统类型和启动顺序](#323-客户机系统类型和启动顺序)

<!-- /code_chunk_output -->

# 1 libvirt简介

提到KVM的管理工具，首先不得不介绍的就是大名鼎鼎的**libvirt**，因为libvirt是目前使用最为广泛的对KVM虚拟机进行管理的工具和应用程序接口，而且一些常用的虚拟机管理工具（如**virsh**、**virt\-install**、**virt\-manager**等）和云计算框架平台（如OpenStack、ZStack、OpenNebula、Eucalyptus等）都在**底层使用libvirt的应用程序接口**。

libvirt是为了更方便地管理平台虚拟化技术而设计的开放源代码的应用程序接口、守护进程和管理工具，它不仅提供了对**虚拟化客户机的管理**，也提供了对**虚拟化网络和存储的管理！！！**。

## 1.1 多种虚拟化方案支持

libvirt支持**多种虚拟化方案**，既支持包括**KVM**、**QEMU**、**Xen**、**VMware**、**VirtualBox**、**Hyper\-V**等在内的**平台虚拟化方案**，也支持**OpenVZ**、**LXC**等**Linux容器虚拟化系统！！！**，还支持**用户态Linux（UML！！！**）的**虚拟化**。

## 1.2 LGPL许可证

libvirt是一个免费的开源的软件，使用的许可证是LGPL￼（**GNU宽松的通用公共许可证**），使用libvirt库进行链接的软件程序**不一定要选择开源和遵守GPL许可证**。和KVM、Xen等开源项目类似，libvirt也有自己的开发者社区，而且随着虚拟化、云计算等成为近年来的技术热点，libvirt项目的社区也比较活跃。目前，libvirt的开发主要由Redhat公司作为强大的支持，由于Redhat公司在虚拟化方面逐渐偏向于支持KVM（而不是Xen），故libvirt对QEMU/KVM的支持是非常成熟和稳定的。当然，IBM、Novell等公司以及众多的个人开发者对libvirt项目的代码贡献量也是非常大的。

## 1.3 编程语言支持、AMQP和加密认证

libvirt本身提供了一套较为稳定的**C语言应用程序接口**，目前，在其他一些流行的**编程语言**中也提供了对libvirt的绑定，在Python、Perl、Java、Ruby、PHP、OCaml等高级编程语言中已经有**libvirt的程序库**可以直接使用。libvirt还提供了为基于**AMQP（高级消息队列协议**）的**消息系统**（如Apache Qpid）提供**QMF代理**，这可以让云计算管理系统中**宿主机与客户机**、**客户机与客户机**之间的消息通信变得更易于实现。libvirt还为安全地**远程管理虚拟客户机**提供了**加密和认证**等安全措施。

正是由于libvirt拥有这些强大的功能和较为稳定的应用程序接口，而且它的许可证（license）也比较宽松，所以libvirt的应用程序接口已被广泛地用在基于虚拟化和云计算的解决方案中，主要作为**连接底层Hypervisor**和**上层应用程序**的一个**中间适配层**。

## 1.4 基本架构

libvirt对多种不同的Hypervisor的支持是通过一种**基于驱动程序的架构**来实现的。libvirt对**不同的Hypervisor**提供了**不同的驱动**：对Xen有Xen的驱动，对QEMU/KVM有QEMU驱动，对VMware有VMware驱动。在libvirt源代码中，可以很容易找到**qemu\_driver.c**、**xen\_driver.c**、**xenapi\_driver.c**、**VMware\_driver.c**、**vbox\_driver.c**这样的驱动程序源代码文件。

libvirt作为中间适配层，可以让底层Hypervisor对上层用户空间的管理工具是完全透明的，因为libvirt屏蔽了底层各种Hypervisor的细节，为上层管理工具提供了一个统一的、较稳定的接口（API）。通过libvirt，一些用户空间管理工具可以管理各种不同的Hypervisor和上面运行的客户机，它们之间基本的交互框架如图4-1所示。

![](./images/2019-05-16-09-07-13.png)

## 1.5 重要概念

在libvirt中涉及几个重要的概念，解释如下：

- **节点（Node**）是一个**物理机器**，上面可能运行着多个虚拟客户机。Hypervisor和Domain都运行在节点上。
- **Hypervisor**也称**虚拟机监控器（VMM**），如KVM、Xen、VMware、Hyper\-V等，是**虚拟化中的一个底层软件层**，它可以虚拟化一个节点让其运行多个虚拟客户机（不同客户机可能有不同的配置和操作系统）。
- **域（Domain**）是在Hypervisor上运行的一个**客户机操作系统实例**。域也被称为实例（instance，如在亚马逊的AWS云计算服务中客户机就被称为实例）、客户机操作系统（guest OS）、虚拟机（virtual machine），它们都是指同一个概念。

节点、Hypervisor和域的关系可以简单地用图4\-2来表示。
￼
![](./images/2019-05-16-09-10-58.png)

## 1.6 管理功能

在了解了节点、Hypervisor和域的概念之后，用一句话概括libvirt的目标，那就是：为了**安全高效地管理节点上的各个域**，而提供一个**公共的稳定的软件层**。当然，这里的管理，既包括**本地的管理**，也包含**远程的管理**。

具体地讲，libvirt的**管理功能**主要包含如下5个部分。

### 1.6.1 域的管理

1）**域的管理**。

包括对节点上的域的各个**生命周期的管理**，如启动、停止、暂停、保存、恢复和**动态迁移**。还包括对**多种设备类型**的**热插拔操作**，包括磁盘、网卡、内存和CPU。当然不同的Hypervisor上对这些热插拔的支持程度有所不同。

### 1.6.2 远程节点的管理

2）**远程节点的管理**。

只要**物理节点**上运行了**libvirtd这个守护进程**，远程的管理程序就可以连接到该节点进程管理操作，经过认证和授权之后，**所有的libvirt功能**都可以被访问和使用。libvirt支持**多种网络远程传输类型**，如**SSH**、**TCP套接字**、**Unix domain socket**、**TLS的加密传输**等。假设使用了最简单的SSH，不需要额外的配置工作，比如，在example.com节点上运行了libvirtd，而且允许SSH访问，在远程的某台管理机器上就可以用如下的命令行来连接到example.com上，从而管理其上的域。

```
virsh -c qemu+ssh://root@example.com/system
```

### 1.6.3 存储的管理

3）**存储的管理**。

任何运行了**libvirtd守护进程的主机！！！**，都可以通过**libvirt**来管理**不同类型的存储**，如创建不同格式的客户机镜像（qcow2、raw、qde、vmdk等）、挂载NFS共享存储系统、查看现有的LVM卷组、创建新的LVM卷组和逻辑卷、对磁盘设备分区、挂载iSCSI共享存储、使用Ceph系统支持的RBD远程存储，等等。

当然在libvirt中，对存储的管理也是支持远程的。

### 1.6.4 网络的管理

4）**网络的管理**。

任何运行了**libvirtd守护进程的主机**，都可以通过libvirt来管理**物理的和逻辑的网络接口**。包括列出现有的网络接口卡，配置网络接口，创建虚拟网络接口，网络接口的桥接，VLAN管理，NAT网络设置，为客户机分配虚拟网络接口，等等。

### 1.6.5 应用程序接口

5）提供一个稳定、可靠、高效的**应用程序接口**，以便可以完成前面的4个管理功能。

## 1.7 libvirt组成

libvirt主要由3个部分组成，分别是：**应用程序编程接口库**、**一个守护进程（libvirtd**）和**一个默认命令行管理工具（virsh**）。

- **应用程序接口**是为其他虚拟机管理工具（如virsh、virt-manager等）提供虚拟机管理的**程序库支持**。
- **libvirtd守护进程**负责执行对节点上的**域的管理**工作，在用各种工具对虚拟机进行管理时，这个守护进程一定要处于**运行状态**中。而且这个守护进程可以分为两种：
    - 一种是**root权限**的**libvirtd**，其权限较大，可以完成所有支持的管理工作；
    - 一种是**普通用户权限**的**libvirtd**，只能完成比较受限的管理工作。
- virsh是libvirt项目中默认的对虚拟机管理的一个命令行工具，将在4.2节中详细介绍。

# 2 libvirt的安装与配置

## 2.1 libvirt安装

RHEL 系列中可以使用yum或rpm工具来安装对应的RPM包。

查看某系统中已经安装的libvirt相关的RPM包，命令行如下：

```
# rpm -qa | grep libvirt
# yum install libvirt
```

当然，RHEL 7.3**默认采用QEMU/KVM的虚拟化方案**，所以应该安装QEMU相关的软件包。查看这些软件包的命令行操作如下：

```
[root@localhost qemu]# rpm -qa | grep '^qemu'
qemu-kvm-1.5.3-160.el7_6.1.x86_64
qemu-kvm-common-1.5.3-160.el7_6.1.x86_64
qemu-guest-agent-2.12.0-2.el7.x86_64
qemu-img-1.5.3-160.el7_6.1.x86_64

# 安装时, 运行yum install qemu-kvm即可
```

由于libvirt是跨平台的，而且还支持微软公司的**Hyper\-V虚拟化**，所以在Windows上也可以安装libvirt，甚至可以编译libvirt。可以到libvirt官方的网页（ https://libvirt.org/windows.html ）中查看更多关于libvirt对Windows的支持。

## 2.2 libvirt的配置文件

以RHEL 7.3为例，libvirt相关的配置文件都在/etc/libvirt/目录之中，如下：

```
[root@localhost qemu]# ll /etc/libvirt/
总用量 80
-rw-r--r--  1 root root   450 4月  24 22:07 libvirt-admin.conf
-rw-r--r--  1 root root   547 4月  24 22:07 libvirt.conf
-rw-r--r--  1 root root 16529 4月  24 22:07 libvirtd.conf
-rw-r--r--  1 root root  1175 4月  24 22:07 lxc.conf
drwx------. 2 root root  4096 5月  15 19:51 nwfilter
drwx------. 3 root root    22 4月  24 22:07 qemu
-rw-r--r--  1 root root 30306 4月  24 22:07 qemu.conf
-rw-r--r--  1 root root  2169 4月  24 22:07 qemu-lockd.conf
drwx------. 2 root root     6 3月   1 09:39 secrets
-rw-r--r--  1 root root  3202 4月  24 22:07 virtlockd.conf
-rw-r--r--  1 root root  3247 4月  24 22:07 virtlogd.conf
[root@localhost qemu]# ll /etc/libvirt/qemu
总用量 0
drwx------. 3 root root 42 4月  24 22:07 networks
```

下面简单介绍其中几个重要的配置文件和目录。

### 2.2.1 /etc/libvirt/libvirt.conf

libvirt.conf文件用于配置一些**常用libvirt连接（通常是远程连接）的别名**。和Linux中的普通配置文件一样，在该配置文件中以井号（#）开头的行是注释，如下：

```
[root@localhost libvirt]# cat /etc/libvirt/libvirt.conf
#
# This can be used to setup URI aliases for frequently
# used connection URIs. Aliases may contain only the
# characters  a-Z, 0-9, _, -.
#
# Following the '=' may be any valid libvirt connection
# URI, including arbitrary parameters

#uri_aliases = [
#  "hail=qemu+ssh://root@hail.cloud.example.com/system",
#  "sleet=qemu+ssh://root@sleet.cloud.example.com/system",
#]

#
# These can be used in cases when no URI is supplied by the application
# (@uri_default also prevents probing of the hypervisor driver).
#
#uri_default = "qemu:///system"
#为了演示目录，配置了如下这个别名￼
uri_aliases = [￼
    "remote1=qemu+ssh://root@192.168.93.201/system",￼
]
```

其中，配置了remote1这个别名，用于指代 qemu+ssh//root@192.168.93.201/system 这个远程的libvirt连接。有这个别名后，就可以在用**virsh等工具**或自己写**代码调用libvirt API**时使用这个别名，而不需要写完整的、冗长的URI连接标识了。

用virsh使用这个别名，连接到远程的libvirt上查询当前已经启动的客户机状态，然后退出连接。命令行操作如下：

```
[root@kvm-host kvm_demo]# systemctl reload libvirtd￼
[root@kvm-host kvm_demo]# virsh -c remote1￼
root@192.168.93.201's password:￼
Welcome to virsh, the virtualization interactive terminal.￼

Type:  'help' for help with commands￼
       'quit' to quit￼

virsh # list￼
 Id    Name                           State￼
 ----------------------------------------------------￼
 1     rhel7u2-remote                 running￼

virsh # quit￼

[root@kvm-host kvm_demo]#
```

在代码中调用libvirt API时也可以使用这个别名来建立连接，如下的python代码行就实现了使用这个别名来建立连接。

```
conn = libvirt.openReadOnly('remote1')
```

### 2.2.2 /etc/libvirt/libvirtd.conf

libvirtd.conf是libvirt的**守护进程libvirtd的配置文件**，被修改后需要让**libvirtd重新加载配置文件**（或**重启libvirtd**）才会生效。

在libvirtd.conf文件中，用井号（#）开头的行是注释内容，真正有用的配置在文件的每一行中使用“**配置项=值**”（如tcp_port="16509"）这样配对的格式来设置。

在libvirtd.conf中配置了libvirtd启动时的许多设置，包括是否建立TCP、UNIX domain socket等连接方式及其最大连接数，以及这些连接的认证机制，设置libvirtd的日志级别等。

例如，下面的几个配置项表示

- **关闭TLS安全认证的连接**（默认值是打开的），
- **打开TCP连接**（默认是关闭TCP连接的），
- 设置TCP监听的端口，
- 设置UNIX domain socket的保存目录
- TCP连接不使用认证授权方式

```
listen_tls = 0￼
listen_tcp = 1￼
tcp_port = "16666"￼
unix_sock_dir = "/var/run/libvirt"￼
auth_tcp = "none"
```
>
>注意:
>要让**TCP、TLS等连接生效**，需要在**启动libvirtd**时加上\-\-**listen参数**（简写为\-l）。而**默认的systemctl start libvirtd**命令在启动libvirtd服务时并**没带\-\-listen**参数。所以如果要使用TCP等连接方式，可以使用libvirtd \-\-listen \-d命令来启动libvirtd。

以上配置选项实现将**UNIX socket**放到/**var/run/libvirt目录**下，启动libvirtd并检验配置是否生效。命令行操作如下：

```
[root@kvm-host ~]# libvirtd --listen -d￼

[root@kvm-host ~]# virsh -c qemu+tcp://localhost:16666/system￼
Welcome to virsh, the virtualization interactive terminal.￼

Type:  'help' for help with commands￼
       'quit' to quit￼
       
virsh # quit￼

[root@kvm-host ~]# ls /var/run/libvirt/libvirt-sock*￼
/var/run/libvirt/libvirt-sock  /var/run/libvirt/libvirt-sock-ro
```

### 2.2.3 /etc/libvirt/qemu.conf

qemu.conf是libvirt对**QEMU的驱动的配置文件**，包括VNC、SPICE等，以及连接它们时采用的权限认证方式的配置，也包括内存大页、SELinux、Cgroups等相关配置。

### 2.2.4 /etc/libvirt/qemu/目录

在qemu目录下存放的是**使用QEMU驱动的域的配置文件**。查看qemu目录如下：

```
[root@kvm-host ~]# ls /etc/libvirt/qemu/￼
networks centos7u2-1.xml centos7u2-2.xml
```

其中包括了**两个域的XML配置文件**（centos7u2\-1.xml和centos7u2\-2.xml），这就是笔者用virt\-manager工具创建的两个域，默认会将其配置文件保存到/etc/libvirt/qemu/目录下。而其中的**networks目录**保存了**创建一个域时默认使用的网络配置**。

# 3 libvirtd的使用

libvirtd是一个作为libvirt虚拟化管理系统中的**服务器端的守护程序**，要让某个节点能够利用libvirt进行管理（无论是**本地还是远程管理！！！**），都需要在这个节点上**运行libvirtd这个守护进程**，以便让其他**上层管理工具可以连接到该节点**，**libvirtd**负责**执行**其他管理工具发送给它的**虚拟化管理操作指令**。

而libvirt的**客户端工具**（包括**virsh**、**virt\-manager**等）可以**连接**到**本地或远程的libvirtd进程**，以便**管理节点上的客户机**（启动、关闭、重启、迁移等）、收集节点上的**宿主机！！！和客户机的配置和资源使用**状态。

在RHEL 7.3中，**libvirtd**是作为一个**服务（service**）配置在系统中的，所以可以通过**systemctl命令**来对其进行操作（RHEL 6.x等系统中使用service命令）。常用的操作方式有：

- “systemctl start libvirtd”命令表示启动libvirtd，
- “systemctl restart libvirtd”表示重启libvirtd，
- “systemctl reload libvirtd”表示**不重启服务但重新加载配置文件**（即/etc/libvirt/**libvirtd.conf**配置文件），
- “systemctl status libvirtd”表示查询libvirtd服务的运行状态。

在**默认情况**下，libvirtd在监听一个**本地！！！的Unix domain socket！！！**，而**没有监听基于网络**的**TCP/IP socket**，需要使用“\-l或\-\-listen”的命令行参数来开启对**libvirtd.conf配置文件**中**TCP/IP socket的配置！！！**。

另外，libvirtd守护进程的**启动或停止**，并**不会直接影响正在运行中的客户机！！！**。libvirtd在**启动或重启完成时**，只要**客户机的XML配置文件**是存在的，libvirtd会**自动加载这些客户的配置**，获取它们的**信息**。当然，如果客户机**没有**基于libvirt格式的**XML文件**来运行（例如直接使用**qemu命令行**来启动的客户机），libvirtd则**不能自动发现**它。


libvirtd是一个可执行程序，不仅可以使用“systemctl”命令调用它作为服务来运行，而且可以**单独地运行libvirtd命令**来使用它。下面介绍几种libvirtd命令行的参数。

（1）\-d或\-\-daemon

表示让libvirtd作为**守护进程**（daemon）在**后台运行**。

（2）\-f或\-\-config FILE

指定**libvirtd的配置文件为FILE**，而不是使用默认值（通常是/**etc/libvirt/libvirtd.conf**）。

（3）\-l或\-\-listen

开启配置文件中配置的TCP/IP连接。

（4）\-p或\-\-pid\-file FILE

将l**ibvirtd进程的PID写入FILE文件**中，而**不是使用默认值**（通常是/**var/run/libvirtd.pid**）。

（5）\-t或\-\-timeout SECONDS

设置**对libvirtd连接的超时时间**为SECONDS秒。

（6）\-v或\-\-verbose

执行命令**输出详细的输出信息**。特别是在运行出错时，详细的输出信息便于用户查找原因。

（7）\-\-version

显示**libvirtd程序的版本信息**。

关于libvirtd命令的使用，几个简单的命令行操作演示如下：

```
#使用libvirtd 命令前，先停止已运行的服务￼
[root@kvm-host ~]# systemctl stop libvirtd￼
[root@kvm-host ~]# libvirtd --version￼
libvirtd (libvirt) 2.0.0￼

[root@kvm-host ~]# libvirtd￼
^C  #没有以daemon的形式启动，标准输出被libvirtd占用；这里用Ctrl+C组合键结束libvirtd进程，以便继续进行后续操作￼

[root@kvm-host ~]# libvirtd -l -d -p /root/libvirtd.pid￼
[root@kvm-host ~]# cat /root/libvirtd.pid￼
8136
```

# 3 libvirt域的XML配置文件

在**使用libvirt对虚拟化系统进行管理**时，很多地方都是以**XML文件作为配置文件！！！** 的，包括**客户机（域）的配置**、**宿主机网络接口配置**、**网络过滤**、各个**客户机的磁盘存储配置**、**磁盘加密**、**宿主机和客户机的CPU特性**，等等。本节**只针对客户机的XML**进行较详细介绍，因为客户机的配置是最基本的和最重要的，了解了它之后就可以使用libvirt管理客户机了。

## 3.1 客户机的XML配置文件格式的示例

在libvirt中，客户机（即域）的配置是采用XML格式来描述的。下面展示了笔者使用virt\-manager创建的一个客户机的配置文件（即在4.1.2节中看到的centos7u2\-1.xml文件），后面几节将会分析其中的主要配置项目。

```xml
<!--￼
WARNING: THIS IS AN AUTO-GENERATED FILE. CHANGES TO IT ARE LIKELY TO BE￼ OVERWRITTEN AND LOST. Changes to this xml configuration should be made using:￼
    virsh edit centos7u2-1￼
or other application using the libvirt API.￼
-->￼
￼
<domain type='kvm'>￼
    <name>centos7u2-1</name>￼
    <uuid>2f6260bf-1283-4933-aaef-fa82148537ba</uuid>￼
    <memory unit='KiB'>2097152</memory>￼
    <currentMemory unit='KiB'>2097152</currentMemory>￼
    <vcpu placement='static'>2</vcpu>￼
    <os>￼
        <type arch='x86_64' machine='pc-i440fx-rhel7.0.0'>hvm</type>￼
        <boot dev='hd'/>￼
        <boot dev='cdrom'/>￼
    </os>￼
    <features>￼
        <acpi/>￼
        <apic/>￼
    </features>￼
    <cpu mode='custom' match='exact'>￼
        <model fallback='allow'>Haswell-noTSX</model>￼
    </cpu>￼
    <clock offset='utc'>￼
        <timer name='rtc' tickpolicy='catchup'/>￼
        <timer name='pit' tickpolicy='delay'/>￼
        <timer name='hpet' present='no'/>￼
    </clock>￼
    <on_poweroff>destroy</on_poweroff>￼
    <on_reboot>restart</on_reboot>￼
    <on_crash>restart</on_crash>￼
    <pm>￼
        <suspend-to-mem enabled='no'/>￼
        <suspend-to-disk enabled='no'/>￼
    </pm>￼
    <devices>￼
        <emulator>/usr/libexec/qemu-kvm</emulator>￼
        <disk type='file' device='disk'>￼
            <driver name='qemu' type='qcow2' cache='none'/>￼
            <source file='/var/lib/libvirt/images/centos7u2.qcow2'/>￼
            <target dev='vda' bus='virtio'/>￼
            <address type='pci' domain='0x0000' bus='0x00' slot='0x07' function='0x0'/>￼
        </disk>￼
        <controller type='usb' index='0' model='ich9-ehci1'>￼
            <address type='pci' domain='0x0000' bus='0x00' slot='0x06' function= '0x7'/>￼
        </controller>￼
        <controller type='usb' index='0' model='ich9-uhci1'>￼
            <master startport='0'/>￼
            <address type='pci' domain='0x0000' bus='0x00' slot='0x06' function= '0x0' multifunction='on'/>￼
        </controller>￼
        <controller type='usb' index='0' model='ich9-uhci2'>￼
            <master startport='2'/>￼
            <address type='pci' domain='0x0000' bus='0x00' slot='0x06' function= '0x1'/>￼
        </controller>￼
        <controller type='usb' index='0' model='ich9-uhci3'>￼
            <master startport='4'/>￼
        <address type='pci' domain='0x0000' bus='0x00' slot='0x06' function='0x2'/>￼
            </controller>￼
        <controller type='pci' index='0' model='pci-root'/>￼
        <controller type='virtio-serial' index='0'>￼
            <address type='pci' domain='0x0000' bus='0x00' slot='0x05' function= '0x0'/>￼
        </controller>￼
        <interface type='network'>￼
            <mac address='52:54:00:36:32:aa'/>￼
            <source network='default'/>￼
            <model type='virtio'/>￼
            <address type='pci' domain='0x0000' bus='0x00' slot='0x03' function= '0x0'/>￼
        </interface>￼
        <serial type='pty'>￼
            <target port='0'/>￼
        </serial>￼
        <console type='pty'>￼
            <target type='serial' port='0'/>￼
        </console>￼
        <channel type='unix'>￼
            <source mode='bind' path='/var/lib/libvirt/qemu/channel/target/domain- centos7u2/org.qemu.guest_agent.0'/>￼
            <target type='virtio' name='org.qemu.guest_agent.0'/>￼
            <address type='virtio-serial' controller='0' bus='0' port='1'/>￼
        </channel>￼
        <channel type='spicevmc'>￼
            <target type='virtio' name='com.redhat.spice.0'/>￼
            <address type='virtio-serial' controller='0' bus='0' port='2'/>￼
        </channel>￼
        <input type='tablet' bus='usb'/>￼
        <input type='mouse' bus='ps2'/>￼
        <input type='keyboard' bus='ps2'/>￼
        <graphics type='vnc' port='-1' autoport='yes'/>￼
        <sound model='ich6'>￼
            <address type='pci' domain='0x0000' bus='0x00' slot='0x04' function= '0x0'/>￼
        </sound>￼
        <video>￼
            <model type='qxl' ram='65536' vram='65536' vgamem='16384' heads='1'/>￼
            <address type='pci' domain='0x0000' bus='0x00' slot='0x02' function= '0x0'/>￼
        </video>￼
        <redirdev bus='usb' type='spicevmc'>￼
        </redirdev>￼
        <redirdev bus='usb' type='spicevmc'>￼
        </redirdev>￼
        <memballoon model='virtio'>￼
            <address type='pci' domain='0x0000' bus='0x00' slot='0x08' function= '0x0'/>￼
        </memballoon>￼
    </devices>￼
</domain>
```

由上面的配置文件示例可以看到，在该域的XML文件中，**所有有效配置**都在\<**domain**\>和\<\/**domain**\>标签之间，这表明该配置文件是**一个域的配置**。

通过**libvirt启动客户机**，经过**文件解析**和**命令参数的转换**，最终也会调用**qemu命令行工具**来**实际完成客户机的创建**。

用这个XML配置文件启动的客户机，它的qemu命令行参数是非常详细、非常冗长的一行。查询qemu命令行参数的操作如下：

```
[root@kvm-host ~]# ps -ef | grep qemu | grep centos7u2-1￼
qemu      5865     1 60 21:21 ?        00:00:13 /usr/libexec/qemu-kvm -name centos7u2-1 -S -machine pc-i440fx-rhel7.0.0,accel=kvm,usb=off -cpu Haswell,-rtm,-hle -m 2048 -realtime mlock=off -smp 2,sockets=2,cores=1,threads=1 -uuid 68ec2ee0-2f50-4189-bbfc-ac5d990fc93a -no-user-config -nodefaults -chardev socket,id=charmonitor,path=/var/lib/libvirt/qemu/domain-centos7u2-1/monitor.sock,server,nowait -mon chardev=charmonitor,id=monitor,mode=control -rtc base=utc,driftfix=slew -global kvm-pit.lost_tick_policy=discard -no-hpet -no-shutdown  #... 省略了更多的命令行参数
```

这里RHEL 7.3系统中**默认的QEMU工具！！！**为/**usr/libexec/qemu\-kvm！！！**，与第3章中从源代码编译和安装的**qemu\-system\-x86\_64工具是类似**的，它们的参数也基本一致（当然如果二者版本差异较大，参数和功能可能有一些不同）。

## 3.2 CPU、内存、启动顺序等基本配置

### 3.2.1 CPU的配置

在前面介绍的centos7u2\-1.xml配置文件中，关于CPU的配置如下：

```xml
<vcpu placement='static'>2</vcpu> ￼
<features>￼
    <acpi/>￼
    <apic/>￼
</features>￼
<cpu mode='custom' match='exact'>￼
    <model fallback='allow'>Haswell-noTSX</model>￼
</cpu>
```
**vcpu标签**，表示客户机中**vCPU的个数**，这里为2。

**features标签**，表示Hypervisor为客户机**打开或关闭CPU**或**其他硬件的特性！！！**，这里打开了**ACPI、APIC**等特性。

当然，**CPU的基础特性！！！** 是在**cpu标签！！！中定义**的，这里是之前**创建客户机时**，libvirt**自动检测了CPU硬件平台**，**默认**使用了**Haswell**的CPU给客户机。对于这里看到的CPU模型：**Haswell\-noTSX**，可以在文件/**usr/share/libvirt/cpu\_map.xml**中查看**详细描述**。

该CPU模型中的特性（如SSE2、LM、NX、TSC、AVX2、SMEP等）也是该**客户机可以看到和使用的特性**。

对于CPU模型的配置，有以下3种模式。

1）**custom模式**：就是**这里**示例中表示的，**基于某个基础的CPU模型**，再做**个性化的设置**。

2）**host\-model**模式：**根据物理CPU的特性**，选择一个与之最接近的标准CPU型号，如果没有指定CPU模式，**默认也是使用这种模式！！！**。

xml配置文件为：

```xml
<cpu mode='host-model'/>
```

3）**host\-passthrough**模式：**直接将物理CPU特性暴露给虚拟机**使用，在虚拟机上看到的**完全就是物理CPU的型号**。

xml配置文件为：

```xml
<cpu mode='host-passthrough'/>
```

对vCPU的分配，可以有更细粒度的配置，如下：

```xml
<domain>￼
    ...￼
    <vcpu placement='static' cpuset="1-4,^3,6" current="1">2</vcpu>￼
    ...￼
</domain>
```

**cpuset**表示允许到**哪些物理CPU上执行**，这里表示客户机的**两个vCPU**被允许调度到**1、2、4、6号物理CPU**上执行（\^3表示**排除3号**）；而current表示**启动客户机**时**只给1个vCPU**，最多可以增加到使用2个vCPU。

当然，libvirt还提供**cputune标签**来对CPU的分配进行**更多调节**，如下：

```xml
<domain>￼
    ...￼
    <cputune>￼
        <vcpupin vcpu="0" cpuset="1"/>￼
        <vcpupin vcpu="1" cpuset="2,3"/>￼
        <vcpupin vcpu="2" cpuset="4"/>￼
        <vcpupin vcpu="3" cpuset="5"/>￼
        <emulatorpin cpuset="1-3"/>￼
        <shares>2048</shares>￼
        <period>1000000</period>￼
        <quota>-1</quota>￼
        <emulator_period>1000000</emulator_period>￼
        <emulator_quota>-1</emulator_quota>￼
    </cputune>￼
    ...￼
</domain>
```

这里只简单解释其中几个配置：

**vcpupin标签**表示将**虚拟CPU绑定到某一个或多个物理CPU**上，如

```xml
<vcpupin vcpu="2" cpuset="4"/>
```

表示客户机**2号虚拟CPU**被绑定到**4号物理CPU**上；


```xml
<emulatorpin cpuset="1-3"/>
```

表示将**QEMU emulator绑定到1\~3号物理CPU**上。

在不设置任何vcpupin和cpuset的情况下，客户机的虚拟CPU可能会被调度到任何一个物理CPU上去运行。

```xml
<shares>2048</shares>
```
表示客户机**占用CPU时间的加权配置**，一个配置为2048的域获得的CPU执行时间是配置为1024的域的两倍。如果**不设置shares**值，就会使用**宿主机系统**提供的**默认值**。

另外，还可以配置客户机的NUMA拓扑，以及让客户机针对宿主机NUMA的策略设置等，读者可参考<numa>标签和<numatune>标签。

### 3.2.2 内存的配置

在该域的XML配置文件中，内存大小的配置如下：

```xml
<memory unit='KiB'>2097152</memory>￼
<currentMemory unit='KiB'>2097152</currentMemory>
```

可知，内存大小为2097152KB（即2GB），**memory标签**中的内存表示客户机**最大可使用的内存**，**currentMemory标签**中的内存表示**启动时**即**分配**给客户机使用的内存。在使用QEMU/KVM时，一般将二者设置为相同的值。

另外，内存的**ballooning**相关的配置包含在**devices这个标签！！！的memballoon子标签**中，该标签配置了该客户机的**内存气球设备**，如下：

```xml
<memballoon model='virtio'>￼
    <address type='pci' domain='0x0000' bus='0x00' slot='0x08' function='0x0'/>￼
</memballoon>
```

该配置将**为客户机**分配一个**使用virtio\-balloon驱动的设备**，以便实现客户机内存的ballooning调节。该设备在客户机中的**PCI设备编号**为**0000:00:08.0**。

### 3.2.3 客户机系统类型和启动顺序

客户机**系统类型及其启动顺序**在**os标签**中配置，如下：

```xml
<os>￼
    <type arch='x86_64' machine='pc-i440fx-rhel7.0.0'>hvm</type>￼
    <boot dev='hd'/>￼
    <boot dev='cdrom'/>￼
</os>
```

这样的配置表示**客户机类型**是**hvm类型**，HVM（hardware virtual machine，硬件虚拟机）原本是Xen虚拟化中的概念，它表示在硬件辅助虚拟化技术（Intel VT或AMD-V等）的支持下不需要修改客户机操作系统就可以启动客户机。因为KVM一定要依赖于硬件虚拟化技术的支持，所以在KVM中，客户机类型应该总是hvm，操作系统的架构是x86_64，机器类型是pc-i440fx-rhel7.0.0（这是libvirt中针对RHEL 7系统的默认类型，也可以根据需要修改为其他类型）。boot选项用于设置客户机启动时的设备，这里有hd（即硬盘）和cdrom（光驱）两种，而且是按照硬盘、光驱的顺序启动的，它们在XML配置文件中的先后顺序即启动时的先后顺序。
3.网络的配置
（1）桥接方式的网络配置
在域的XML配置中，使用桥接方式的网络的相关配置如下：

```xml
<devices>￼
    ...￼
    <interface type='bridge'>￼
        <mac address='52:54:00:e9:e0:3b'/>￼
        <source bridge='br0'/>￼
        <model type='virtio'/>￼
        <address type='pci' domain='0x0000' bus='0x00' slot='0x03' function='0x0'/>￼
    </interface>￼
    ...￼
</devices>
```

type='bridge'表示使用桥接方式使客户机获得网络，address用于配置客户机中网卡的MAC地