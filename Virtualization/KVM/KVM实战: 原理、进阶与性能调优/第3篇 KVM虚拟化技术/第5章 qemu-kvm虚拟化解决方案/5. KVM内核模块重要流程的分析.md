
<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [1 初始化流程](#1-初始化流程)
- [2 虚拟机的创建](#2-虚拟机的创建)
- [3 vCPU的创建](#3-vcpu的创建)
- [4 vCPU的运行](#4-vcpu的运行)

<!-- /code_chunk_output -->

# 1 初始化流程

KVM模块分为三个主要模块：kvm.ko、kvm\-intel.ko和kvm\-amd.ko，这三个模块在初始化阶段的流程如图5\-4所示。
￼
图5\-4 KVM模块初始化阶段:

![2019-07-05-21-29-03.png](./images/2019-07-05-21-29-03.png)

**KVM模块**可以**编译进内核**中，也可以作为**内核模块**在Linux系统启动完成**之后加载**。加载时，KVM 根据主机所用的体系架构是 Intel的 VMX技术还是AMD的SVM技术，会采用略微不同的加载流程。

Linux的**子模块入口**通常通过**module\_init**宏进行定义，由内核进行调用。KVM的初始化流程如图5\-5所示。
￼
图5\-5 KVM的初始化流程:

![2019-07-05-22-18-28.png](./images/2019-07-05-22-18-28.png)

KVM的初始化步骤分为以下三步。

1）在**平台相关的KVM模块**中通过**module\_init宏**正式进入KVM的初始化阶段，并且执行相关的**硬件初始化准备**。

2）进入**kvm\_main.c**中的**kvm\_init**函数进行正式的初始化工作，期间进行了一系列子操作。

- 通过**kvm\_arch\_init**函数初始化KVM内部的一些数据结构：**注册全局变量kvm\_x86\_ops**、**初始化MMU**等数据结构、**初始化Timer定时器**架构。
- 分配KVM内部操作所需要的**内存空间**。
- 调用kvm\_x86\_ops的**hardware\_setup**函数进行具体的硬件体系结构的初始化工作。
- 注册**sysfs**和**devfs**等API接口信息。
- 最后初始化**debugfs**的调试信息。

3）进行后续的硬件初始化准备操作。

# 2 虚拟机的创建

基于KVM的虚拟机创建分为**虚拟机创建**和**虚拟CPU创建**两个步骤。在下文的描述中，**虚拟机**对应的**文件描述符**为**vm\_fd**，**虚拟CPU**对应的**文件描述符**为**vcpu\_fd**。

打开/dev/kvm 文件并且获得文件描述符 fd 后，通过 ioctl 指令写入KVM\_CREATE\_KVM，即可创建一个 VM 虚拟。KVM 的该部分代码实现在kvm\_dev 的 file\_operation 结构体中，对应的代码在 kvm\_main.c 中调用 kvm\_dev\_ioctl\_creat\_vm函数实现，其代码如下：

代码5-7 KVM_CREATE_VM实现代码

```
(1880)        case KVM_CREATE_VM:￼
(1881)             r = -EINVAL;￼
(1882)             if (arg)￼
(1883)                  goto out;￼
(1884)             r = kvm_dev_ioctl_create_vm();￼
(1885)             break;
```

kvm\_dev\_ioctl\_create\_vm函数通过调用kvm\_create函数对KVM结构体进行创建。KVM 结构体如前文所述，保存了虚拟机运行的上下文及其他相关状态，在使用之前，需要进行一定的初始化工作。

在 x86体系架构中，KVM结构体的初始化任务在 kvm\_arch\_create\_vm函数中进行，进行了分配内存、初始化设备列表、设置中断管理和初始化 tsc 的spin\_lock的功能。在完成之后，将执行硬件初始化工作，该部分硬件初始化工作通过调用on\_each\_cpu宏，将在每个物理CPU上执行同样的操作。

该操作主要是尝试将所有的CPU切换入vitualize模式，并且设置好时钟等信息，这个过程通过 kvm\_arch\_hardware\_enable 函数完成。该函数代码(arch/x86/kvm/x86.c)如下，主要执行了两个工作：整理CPU的时钟信息；调用kvm\_x86\_ops的硬件相关的函数进行具体操作。

代码5-8 kvm_arch_hardware_enable函数代码

```
￼(5799)   int kvm_arch_hardware_enable(void *garbage)￼
(5800)   {￼
(5801)        struct kvm *kvm;￼
(5802)        struct kvm_vcpu *vcpu;￼
(5803)        int i;￼
(5804)￼
(5805)        kvm_shared_msr_cpu_online();￼
(5806)        list_for_each_entry(kvm, &vm_list, vm_list)￼
(5807)             kvm_for_each_vcpu(i, vcpu, kvm)￼
(5808)                  if (vcpu->cpu == smp_processor_id())￼
(5809)                       kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);￼
(5810)        return kvm_x86_ops->hardware_enable(garbage);￼
(5811)   }
```

接下来，将初始化 KVM 的 memslot 结构体、Bus 总线结构体信息、scru读/写锁信息、eventfd事件通知信息、mmu内存管理结构体信息。

然后，调用 anon\_inode\_getfd 函数。该函数设置了对所有 KVM 的操作都将给予kvm\_vm这个共享文件进行，该共享文件的操作封装在kvm\_vm\_fops结构体中，对VM的操作实际上就是对此文件的操作。因此，对其ioctl调用的是kvm_vm_fops中的成员函数。

代码5\-9 调用anon\_inode\_getfd创建kvm\-vm

```
￼(1840)        fd = anon_inode_getfd("kvm-vm", &kvm_vm_fops, kvm, O_RDWR);￼
(1841)        if (fd < 0)￼
(1842)             kvm_put_kvm(kvm);￼
(1843)￼
(1844)        return fd;
```

通过anon\_inode\_getfd获得的fd文件描述符，就是供用户态使用的vm\_fd，用户态将通过该fd进行进一步的虚拟机操作，首先要做的事情是初始化vCPU。

# 3 vCPU的创建

创建vCPU实际上就是创建vCPU的描述符，在KVM中，vCPU对应的数据结构体为kvm\_vcpu。因此，创建vCPU的描述符，简单来说就是分配相应大小的内存，并且进行相应的初始化工作。kvm\_vcpu中描述符包含的内容有很多，通常会包含各个平台通用的内容和平台相关的内容。

在物理CPU上电之后，需要进一步初始化才可以使用。在这个过程中，硬件会自动将CPU初始化成特定的状态。kvm\_vcpu的初始化也是一个类似的过程，将 kvm\_vcpu 的各个数据结构体设置成为可用的状态，通常需要包含如下内容。

- 分配vCPU标识，设置cpu_id属于哪个KVM虚拟机，并且分配对该vCPU的唯一标识符。
- 初始化虚拟寄存器组。
- 初始化 kvm_vcpu 的状态信息，设置 kvm_vcpu 在被调度前需要配置的必要标志。
- 初始化额外的信息，并且配置apic等虚拟化组件。

接下来讲述KVM中vCPU的创建过程。在获得了fd\_vm之后，通过ioctl调用KVM\_CREATE\_VCPU指令，可以对该fd\_vm对应的虚拟机创建vCPU，其入口函数地址在kvm\_vm\_ioctl函数中，通过switch之后，程序流程将选择进入kvm\_vm\_ioctl\_create\_vcpu函数中进行处理，其代码如下。

代码5-10 kvm_vm_ioctl_create_vcpu代码

```c
￼    (1366)   static int kvm_vm_ioctl_create_vcpu(struct kvm *kvm, u32 id)￼
    (1367)   {￼
    (1368)        int r;￼
    (1369)        struct kvm_vcpu *vcpu, *v;￼
    (1370)￼
    (1371)        vcpu = kvm_arch_vcpu_create(kvm, id);￼
    (1372)        if (IS_ERR(vcpu))￼
    (1373)             return PTR_ERR(vcpu);￼
    (1374)￼
    (1375)        preempt_notifier_init(&vcpu->preempt_notifier, &kvm_preempt_ops);￼
    (1376)￼
    (1377)        r = kvm_arch_vcpu_setup(vcpu);￼
    (1378)        if (r)￼
    (1379)             return r;￼
    (1380)￼
    (1381)        mutex_lock(&kvm->lock);￼
    (1382)        if (atomic_read(&kvm->online_vcpus) == KVM_MAX_VCPUS) {￼
    (1383)             r = -EINVAL;￼
    (1384)             goto vcpu_destroy;￼
    (1385)        }￼
    (1386)￼
    (1387)        kvm_for_each_vcpu(r, v, kvm)￼
    (1388)             if (v->vcpu_id == id) {￼
    (1389)                  r = -EEXIST;￼
    (1390)                  goto vcpu_destroy;￼
    (1391)             }￼
    (1392)￼
    (1393)        BUG_ON(kvm->vcpus[atomic_read(&kvm->online_vcpus)]);￼
    (1394)￼
    (1395)        /* Now it's all set up, let userspace reach it */￼
    (1396)        kvm_get_kvm(kvm);￼
    (1397)        r = create_vcpu_fd(vcpu);￼
    (1398)        if (r < 0) {￼
    (1399)             kvm_put_kvm(kvm);￼
    (1400)             goto vcpu_destroy;￼
    (1401)        }￼
    (1402)￼
    (1403)        kvm->vcpus[atomic_read(&kvm->online_vcpus)] = vcpu;￼
    (1404)        smp_wmb();￼
    (1405)        atomic_inc(&kvm->online_vcpus);￼
    (1406)￼
    (1407)   #ifdef CONFIG_KVM_APIC_ARCHITECTURE￼
    (1408)        if (kvm->bsp_vcpu_id == id)￼
    (1409)             kvm->bsp_vcpu = vcpu;￼
    (1410)   #endif￼
    (1411)        mutex_unlock(&kvm->lock);￼
    (1412)        return r;￼
    (1413)￼
    (1414)   vcpu_destroy:￼
    (1415)        mutex_unlock(&kvm->lock);￼
    (1416)        kvm_arch_vcpu_destroy(vcpu);￼
    (1417)        return r;￼
    (1418)   }
```

首先，在1371行，调用kvm\_arch\_vcpu\_create函数创建一个kvm\_vcpu结构体。该创建内容与架构相关，因此，直接调用kvm\_x86\_ops中的create\_vcpu方法执行。虽然代码不同，但是AMD平台和Intel平台实现的思路都是类似的：先指定CPUID之后，接着初始化MSR和VMCS等寄存器，最后完成I/O和内存部分寄存器的初始化，为被初次调度运行做好准备。

其次，在1377行调用kvm\_arch\_vcpu\_setup函数对kvm\_vcpu中的数据结构进行初始化。这里将先调用kvm\_x86\_ops中的put\_vcpu函数，实现将vCPU的参数信息加载入CPU中，并且执行MMU初始化和CPU复位操作。

在 1381～1391 行中，进行了两个检测。第一个是检测到如果当前的 vCPU数量已经达到了系统设置的上限 KVM\_MAX\_VCPU，则将销毁刚才创建的实例。第二个是如果当前的vCPU创建出来已经加入了某一个已有的KVM主机，则也将销毁该实例。

然后，在 1396～1405 行，会创建当前 vCPU 对应的文件描述符 vcpu\_fd，并且将kvm\_vcpu添加入KVM的vCPU数组中。这里有一个特别之处，是使用了 atom\_read 和 atom\_inc 宏，这两个宏能够保证在进行 KVM 虚拟机的 vCPU添加时按照给定的顺序，不会因为执行中途的中断、进程切换等方式导致添加到不正确的kvm\_vcpu数组中。

最后，释放掉所有的内核锁，完成本次vCPU的创建工作。

# 4 vCPU的运行

在创建完VM和vCPU并且完成了初始化工作之后，就可以通过调度程序调度执行。因为在Linux中，KVM虚拟机作为一个系统线程运行，因此，KVM虚拟机的调度程序实际上也就是Linux的调度程序，具体的调度将在后文qemu部分进行讨论，在当前，KVM的调用是从ioctl的KVM\_RUN指令字开始的。

KVM\_RUN指令字针对fd\_vcpu描述符操作，当vCPU准备完成之后，即可通过该指令让虚拟机运行起来。虚拟机运行的主要任务则是进行上下文切换。上下文切换的内容较多，通常包括通用寄存器、浮点寄存器、段寄存器、控制寄存器、MSR等，在KVM中，还包括APIC状态、TLB等。

通常，进行上下文切换的过程可以归纳为如下步骤。

1）KVM保存自己的上下文。

2）KVM通过使用将kvm_vcpu结构体中的相关上下文加载到物理CPU中。

3）KVM执行kvm\_x86\_ops中的run\_vcpu函数，调用具体的平台相关指令，进入虚拟机运行环境中。

由此可见，上下文切换次数过于频繁会带来不小的性能开销，因此，很有必要对这方面进行优化。和操作系统进行进程切换的思路一样，KVM使用Lazy Save/Restore 的方法进行优化。其基本思想是尽量不要对寄存器进行恢复/保存操作，直到必须要这么做的时候，才进行类似的操作。

执行vCPU的请求首先发送到kvm\_vcpu\_ioctl函数中，然后加载vCPU参数，调用kvm\_arch\_vcpu\_ioctl\_run函数进入具体的vCPU运行环节。

1）通过调用sigprocmask函数，保证在vCPU的初始化过程中，不会因为来自其他线程的信号干扰而中断。

2）将vCPU的状态切换为KVM\_MP\_STATE\_UNINITIALIZED。

3）配置APIC和mmio的中断信息。

4）对要进入的虚拟机进行一些关键指令的测试，在测试中主要针对内存读/写情况进行测试。

5）将vCPU中保存的上下文信息（寄存器状态等）写入指定的位置。

6）接下来才开始实质性的工作，调用\_vcpu\_run函数进行后续处理。

\_vcpu\_run函数的代码如下。

代码5-11 _vcpu_run函数

```c
(5232)   static int __vcpu_run(struct kvm_vcpu *vcpu)￼
(5233)   {￼
(5234)        int r;￼
(5235)        struct kvm *kvm = vcpu->kvm;￼
(5236)￼
(5237)        if (unlikely(vcpu->arch.mp_state == KVM_MP_STATE_SIPI_RECEIVED)) {￼
(5238)             pr_debug("vcpu %d received sipi with vector # %x\n",￼
(5239)                   vcpu->vcpu_id, vcpu->arch.sipi_vector);￼
(5240)             kvm_lapic_reset(vcpu);￼
(5241)             r = kvm_arch_vcpu_reset(vcpu);￼
(5242)             if (r)￼
(5243)                  return r;￼
(5244)             vcpu->arch.mp_state = KVM_MP_STATE_RUNNABLE;￼
(5245)        }￼
(5246)￼
(5247)        vcpu->srcu_idx = srcu_read_lock(&kvm->srcu);￼
(5248)        vapic_enter(vcpu);￼
(5249)￼
(5250)        r = 1;￼
(5251)        while (r > 0) {￼
(5252)             if (vcpu->arch.mp_state == KVM_MP_STATE_RUNNABLE)￼
(5253)                  r = vcpu_enter_guest(vcpu);￼
(5254)             else {￼
(5255)                  srcu_read_unlock(&kvm->srcu, vcpu->srcu_idx);￼
(5256)                  kvm_vcpu_block(vcpu);￼
(5257)                  vcpu->srcu_idx = srcu_read_lock(&kvm->srcu);￼
(5258)                  if (kvm_check_request(KVM_REQ_UNHALT, vcpu))￼
(5259)                  {￼
(5260)                       switch(vcpu->arch.mp_state) {￼
(5261)                       case KVM_MP_STATE_HALTED:￼
(5262)                            vcpu->arch.mp_state =￼
(5263)                                KVM_MP_STATE_RUNNABLE;￼
(5264)                       case KVM_MP_STATE_RUNNABLE:￼
(5265)                            break;￼
(5266)                       case KVM_MP_STATE_SIPI_RECEIVED:￼
(5267)                       default:￼
(5268)                            r = -EINTR;￼
(5269)                            break;￼
(5270)                       }￼
(5271)                  }￼
(5272)             }￼
(5273)￼
(5274)             if (r <= 0)￼
(5275)                  break;￼
(5276)￼
(5277)             clear_bit(KVM_REQ_PENDING_TIMER, &vcpu->requests);￼
(5278)             if (kvm_cpu_has_pending_timer(vcpu))￼
(5279)                  kvm_inject_pending_timer_irqs(vcpu);￼
(5280)￼
(5281)             if (dm_request_for_irq_injection(vcpu)) {￼
(5282)                  r = -EINTR;￼
(5283)                  vcpu->run->exit_reason = KVM_EXIT_INTR;￼
(5284)                  ++vcpu->stat.request_irq_exits;￼
(5285)             }￼
(5286)             if (signal_pending(current)) {￼
(5287)                  r = -EINTR;￼
(5288)                  vcpu->run->exit_reason = KVM_EXIT_INTR;￼
(5289)                  ++vcpu->stat.signal_exits;￼
(5290)             }￼
(5291)             if (need_resched()) {￼
(5292)                  srcu_read_unlock(&kvm->srcu, vcpu->srcu_idx);￼
(5293)                  kvm_resched(vcpu);￼
(5294)                  vcpu->srcu_idx = srcu_read_lock(&kvm->srcu);￼
(5295)             }￼
(5296)        }￼
(5297)￼
(5298)        srcu_read_unlock(&kvm->srcu, vcpu->srcu_idx);￼
(5299)￼
(5300)        vapic_exit(vcpu);￼
(5301)￼
(5302)        return r;￼
(5303)   }
```

该函数较长，执行的内容也比较重要，重要的部分如下。

1）在5232～5240行中，将虚拟APIC和vCPU的状态重置。这个操作通过调用kvm\_lapic\_reset和kvm\_arch\_vcpu\_reset函数实现。

2）在5245～5270行中，正常情况下，将kvm\_vcp\-\>arch.mp\_state的取值作为单机未运行的取值：KVM\_MP\_STATE\_RUNNABLE；如果 vCPU 在 VM 中处于其他状态，则会出错。在运行中有一个循环，直到确认了vcpu\_enter\_guest函数执行完毕，即物理CPU进入了GUEST状态并且执行完成后，才会执行下一步操作。

3）在5273～5278行中，将检查本次执行的一些结果。如果CPU当前有挂起的定时器或者其他中断，则会保存该中断的现场。

4）在5286～5289行中，如果对当前执行的vCPU需要调度，会引用Linux的进程调度子程序进行一次任务调度。

在上面的执行流程中，最重要的执行在 vcpu\_enter\_guest 函数中，该函数实现了进入客户机并且执行具体指令的操作。